<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01 USA.gov数据集 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="CHAPTER 14 Data Analysis Examples（数据分析实例） 14.1 USA.gov Data from Bitly（USA.gov数据集） 2011年，短链接服务（URL shortening service）商Bitl" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/03-python-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/11-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%BE%8B%E5%AD%90/01-usa.gov%E6%95%B0%E6%8D%AE%E9%9B%86/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="01 USA.gov数据集" />
<meta property="og:description" content="CHAPTER 14 Data Analysis Examples（数据分析实例） 14.1 USA.gov Data from Bitly（USA.gov数据集） 2011年，短链接服务（URL shortening service）商Bitl" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/03-python-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/11-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%BE%8B%E5%AD%90/01-usa.gov%E6%95%B0%E6%8D%AE%E9%9B%86/" /><meta property="article:published_time" content="2018-07-08T14:29:31&#43;00:00"/>
<meta property="article:modified_time" content="2018-07-08T14:29:31&#43;00:00"/>
<meta itemprop="name" content="01 USA.gov数据集">
<meta itemprop="description" content="CHAPTER 14 Data Analysis Examples（数据分析实例） 14.1 USA.gov Data from Bitly（USA.gov数据集） 2011年，短链接服务（URL shortening service）商Bitl">


<meta itemprop="datePublished" content="2018-07-08T14:29:31&#43;00:00" />
<meta itemprop="dateModified" content="2018-07-08T14:29:31&#43;00:00" />
<meta itemprop="wordCount" content="3679">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="01 USA.gov数据集"/>
<meta name="twitter:description" content="CHAPTER 14 Data Analysis Examples（数据分析实例） 14.1 USA.gov Data from Bitly（USA.gov数据集） 2011年，短链接服务（URL shortening service）商Bitl"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">最新</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">最新</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01 USA.gov数据集</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-07-08 </span>
        
        <span class="more-meta"> 3679 words </span>
        <span class="more-meta"> 8 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#chapter-14-data-analysis-examples-数据分析实例">CHAPTER 14 Data Analysis Examples（数据分析实例）</a></li>
<li><a href="#14-1-usa-gov-data-from-bitly-usa-gov数据集">14.1 USA.gov Data from Bitly（USA.gov数据集）</a></li>
<li><a href="#1-counting-time-zones-in-pure-python-用纯python代码对时区进行计数">1 Counting Time Zones in Pure Python（用纯python代码对时区进行计数）</a></li>
<li><a href="#2-counting-time-zones-with-pandas-用pandas对时区进行计数">2 Counting Time Zones with pandas（用pandas对时区进行计数）</a></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h1 id="chapter-14-data-analysis-examples-数据分析实例">CHAPTER 14 Data Analysis Examples（数据分析实例）</h1>

<h1 id="14-1-usa-gov-data-from-bitly-usa-gov数据集">14.1 USA.gov Data from Bitly（USA.gov数据集）</h1>

<p>2011年，短链接服务（URL shortening service）商<a href="https://bitly.com/">Bitly</a>和美国政府网站<a href="https://www.usa.gov/">USA.gov</a>合作，提供了一份从用户中收集来的匿名数据，这些用户使用了结尾为.gov或.mil的短链接。在2011年，这些数据的动态信息每小时都会保存一次，并可供下载。不过在2017年，这项服务被停掉了。</p>

<p>数据是每小时更新一次，文件中的每一行都用JOSN（JavaScript Object Notation）格式保存。我们先读取几行看一下数据是什么样的：</p>

<pre><code class="language-python">path = '../datasets/bitly_usagov/example.txt'
</code></pre>

<pre><code class="language-python">open(path).readline()
</code></pre>

<pre><code>'{ &quot;a&quot;: &quot;Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11 (KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11&quot;, &quot;c&quot;: &quot;US&quot;, &quot;nk&quot;: 1, &quot;tz&quot;: &quot;America\\/New_York&quot;, &quot;gr&quot;: &quot;MA&quot;, &quot;g&quot;: &quot;A6qOVH&quot;, &quot;h&quot;: &quot;wfLQtf&quot;, &quot;l&quot;: &quot;orofrog&quot;, &quot;al&quot;: &quot;en-US,en;q=0.8&quot;, &quot;hh&quot;: &quot;1.usa.gov&quot;, &quot;r&quot;: &quot;http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf&quot;, &quot;u&quot;: &quot;http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991&quot;, &quot;t&quot;: 1331923247, &quot;hc&quot;: 1331822918, &quot;cy&quot;: &quot;Danvers&quot;, &quot;ll&quot;: [ 42.576698, -70.954903 ] }\n'
</code></pre>

<p>python有很多内置的模块能把JSON字符串转换成Python字典对象。这里我们用JSON模块：</p>

<pre><code class="language-python">import json
path = '../datasets/bitly_usagov/example.txt'
records = [json.loads(line) for line in open(path)]
</code></pre>

<p>上面这种方法叫做列表推导式, list comprehension, 在一组字符串上执行一条相同操作（比如这里的json.loads）。结果对象records现在是一个由dict组成的list：</p>

<pre><code class="language-python">records[0]
</code></pre>

<pre><code>{'a': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.78 Safari/535.11',
 'al': 'en-US,en;q=0.8',
 'c': 'US',
 'cy': 'Danvers',
 'g': 'A6qOVH',
 'gr': 'MA',
 'h': 'wfLQtf',
 'hc': 1331822918,
 'hh': '1.usa.gov',
 'l': 'orofrog',
 'll': [42.576698, -70.954903],
 'nk': 1,
 'r': 'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf',
 't': 1331923247,
 'tz': 'America/New_York',
 'u': 'http://www.ncbi.nlm.nih.gov/pubmed/22415991'}
</code></pre>

<pre><code class="language-python">records[0]['tz']
</code></pre>

<pre><code>'America/New_York'
</code></pre>

<h1 id="1-counting-time-zones-in-pure-python-用纯python代码对时区进行计数">1 Counting Time Zones in Pure Python（用纯python代码对时区进行计数）</h1>

<p>我们想知道数据集中出现在哪个时区（即tz字段）</p>

<pre><code class="language-python">time_zones = [rec['tz'] for rec in records]
</code></pre>

<pre><code>---------------------------------------------------------------------------

KeyError                                  Traceback (most recent call last)

&lt;ipython-input-10-db4fbd348da9&gt; in &lt;module&gt;()
----&gt; 1 time_zones = [rec['tz'] for rec in records]


&lt;ipython-input-10-db4fbd348da9&gt; in &lt;listcomp&gt;(.0)
----&gt; 1 time_zones = [rec['tz'] for rec in records]


KeyError: 'tz'
</code></pre>

<p>看来并不是所有的记录都有时区字段。那么只需要在推导式的末尾加一个if &lsquo;tz&rsquo; in rec判断即可</p>

<pre><code class="language-python">time_zones = [rec['tz'] for rec in records if 'tz' in rec]
</code></pre>

<pre><code class="language-python">time_zones[:10]
</code></pre>

<pre><code>['America/New_York',
 'America/Denver',
 'America/New_York',
 'America/Sao_Paulo',
 'America/New_York',
 'America/New_York',
 'Europe/Warsaw',
 '',
 '',
 '']
</code></pre>

<p>在这10条时区信息中，可以看到有些是空字符串，现在先留着。</p>

<p>为了对时区进行计数，我们用两种方法：一个用纯python代码，比较麻烦。另一个用pandas，比较简单。 这里我们先介绍使用纯python代码的方法：</p>

<p>遍历时区的过程中将计数值保存在字典中：</p>

<pre><code class="language-python">def get_counts(sequence):
    counts = {}
    for x in sequence:
        if x in counts:
            counts[x] += 1
        else:
            counts[x] = 1
    return counts
</code></pre>

<p>使用python标准库的话，能把代码写得更简洁一些：</p>

<pre><code class="language-python">from collections import defaultdict

def get_counts2(sequence):
    counts = defaultdict(int) # 所有的值均会被初始化为0
    for x in sequence:
        counts[x] += 1
    return counts
</code></pre>

<p>（译者：下面关于defaultdict的用法是我从Stack Overflow上找到的，英文比较多，简单的说就是通常如果一个字典里不存在一个key，调用的时候会报错，但是如果我们设置了了default，就不会被报错，而是会新建一个key，对应的value就是我们设置的int，这里int代表0）</p>

<blockquote>
<p><strong>defaultdict</strong> means that if a key is not found in the dictionary, then instead of a KeyError being thrown, a new entry is created. The type of this new entry is given by the argument of defaultdict.</p>
</blockquote>

<pre><code>somedict = {}
print(somedict[3]) # KeyError

someddict = defaultdict(int)
print(someddict[3]) # print int(), thus 0
</code></pre>

<blockquote>
<p>Usually, a Python dictionary throws a KeyError if you try to get an item with a key that is not currently in the dictionary. The defaultdict in contrast will simply create any items that you try to access (provided of course they do not exist yet). To create such a &ldquo;default&rdquo; item, it calls the function object that you pass in the constructor (more precisely, it&rsquo;s an arbitrary &ldquo;callable&rdquo; object, which includes function and type objects). For the first example, default items are created using <code>int()</code>, which will return the integer object 0. For the second example, default items are created using <code>list()</code>, which returns a new empty list object.</p>
</blockquote>

<pre><code class="language-python">someddict = defaultdict(int)
print(someddict[3])
</code></pre>

<pre><code>0
</code></pre>

<pre><code class="language-python">someddict[3]
</code></pre>

<pre><code>0
</code></pre>

<p>上面用函数的方式写出来是为了有更高的可用性。要对它进行时区处理，只需要将time_zones传入即可：</p>

<pre><code class="language-python">counts = get_counts(time_zones)
</code></pre>

<pre><code class="language-python">counts['America/New_York']
</code></pre>

<pre><code>1251
</code></pre>

<pre><code class="language-python">len(time_zones)
</code></pre>

<pre><code>3440
</code></pre>

<p>如何想要得到前10位的时区及其计数值，我们需要一些有关字典的处理技巧：</p>

<pre><code class="language-python">def top_counts(count_dict, n=10):
    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]
    value_key_pairs.sort()
    return value_key_pairs[-n:]
</code></pre>

<pre><code class="language-python">top_counts(counts)
</code></pre>

<pre><code>[(33, 'America/Sao_Paulo'),
 (35, 'Europe/Madrid'),
 (36, 'Pacific/Honolulu'),
 (37, 'Asia/Tokyo'),
 (74, 'Europe/London'),
 (191, 'America/Denver'),
 (382, 'America/Los_Angeles'),
 (400, 'America/Chicago'),
 (521, ''),
 (1251, 'America/New_York')]
</code></pre>

<p>如果用python标准库里的collections.Counter类，能让这个任务变得更简单</p>

<pre><code class="language-python">from collections import Counter
</code></pre>

<pre><code class="language-python">counts = Counter(time_zones)
</code></pre>

<pre><code class="language-python">counts.most_common(10)
</code></pre>

<pre><code>[('America/New_York', 1251),
 ('', 521),
 ('America/Chicago', 400),
 ('America/Los_Angeles', 382),
 ('America/Denver', 191),
 ('Europe/London', 74),
 ('Asia/Tokyo', 37),
 ('Pacific/Honolulu', 36),
 ('Europe/Madrid', 35),
 ('America/Sao_Paulo', 33)]
</code></pre>

<h1 id="2-counting-time-zones-with-pandas-用pandas对时区进行计数">2 Counting Time Zones with pandas（用pandas对时区进行计数）</h1>

<p>从一组原始记录中创建DataFrame是很简单的，直接把records传递给pandas.DataFrame即可：</p>

<pre><code class="language-python">import pandas as pd
import numpy as np
</code></pre>

<pre><code class="language-python">frame = pd.DataFrame(records)
</code></pre>

<pre><code class="language-python">frame.info()
</code></pre>

<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3560 entries, 0 to 3559
Data columns (total 18 columns):
_heartbeat_    120 non-null float64
a              3440 non-null object
al             3094 non-null object
c              2919 non-null object
cy             2919 non-null object
g              3440 non-null object
gr             2919 non-null object
h              3440 non-null object
hc             3440 non-null float64
hh             3440 non-null object
kw             93 non-null object
l              3440 non-null object
ll             2919 non-null object
nk             3440 non-null float64
r              3440 non-null object
t              3440 non-null float64
tz             3440 non-null object
u              3440 non-null object
dtypes: float64(4), object(14)
memory usage: 500.7+ KB
</code></pre>

<pre><code class="language-python">frame['tz'][:10]
</code></pre>

<pre><code>0     America/New_York
1       America/Denver
2     America/New_York
3    America/Sao_Paulo
4     America/New_York
5     America/New_York
6        Europe/Warsaw
7
8
9
Name: tz, dtype: object
</code></pre>

<p>这里frame的输出形式是summary view, 主要用于较大的dataframe对象。frame[&lsquo;tz&rsquo;]所返回的Series对象有一个value_counts方法，该方法可以让我们得到想要的信息:</p>

<pre><code class="language-python">tz_counts = frame['tz'].value_counts()
</code></pre>

<pre><code class="language-python">tz_counts[:10]
</code></pre>

<pre><code>America/New_York       1251
                        521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
America/Sao_Paulo        33
Name: tz, dtype: int64
</code></pre>

<p>我们能利用matplotlib为这段数据生成一张图片。这里我们先给记录中未知或缺失的时区填上一个替代值。fillna函数可以替代缺失值（NA），而未知值（空字符串）则可以通过布尔型数组索引，加以替换：</p>

<pre><code class="language-python">clean_tz = frame['tz'].fillna('Missing')
</code></pre>

<pre><code class="language-python">clean_tz[clean_tz == ''] = 'Unknown'
</code></pre>

<pre><code class="language-python">tz_counts = clean_tz.value_counts()
</code></pre>

<pre><code class="language-python">tz_counts[:10]
</code></pre>

<pre><code>America/New_York       1251
Unknown                 521
America/Chicago         400
America/Los_Angeles     382
America/Denver          191
Missing                 120
Europe/London            74
Asia/Tokyo               37
Pacific/Honolulu         36
Europe/Madrid            35
Name: tz, dtype: int64
</code></pre>

<p>利用counts对象的plot方法即可得到一张水平条形图：</p>

<pre><code class="language-python">%matplotlib inline
tz_counts[:10].plot(kind='barh', rot=0)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x10fba90b8&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/mmaEAdgb7e.png?imageslim" alt="mark" /></p>

<p>当然，我们也可以使用之前介绍的seaborn来画一个水平条形图（horizontal bar plot）：</p>

<pre><code class="language-python">import seaborn as sns
</code></pre>

<pre><code class="language-python">subset = tz_counts[:10]
sns.barplot(y=subset.index, x=subset.values)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x10fc93fd0&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/mhKAlb5cIg.png?imageslim" alt="mark" /></p>

<p>我们还可以对这种数据进行更多的处理。比如a字段含有执行URL操作的浏览器、设备、应用程序的相关信息：</p>

<pre><code class="language-python">frame['a'][1]
</code></pre>

<pre><code>'GoogleMaps/RochesterNY'
</code></pre>

<pre><code class="language-python">frame['a'][50]
</code></pre>

<pre><code>'Mozilla/5.0 (Windows NT 5.1; rv:10.0.2) Gecko/20100101 Firefox/10.0.2'
</code></pre>

<pre><code class="language-python">frame['a'][51]
</code></pre>

<pre><code>'Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P925/V10e Build/FRG83G) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1'
</code></pre>

<pre><code class="language-python">frame['a'][:5]
</code></pre>

<pre><code>0    Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...
1                               GoogleMaps/RochesterNY
2    Mozilla/4.0 (compatible; MSIE 8.0; Windows NT ...
3    Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8)...
4    Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...
Name: a, dtype: object
</code></pre>

<p>将这些USER_AGENT字符串中的所有信息都解析出来是一件挺郁闷的工作。不过只要掌握了Python内置的字符串函数和正则表达式，就方便了。比如，我们可以把字符串的第一节（与浏览器大致对应）分离出来得到另一份用户行为摘要：</p>

<pre><code class="language-python">results = Series([x.split()[0] for x in frame.a.dropna()])
</code></pre>

<pre><code class="language-python">results[:5]
</code></pre>

<pre><code>0               Mozilla/5.0
1    GoogleMaps/RochesterNY
2               Mozilla/4.0
3               Mozilla/5.0
4               Mozilla/5.0
dtype: object
</code></pre>

<pre><code class="language-python">results.value_counts()[:8]
</code></pre>

<pre><code>Mozilla/5.0                 2594
Mozilla/4.0                  601
GoogleMaps/RochesterNY       121
Opera/9.80                    34
TEST_INTERNET_AGENT           24
GoogleProducer                21
Mozilla/6.0                    5
BlackBerry8520/5.0.0.681       4
dtype: int64
</code></pre>

<p>现在，假设我们想按Windows和非Windows用户对时区统计信息进行分解。为了简单期间，我们假定只要agent字符串中含有“windows”就认为该用户是windows用户。由于有的agent缺失，所以先将他们从数据中移除：</p>

<pre><code class="language-python">cframe = frame[frame.a.notnull()]
cframe.head()
</code></pre>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>_heartbeat_</th>
      <th>a</th>
      <th>al</th>
      <th>c</th>
      <th>cy</th>
      <th>g</th>
      <th>gr</th>
      <th>h</th>
      <th>hc</th>
      <th>hh</th>
      <th>kw</th>
      <th>l</th>
      <th>ll</th>
      <th>nk</th>
      <th>r</th>
      <th>t</th>
      <th>tz</th>
      <th>u</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>
      <td>en-US,en;q=0.8</td>
      <td>US</td>
      <td>Danvers</td>
      <td>A6qOVH</td>
      <td>MA</td>
      <td>wfLQtf</td>
      <td>1.331823e+09</td>
      <td>1.usa.gov</td>
      <td>NaN</td>
      <td>orofrog</td>
      <td>[42.576698, -70.954903]</td>
      <td>1.0</td>
      <td>http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/...</td>
      <td>1.331923e+09</td>
      <td>America/New_York</td>
      <td>http://www.ncbi.nlm.nih.gov/pubmed/22415991</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>GoogleMaps/RochesterNY</td>
      <td>NaN</td>
      <td>US</td>
      <td>Provo</td>
      <td>mwszkS</td>
      <td>UT</td>
      <td>mwszkS</td>
      <td>1.308262e+09</td>
      <td>j.mp</td>
      <td>NaN</td>
      <td>bitly</td>
      <td>[40.218102, -111.613297]</td>
      <td>0.0</td>
      <td>http://www.AwareMap.com/</td>
      <td>1.331923e+09</td>
      <td>America/Denver</td>
      <td>http://www.monroecounty.gov/etc/911/rss.php</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>Mozilla/4.0 (compatible; MSIE 8.0; Windows NT ...</td>
      <td>en-US</td>
      <td>US</td>
      <td>Washington</td>
      <td>xxr3Qb</td>
      <td>DC</td>
      <td>xxr3Qb</td>
      <td>1.331920e+09</td>
      <td>1.usa.gov</td>
      <td>NaN</td>
      <td>bitly</td>
      <td>[38.9007, -77.043098]</td>
      <td>1.0</td>
      <td>http://t.co/03elZC4Q</td>
      <td>1.331923e+09</td>
      <td>America/New_York</td>
      <td>http://boxer.senate.gov/en/press/releases/0316...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8)...</td>
      <td>pt-br</td>
      <td>BR</td>
      <td>Braz</td>
      <td>zCaLwp</td>
      <td>27</td>
      <td>zUtuOu</td>
      <td>1.331923e+09</td>
      <td>1.usa.gov</td>
      <td>NaN</td>
      <td>alelex88</td>
      <td>[-23.549999, -46.616699]</td>
      <td>0.0</td>
      <td>direct</td>
      <td>1.331923e+09</td>
      <td>America/Sao_Paulo</td>
      <td>http://apod.nasa.gov/apod/ap120312.html</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...</td>
      <td>en-US,en;q=0.8</td>
      <td>US</td>
      <td>Shrewsbury</td>
      <td>9b6kNl</td>
      <td>MA</td>
      <td>9b6kNl</td>
      <td>1.273672e+09</td>
      <td>bit.ly</td>
      <td>NaN</td>
      <td>bitly</td>
      <td>[42.286499, -71.714699]</td>
      <td>0.0</td>
      <td>http://www.shrewsbury-ma.gov/selco/</td>
      <td>1.331923e+09</td>
      <td>America/New_York</td>
      <td>http://www.shrewsbury-ma.gov/egov/gallery/1341...</td>
    </tr>
  </tbody>
</table>
</div>

<p>其次根据a值计算出各行是否是windows：</p>

<pre><code class="language-python">cframe['os'] = np.where(cframe['a'].str.contains('Windows'),
                            'Windows', 'Not Windows')
</code></pre>

<pre><code>/Users/xu/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  from ipykernel import kernelapp as app
</code></pre>

<pre><code class="language-python">cframe['os'][:5]
</code></pre>

<pre><code>0        Windows
1    Not Windows
2        Windows
3    Not Windows
4        Windows
Name: os, dtype: object
</code></pre>

<p>接下来就可以根据时区和新得到的操作系统列表对数据进行分组了：</p>

<pre><code class="language-python">by_tz_os = cframe.groupby(['tz', 'os'])
</code></pre>

<pre><code class="language-python">by_tz_os.size()
</code></pre>

<pre><code>tz                              os
                                Not Windows    245
                                Windows        276
Africa/Cairo                    Windows          3
Africa/Casablanca               Windows          1
Africa/Ceuta                    Windows          2
Africa/Johannesburg             Windows          1
Africa/Lusaka                   Windows          1
America/Anchorage               Not Windows      4
                                Windows          1
America/Argentina/Buenos_Aires  Not Windows      1
America/Argentina/Cordoba       Windows          1
America/Argentina/Mendoza       Windows          1
America/Bogota                  Not Windows      1
                                Windows          2
America/Caracas                 Windows          1
America/Chicago                 Not Windows    115
                                Windows        285
America/Chihuahua               Not Windows      1
                                Windows          1
America/Costa_Rica              Windows          1
America/Denver                  Not Windows    132
                                Windows         59
America/Edmonton                Not Windows      2
                                Windows          4
America/Guayaquil               Not Windows      2
America/Halifax                 Not Windows      1
                                Windows          3
America/Indianapolis            Not Windows      8
                                Windows         12
America/La_Paz                  Windows          1
                                              ...
Europe/Madrid                   Not Windows     16
                                Windows         19
Europe/Malta                    Windows          2
Europe/Moscow                   Not Windows      1
                                Windows          9
Europe/Oslo                     Not Windows      2
                                Windows          8
Europe/Paris                    Not Windows      4
                                Windows         10
Europe/Prague                   Not Windows      3
                                Windows          7
Europe/Riga                     Not Windows      1
                                Windows          1
Europe/Rome                     Not Windows      8
                                Windows         19
Europe/Skopje                   Windows          1
Europe/Sofia                    Windows          1
Europe/Stockholm                Not Windows      2
                                Windows         12
Europe/Uzhgorod                 Windows          1
Europe/Vienna                   Not Windows      3
                                Windows          3
Europe/Vilnius                  Windows          2
Europe/Volgograd                Windows          1
Europe/Warsaw                   Not Windows      1
                                Windows         15
Europe/Zurich                   Not Windows      4
Pacific/Auckland                Not Windows      3
                                Windows          8
Pacific/Honolulu                Windows         36
Length: 149, dtype: int64
</code></pre>

<p>上面通过size对分组结果进行计数，类似于value_counts函数，并利用unstack对计数结果进行重塑为一个表格：</p>

<pre><code class="language-python">agg_counts = by_tz_os.size().unstack().fillna(0)
</code></pre>

<pre><code class="language-python">agg_counts[:10]
</code></pre>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>os</th>
      <th>Not Windows</th>
      <th>Windows</th>
    </tr>
    <tr>
      <th>tz</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>245.0</td>
      <td>276.0</td>
    </tr>
    <tr>
      <th>Africa/Cairo</th>
      <td>0.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>Africa/Casablanca</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Africa/Ceuta</th>
      <td>0.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Africa/Johannesburg</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Africa/Lusaka</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>America/Anchorage</th>
      <td>4.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>America/Argentina/Buenos_Aires</th>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>America/Argentina/Cordoba</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>America/Argentina/Mendoza</th>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>最后，我们来选取最常出现的时区。为了达到这个目的，根据agg_counts中的行数构造了一个简洁索引数组：</p>

<pre><code class="language-python">indexer = agg_counts.sum(1).argsort()
indexer[:10]
</code></pre>

<pre><code>tz
                                  24
Africa/Cairo                      20
Africa/Casablanca                 21
Africa/Ceuta                      92
Africa/Johannesburg               87
Africa/Lusaka                     53
America/Anchorage                 54
America/Argentina/Buenos_Aires    57
America/Argentina/Cordoba         26
America/Argentina/Mendoza         55
dtype: int64
</code></pre>

<pre><code class="language-python">indexer = agg_counts.sum(1).argsort()
indexer[:10]
</code></pre>

<pre><code>tz
                                  24
Africa/Cairo                      20
Africa/Casablanca                 21
Africa/Ceuta                      92
Africa/Johannesburg               87
Africa/Lusaka                     53
America/Anchorage                 54
America/Argentina/Buenos_Aires    57
America/Argentina/Cordoba         26
America/Argentina/Mendoza         55
dtype: int64
</code></pre>

<p>然后通过take按照这个顺序截取了最后10行：</p>

<pre><code class="language-python">count_subset = agg_counts.take(indexer)[-10:]
count_subset
</code></pre>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>os</th>
      <th>Not Windows</th>
      <th>Windows</th>
    </tr>
    <tr>
      <th>tz</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>America/Sao_Paulo</th>
      <td>13.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Europe/Madrid</th>
      <td>16.0</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>Pacific/Honolulu</th>
      <td>0.0</td>
      <td>36.0</td>
    </tr>
    <tr>
      <th>Asia/Tokyo</th>
      <td>2.0</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>Europe/London</th>
      <td>43.0</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>America/Denver</th>
      <td>132.0</td>
      <td>59.0</td>
    </tr>
    <tr>
      <th>America/Los_Angeles</th>
      <td>130.0</td>
      <td>252.0</td>
    </tr>
    <tr>
      <th>America/Chicago</th>
      <td>115.0</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th></th>
      <td>245.0</td>
      <td>276.0</td>
    </tr>
    <tr>
      <th>America/New_York</th>
      <td>339.0</td>
      <td>912.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>pandas有一个很方便的方法叫nlargest，可以实现相同效果：</p>

<pre><code class="language-python">agg_counts.sum(1).nlargest(10)
</code></pre>

<pre><code>tz
America/New_York       1251.0
                        521.0
America/Chicago         400.0
America/Los_Angeles     382.0
America/Denver          191.0
Europe/London            74.0
Asia/Tokyo               37.0
Pacific/Honolulu         36.0
Europe/Madrid            35.0
America/Sao_Paulo        33.0
dtype: float64
</code></pre>

<p>上面的输出结果可以画成条形图；通过给seaborn的barplot函数传递一个参数，来画出堆积条形图（stacked bar plot）：</p>

<pre><code class="language-python"># Rearrange the data for plotting
count_subset = count_subset.stack()
count_subset.head()
</code></pre>

<pre><code>tz                 os
America/Sao_Paulo  Not Windows    13.0
                   Windows        20.0
Europe/Madrid      Not Windows    16.0
                   Windows        19.0
Pacific/Honolulu   Not Windows     0.0
dtype: float64
</code></pre>

<pre><code class="language-python">count_subset.name = 'total'
count_subset = count_subset.reset_index()
count_subset[:10]
</code></pre>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>tz</th>
      <th>os</th>
      <th>total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>America/Sao_Paulo</td>
      <td>Not Windows</td>
      <td>13.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>America/Sao_Paulo</td>
      <td>Windows</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Europe/Madrid</td>
      <td>Not Windows</td>
      <td>16.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Europe/Madrid</td>
      <td>Windows</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Pacific/Honolulu</td>
      <td>Not Windows</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Pacific/Honolulu</td>
      <td>Windows</td>
      <td>36.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Asia/Tokyo</td>
      <td>Not Windows</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Asia/Tokyo</td>
      <td>Windows</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Europe/London</td>
      <td>Not Windows</td>
      <td>43.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Europe/London</td>
      <td>Windows</td>
      <td>31.0</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="language-python">sns.barplot(x='total', y='tz', hue='os', data=count_subset)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x10fc5fcc0&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/l2KldJfKc9.png?imageslim" alt="mark" /></p>

<p>由于这张图中不太容易看清楚较小分组中windows用户的相对比例，因此我们可以将各行规范化为“总计为1”并重新绘图：</p>

<pre><code class="language-python">def norm_total(group):
    group['normed_total'] = group.total / group.total.sum()
    return group

results = count_subset.groupby('tz').apply(norm_total)
</code></pre>

<pre><code class="language-python">sns.barplot(x='normed_total', y='tz', hue='os', data=results)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x113ff5b70&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/48fk352Hj3.png?imageslim" alt="mark" /></p>

<p>我们还可以使用transform和groupby，来更有效率地计算规范化的和：</p>

<pre><code class="language-python">g = count_subset.groupby('tz')
results2 = count_subset.total / g.total.transform('sum')
</code></pre>

<p>译者：下面的内容是不适用seaborn的画图方法，这种画法是2013年第一版中的内容：</p>

<pre><code class="language-python">count_subset = agg_counts.take(indexer)[-10:]
count_subset
</code></pre>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>os</th>
      <th>Not Windows</th>
      <th>Windows</th>
    </tr>
    <tr>
      <th>tz</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>America/Sao_Paulo</th>
      <td>13.0</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Europe/Madrid</th>
      <td>16.0</td>
      <td>19.0</td>
    </tr>
    <tr>
      <th>Pacific/Honolulu</th>
      <td>0.0</td>
      <td>36.0</td>
    </tr>
    <tr>
      <th>Asia/Tokyo</th>
      <td>2.0</td>
      <td>35.0</td>
    </tr>
    <tr>
      <th>Europe/London</th>
      <td>43.0</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>America/Denver</th>
      <td>132.0</td>
      <td>59.0</td>
    </tr>
    <tr>
      <th>America/Los_Angeles</th>
      <td>130.0</td>
      <td>252.0</td>
    </tr>
    <tr>
      <th>America/Chicago</th>
      <td>115.0</td>
      <td>285.0</td>
    </tr>
    <tr>
      <th></th>
      <td>245.0</td>
      <td>276.0</td>
    </tr>
    <tr>
      <th>America/New_York</th>
      <td>339.0</td>
      <td>912.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>这里也可以生成一张条形图。我们使用stacked=True来生成一张堆积条形图：</p>

<pre><code class="language-python">count_subset.plot(kind='barh', stacked=True)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x1143130b8&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/gmi02075fj.png?imageslim" alt="mark" /></p>

<p>由于这张图中不太容易看清楚较小分组中windows用户的相对比例，因此我们可以将各行规范化为“总计为1”并重新绘图：</p>

<pre><code class="language-python">normed_subset = count_subset.div(count_subset.sum(1), axis=0)
</code></pre>

<pre><code class="language-python">normed_subset.plot(kind='barh', stacked=True)
</code></pre>

<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x11433a7b8&gt;
</code></pre>

<p><img src="http://pacdb2bfr.bkt.clouddn.com/blog/image/180708/C7kg4BhI4e.png?imageslim" alt="mark" /></p>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/03-python-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/11-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%BE%8B%E5%AD%90/05-2012%E8%81%94%E9%82%A6%E9%80%89%E4%B8%BE%E5%A7%94%E5%91%98%E4%BC%9A%E6%95%B0%E6%8D%AE%E5%BA%93/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">05 2012联邦选举委员会数据库</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/03-python-%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97/02-numpy/07-%E4%B8%80%E4%B8%AA%E4%BE%8B%E5%AD%90%E9%9A%8F%E6%9C%BA%E6%BC%AB%E6%AD%A5/">
            <span class="next-text nav-default">07 一个例子：随机漫步</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
