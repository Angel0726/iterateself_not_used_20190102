<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>04 文本和字节序列 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="第 4 章 文本和字节序列 人类使用文本，计算机使用字节序列。 1 ——Esther Nam 和 Travis Fischer “Character Encoding and Unicode in Python” 1PyCon 2014，“Ch" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/%E6%B5%81%E7%95%85%E7%9A%84-python/04-%E6%96%87%E6%9C%AC%E5%92%8C%E5%AD%97%E8%8A%82%E5%BA%8F%E5%88%97/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="04 文本和字节序列" />
<meta property="og:description" content="第 4 章 文本和字节序列 人类使用文本，计算机使用字节序列。 1 ——Esther Nam 和 Travis Fischer “Character Encoding and Unicode in Python” 1PyCon 2014，“Ch" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/%E6%B5%81%E7%95%85%E7%9A%84-python/04-%E6%96%87%E6%9C%AC%E5%92%8C%E5%AD%97%E8%8A%82%E5%BA%8F%E5%88%97/" /><meta property="article:published_time" content="2018-06-26T21:32:38&#43;00:00"/>
<meta property="article:modified_time" content="2018-06-26T21:32:38&#43;00:00"/>
<meta itemprop="name" content="04 文本和字节序列">
<meta itemprop="description" content="第 4 章 文本和字节序列 人类使用文本，计算机使用字节序列。 1 ——Esther Nam 和 Travis Fischer “Character Encoding and Unicode in Python” 1PyCon 2014，“Ch">


<meta itemprop="datePublished" content="2018-06-26T21:32:38&#43;00:00" />
<meta itemprop="dateModified" content="2018-06-26T21:32:38&#43;00:00" />
<meta itemprop="wordCount" content="28190">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="04 文本和字节序列"/>
<meta name="twitter:description" content="第 4 章 文本和字节序列 人类使用文本，计算机使用字节序列。 1 ——Esther Nam 和 Travis Fischer “Character Encoding and Unicode in Python” 1PyCon 2014，“Ch"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">iterate self</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">about</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">iterate self</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">about</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">04 文本和字节序列</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-06-26 </span>
        
        <span class="more-meta"> 28190 words </span>
        <span class="more-meta"> 57 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#第-4-章-文本和字节序列">第 4 章 文本和字节序列</a>
<ul>
<li><a href="#4-1-字符问题">4.1 字符问题</a></li>
<li><a href="#4-2-字节概要">4.2 字节概要</a></li>
<li><a href="#4-3-基本的编解码器">4.3 基本的编解码器</a></li>
<li><a href="#4-4-了解编解码问题">4.4 了解编解码问题</a>
<ul>
<li><a href="#出现与unicode有关的错误时-首先要明确异常的类型-导致编码问题的是-unicodeencodeerror-unicodedecodeerror-还是如-syntaxerror-的其他错">出现与Unicode有关的错误时，首先要明确异常的类型。导致编码问题的是 UnicodeEncodeError、UnicodeDecodeError，还是如 SyntaxError 的其他错</a></li>
<li><a href="#❸-cp437-无法编码-a-带波形符的-a-默认的错误处理方式-strict-抛出-unicodeencodeerror">❸&rsquo;cp437&rsquo;无法编码’a&rsquo;（带波形符的“a”）。默认的错误处理方式&rsquo;strict&rsquo;抛出 UnicodeEncodeError。</a></li>
</ul></li>
<li><a href="#4-5-处理文本文件">4.5 处理文本文件</a>
<ul>
<li><a href="#问题是-写入文件时指定了-utf-8-编码-但是读取文件时没有这么做-因此-python-假定-要使用系统默认的编码-windows-1252-于是文件的最后一个字节解码成了字符">问题是：写入文件时指定了 UTF-8 编码，但是读取文件时没有这么做，因此 Python 假定 要使用系统默认的编码(Windows 1252)，于是文件的最后一个字节解码成了字符</a></li>
<li><a href="#示例-4-11-在-gnu-linux-ubuntu-14-04-和-os-x-mavericks-10-9-中的输出一样-表明这">示例 4-11 在 GNU/Linux (Ubuntu 14.04)和 OS X(Mavericks 10.9)中的输出一样，表明这</a></li>
<li><a href="#然而-在-windows-中的输出有所不同-如示例-4-12-所示">然而，在 Windows 中的输出有所不同，如示例 4-12 所示。</a></li>
<li><a href="#示例4-12在windows-7-sp1-巴西版中的cmd-exe中输出的默认编码-powershell">示例4-12在Windows 7 (SP1)巴西版中的cmd.exe中输出的默认编码；PowerShell</a></li>
<li><a href="#o-chcp输出当前控制台激活的代码页-850">O chcp输出当前控制台激活的代码页：850。</a></li>
<li><a href="#运行default-encodings-py-把结果输出到控制台">©运行default_encodings.py，把结果输出到控制台。</a></li>
<li><a href="#locale-getpreferredencoding-是最重要的设置">© locale.getpreferredencoding()是最重要的设置。</a></li>
</ul></li>
<li><a href="#4-6为了正确比较而规范化unicode字符串">4.6为了正确比较而规范化Unicode字符串</a>
<ul>
<li><a href="#此要规范化-防止出现意外">此要规范化，防止出现意外：</a></li>
<li><a href="#在另外两个规范化形式-nfkc和nfkd-的首字母缩略词中-字母k表">在另外两个规范化形式(NFKC和NFKD)的首字母缩略词中，字母K表</a></li>
<li><a href="#下面是-nfkc-的具体应用">下面是 NFKC 的具体应用：</a></li>
<li><a href="#使用-1-2-替代-x-可以接受-微符号也确实是小写的希腊字母-p-但是把-42-转换">使用’1/2&rsquo;替代’X&rsquo;可以接受，微符号也确实是小写的希腊字母’p&rsquo;，但是把’42&rsquo;转换</a></li>
<li><a href="#其中-c3-a3-是utf-8编码-a-字母-带有波形符的-a-转义后得到的结果-下述形">其中，“°%C3°%A3”是UTF-8编码“a”字母(带有波形符的“a”)转义后得到的结果。下述形</a></li>
<li><a href="#如果想把字符串中的所有变音符号都去掉-可以使用示例-4-14-中的函数">如果想把字符串中的所有变音符号都去掉，可以使用示例 4-14 中的函数</a></li>
<li><a href="#示例-4-14-去掉全部组合记号的函数-在-sanitize-py-模块中">示例 4-14 去掉全部组合记号的函数(在 sanitize.py 模块中)</a></li>
<li><a href="#o-把所有字符分解成基字符和组合记号">O 把所有字符分解成基字符和组合记号。</a></li>
<li><a href="#过滤掉所有组合记号">© 过滤掉所有组合记号。</a></li>
<li><a href="#o重组所有字符">o重组所有字符。</a></li>
<li><a href="#o只替换了-和-r三个字符">O只替换了 ％”“?”和“r三个字符。</a></li>
<li><a href="#示例4-16删除拉丁字母中组合记号的函数-import语句省略了-因为这是示例4-14-中定义的-sanitize-py-模块的一部分">示例4-16删除拉丁字母中组合记号的函数(import语句省略了，因为这是示例4-14 中定义的 sanitize.py 模块的一部分)</a></li>
<li><a href="#o-把所有字符分解成基字符和组合记号-1">O 把所有字符分解成基字符和组合记号。</a></li>
<li><a href="#基字符为拉丁字母时-跳过组合记号">© 基字符为拉丁字母时，跳过组合记号。</a></li>
<li><a href="#否则-保存当前字符">© 否则，保存当前字符。</a></li>
<li><a href="#检测新的基字符-判断是不是拉丁字母">© 检测新的基字符，判断是不是拉丁字母。</a></li>
<li><a href="#❺-重组所有字符">❺ 重组所有字符。</a></li>
</ul></li>
<li><a href="#4-7-unicode文本排序">4.7 Unicode文本排序</a></li>
<li><a href="#4-9支持字符串和字节序列的双模式api">4.9支持字符串和字节序列的双模式API</a></li>
<li><a href="#4-10-本章小结">4.10 本章小结</a></li>
<li><a href="#4-11-延伸阅读">4.11 延伸阅读</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h2 id="第-4-章-文本和字节序列">第 4 章 文本和字节序列</h2>

<p>人类使用文本，计算机使用字节序列。 1</p>

<p>——Esther Nam 和 Travis Fischer “Character Encoding and Unicode in Python”</p>

<p>1PyCon 2014，“Character Encoding and Unicode in Python”演讲的第 12 张幻灯片［幻灯片 (<a href="http://www.slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863">http://www.slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863</a>)，视频 ( <a href="http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html">http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html</a>) ］。</p>

<p>Python 3 明确区分了人类可读的文本字符串和原始的字节序列。隐式地把字节序列转换成 Unicode 文本己成过去。本章将要讨论 Unicode 字符串、二进制序列，以及在二者之间转 换时使用的编码。</p>

<p>深入理解 Unicode 对你可能十分重要，也可能无关紧要，这取决于 Python 编程的场景。说 到底，本章涵盖的问题对只处理 ASCII 文本的程序员没有影响。但是即便如此，也不能避 而不谈字符串和字节序列的区别。此外，你会发现专门的二进制序列类型所提供的功能，</p>

<p>有些是 Python 2 中“全功能”的 str 类型不具有的。</p>

<p>本章将讨论下述话题：</p>

<p>•字符、码位和字节表述</p>

<p>•    bytes、bytearray和memoryview等二进制序列的独特特性</p>

<p>•全部Unicode和陈旧字符集的编解码器</p>

<p>•避免和处理编码错误</p>

<p>•处理文本文件的最佳实践</p>

<p>•默认编码的陷阱和标准I/O的问题</p>

<p>•规范化Unicode文本，进行安全的比较</p>

<p>•规范化、大小写折叠和暴力移除音调符号的实用函数</p>

<p>•使用locale模块和PyUCA库正确地排序Unicode文本</p>

<p>•    Unicode数据库中的字符元数据</p>

<p>•能处理字符串和字节序列的双模式API</p>

<p>接下来先从字符、码位和字节序列开始。</p>

<h3 id="4-1-字符问题">4.1 字符问题</h3>

<p>“字符串”是个相当简单的概念：一个字符串是一个字符序列。问题出在“字符”的定义上。</p>

<p>在 2015 年， “字符”的最佳定义是 Unicode 字符。因此，从 Python 3 的 str 对象中获取的 元素是 Unicode 字符，这相当于从 Python 2 的 unicode 对象中获取的元素，而不是从 Python 2 的 str 对象中获取的原始字节序列。</p>

<p>Unicode 标准把字符的标识和具体的字节表述进行了如下的明确区分。</p>

<p>•字符的标识，即码位，是0〜1 114 111的数字（十进制），在Unicode标准中以4〜6 个十六进制数字表示，而且加前缀“U+”。例如，字母A的码位是U+0041，欧元符号 的码位是U+20AC，高音谱号的码位是U+1D11E。在Unicode 6.3中（这是Python 3+4 使用的标准），约 10% 的有效码位有对应的字符。</p>

<p>•字符的具体表述取决于所用的编码。编码是在码位和字节序列之间转换时使用的算</p>

<p>法。在UTF-8编码中，A （U+0041）的码位编码成单个字节\x41，而在UTF-16LE 编码中编码成两个字节\x41\x00。再举个例子，欧元符号（U+20AC）在UTF-8编 码中是三个字节——\xe2\x82\xac，而在UTF-16LE中编码成两个字</p>

<p>节：\xac\x20。</p>

<p>把码位转换成字节序列的过程是编码；把字节序列转换成码位的过程是解码。示例 4-1</p>

<p>阐释了这一区分。</p>

<p>示例 4-1 编码和解码</p>

<p>&gt;&gt;&gt; s = &lsquo;cafe&rsquo;</p>

<p>&gt;&gt;&gt; len(s) # O</p>

<p>4</p>

<p>&gt;&gt;&gt; b = s.encode(&lsquo;utf8&rsquo;) # © &gt;&gt;&gt; b</p>

<p>b&rsquo;caf\xc3\xa9&rsquo; # ©</p>

<p>&gt;&gt;&gt; len(b) # ©</p>

<p>5</p>

<p>&gt;&gt;&gt; b.decode(&lsquo;utf8&rsquo;) # ❺ &lsquo;cafe</p>

<p>❶ &lsquo;cafe&rsquo; 字符串有 4 个 Unicode 字符。</p>

<p>❷ 使用 UTF-8 把 str 对象编码成 bytes 对象。</p>

<p>❸ bytes 字面量以 b 开头。</p>

<p>❹字节序列b有5个字节（在UTF-8中，“6”的码位编码成两个字节）。 ❺ 使用 UTF-8 把 bytes 对象解码成 str 对象。</p>

<p>如果想帮助自己记住.deeode()和.eneode()的区别，可以把字节序列想成 晦涩难懂的机器磁芯转储，把 Unicode 字符串想成“人类可读”的文本。那么，把字节 序列变成人类可读的文本字符串就是解码，而把字符串变成用于存储或传输的字节 序列就是编码。</p>

<p>虽然 Python 3 的 str 类型基本相当于 Python 2 的 unieode 类型，只不过是换了个新名 称，但是 Python 3 的 bytes 类型却不是把 str 类型换个名称那么简单，而且还有关系紧 密的 bytearray 类型。因此，在讨论编码和解码的问题之前，有必要先来介绍一下二进 制序列类型。</p>

<h3 id="4-2-字节概要">4.2 字节概要</h3>

<p>新的二进制序列类型在很多方面与 Python 2 的 str 类型不同。首先要知道， Python 内置了 两种基本的二进制序列类型：Python 3引入的不可变bytes类型和Python 2.6添加的可变 bytearray类型。（Python2.6也引入了 bytes类型，但那只不过是str类型的别名，与 Python 3 的 bytes 类型不同。）</p>

<p>bytes 或 bytearray 对象的各个元素是介于 0~255（含）之间的整数，而不像 Python 2 的 str 对象那样是单个的字符。然而，二进制序列的切片始终是同一类型的二进制序 列，包括长度为 1 的切片，如示例 4-2 所示。</p>

<p>示例 4-2 包含 5 个字节的 bytes 和 bytearray 对象</p>

<p>&gt;&gt;&gt; cafe = bytes(&lsquo;cafe&rsquo;, encoding=&lsquo;utf_8&rsquo;) O</p>

<p>&gt;&gt;&gt; cafe</p>

<p>b&rsquo;caf\xc3\xa9&rsquo;</p>

<p>&gt;&gt;&gt; cafe[0] ©</p>

<p>99</p>

<p>&gt;&gt;&gt; cafe[:1] © b&rsquo;c&rsquo;</p>

<p>&gt;&gt;&gt; cafe_arr = bytearray(cafe)</p>

<p>&gt;&gt;&gt; cafe_arr o bytearray(b&rsquo;caf\xc3\xa9&rsquo;)</p>

<p>&gt;&gt;&gt; cafe_arr[-1:] bytearray(b&rsquo;\xa9&rsquo;)</p>

<p>❶ bytes 对象可以从 str 对象使用给定的编码构建。</p>

<p>❷ 各个元素是 range（256） 内的整数。</p>

<p>❸ bytes 对象的切片还是 bytes 对象，即使是只有一个字节的切片。</p>

<p>❹ bytearray 对象没有字面量句法，而是以 bytearray（） 和字节序列字面量参数的形式</p>

<p>显示。</p>

<p>❺ bytearray 对象的切片还是 bytearray 对象。</p>

<p>my_bytes[0]获取的是一个整数，而my_bytes[:1]返回的是一个长度为1 的 bytes 对象——这一点应该不会让人意外。 s[0] == s[:1] 只对 str 这个序列类 型成立。不过， str 类型的这个行为十分罕见。对其他各个序列类型来说， s[i] 返 回一个元素，而 s[i:i+1] 返回一个相同类型的序列，里面是 s[i] 元素。</p>

<p>虽然二进制序列其实是整数序列，但是它们的字面量表示法表明其中有 ASCII 文本。因 此，各个字节的值可能会使用下列三种不同的方式显示。</p>

<p>•可打印的ASCII范围内的字节（从空格到~），使用ASCII字符本身。</p>

<p>•制表符、换行符、回车符和\对应的字节，使用转义序列\t、\n、\r和\。</p>

<p>•其他字节的值，使用十六进制转义序列（例如，\x00是空字节）。</p>

<p>因此，在示例4-2中，我们看到的是b&rsquo;eaf\xe3\xa9&rsquo;:前3个字节b&rsquo;eaf&rsquo;在可打印的 ASCII 范围内，后两个字节则不然。</p>

<p>除了格式化方法（format和format_map）和几个处理Unicode数据的方法（包括 easefold、 isdeeimal、 isidentifier、 isnumerie、 isprintable 和 eneode）之 外， str 类型的其他方法都支持 bytes 和 bytearray 类型。这意味着，我们可以使用熟 悉的字符串方法处理二进制序列，如 endswith、 replaee、 strip、 translate、 upper 等，只有少数几个其他方法的参数是 bytes 对象，而不是 str 对象。此外，如果正则表 达式编译自二进制序列而不是字符串， re 模块中的正则表达式函数也能处理二进制序 列。Python 3.0~3.4不能使用％运算符处理二进制序列，但是根据“PEP 461 —Adding % formatting to bytes and bytearray” （ <a href="https://www.python.org/dev/peps/pep-0461/">https ://www.python.org/dev/peps/pep-046 1/</a> ） ， Python 3.5 应该会支持。</p>

<p>二进制序列有个类方法是str没有的，名为fromhex，它的作用是解析十六进制数字对 （数字对之间的空格是可选的），构建二进制序列：</p>

<p>&gt;&gt;&gt; bytes.fromhex(&lsquo;31 4B CE A9&rsquo;) b&rsquo;1K\xee\xa9&rsquo;</p>

<p>构建 bytes 或 bytearray 实例还可以调用各自的构造方法，传入下述参数。</p>

<p>•    一个str对象和一个eneoding关键字参数。</p>

<p>•    一个可迭代对象，提供0〜255之间的数值。</p>

<p>•    一个整数，使用空字节创建对应长度的二进制序列。[Python 3.5会把这个构造方法标 记为“过时的”，Python 3.6 会将其删除。参见“PEP 467—Minor API improvements for binary sequences” （<a href="https://www.python.org/dev/peps/pep-0467/）">https://www.python.org/dev/peps/pep-0467/）</a> 。 ]</p>

<p>-一个实现了缓冲协议的对象（如</p>

<p>bytes、bytearray、memoryview、array.array）;此时，把源对象中的字节序</p>

<p>列复制到新建的二进制序列中。</p>

<p>使用缓冲类对象构建二进制序列是一种低层操作，可能涉及类型转换。示例 4-3 做了演 示。</p>

<p>示例 4-3 使用数组中的原始数据初始化 bytes 对象</p>

<p>&gt;&gt;&gt; import array</p>

<p>&gt;&gt;&gt; numbers = array.array(&lsquo;h&rsquo;, [-2, -1, 0, 1, 2]) O &gt;&gt;&gt; oetets = bytes(numbers) &amp;</p>

<p>&gt;&gt;&gt; oetets</p>

<p>b&rsquo;\xfe\xff\xff\xff\x00\x00\x01\x00\x02\x00&rsquo; ©</p>

<p>O指定类型代码h，创建一个短整数(16位)数组。</p>

<p>© octets 保存组成 numbers 的字节序列的副本。</p>

<p>© 这些是表示那 5 个短整数的 10 个字节。</p>

<p>使用缓冲类对象创建 bytes 或 bytearray 对象时，始终复制源对象中的字节序列。与之</p>

<p>相反， memoryview 对象允许在二进制数据结构之间共享内存。如果想从二进制序列中提</p>

<p>取结构化信息， struct 模块是重要的工具。下一节会使用这个模块处理 bytes 和</p>

<p>memoryview 对象。</p>

<p>结构体和内存视图</p>

<p>struct 模块提供了一些函数，把打包的字节序列转换成不同类型字段组成的元组，还有 一些函数用于执行反向转换，把元组转换成打包的字节序列。 struct 模块能处理 bytes、bytearray 和 memoryview 对象。</p>

<p>如 2.9.2 节所述， memoryview 类不是用于创建或存储字节序列的，而是共享内存，让你 访问其他二进制序列、打包的数组和缓冲中的数据切片，而无需复制字节序列，例如 Python Imaging Library(PIL) 2 就是这样处理图像的。</p>

<p>| 2Pillow (<a href="https://pillow.readthedocs.org/en/latest/">https://pillow+readthedocs+org/en/latest/</a>)是 PIL 最活跃的派生库。</p>

<p>示例 4-4 展示了如何使用 memoryview 和 struct 提取一个 GIF 图像的宽度和高度。</p>

<p>示例 4-4 使用 memoryview 和 struct 查看一个 GIF 图像的首部</p>

<p>&gt;&gt;&gt; import struct</p>

<p>&gt;&gt;&gt; fmt = &lsquo;&lt;3s3sHH&rsquo;    # O</p>

<p>&gt;&gt;&gt; with open(&lsquo;filter.gif&rsquo;, &lsquo;rb&rsquo;) as fp:</p>

<p>&hellip; img = memoryview(fp.read()) # ©</p>

<p>&gt;&gt;&gt; header = img[:10] # ©</p>

<p>&gt;&gt;&gt; bytes(header) # © b&rsquo;GIF89a+\x02\xe6\x00&rsquo;</p>

<p>&gt;&gt;&gt; struct.unpack(fmt, header) # ❺ (b&rsquo;GIF&rsquo;, b&rsquo;89a&rsquo;, 555, 230)</p>

<p>&gt;&gt;&gt; del header #</p>

<p>&gt;&gt;&gt; del img</p>

<p>❶ 结构体的格式： &lt; 是小字节序， 3s3s 是两个 3 字节序列， HH 是两个 16 位二进制整 数。</p>

<p>❷ 使用内存中的文件内容创建一个 memoryview 对象……</p>

<p>❸ ……然后使用它的切片再创建一个 memoryview 对象；这里不会复制字节序列。</p>

<p>❹ 转换成字节序列，这只是为了显示；这里复制了 10 字节。</p>

<p>❺ 拆包 memoryview 对象，得到一个元组，包含类型、版本、宽度和高度。</p>

<p>❻ 删除引用，释放 memoryview 实例所占的内存。</p>

<p>注意， memoryview 对象的切片是一个新 memoryview 对象，而且不会复制字节序列。 [ 本书的技术审校之一 Leonardo Rochael 指出，如果使用 mmap 模块把图像打开为内存映射 文件，那么会复制少量字节。本书不会讨论mmap，如果你经常读取和修改二进制文件，</p>

<p>可以阅读“ mmap—Memory-mapped file</p>

<p>support” (<a href="https://docs.python.org/3/library/mmap.html">https://docs.python.org/3/library/mmap.html</a>)来进一步学习。]</p>

<p>本书不会深入介绍 memoryview 和 struct 模块，如果要处理二进制数据，可以阅读它们 的文档： “Built-in Types » Memory</p>

<p>Views” (<a href="https://docs.python.org/3/library/stdtypes.html%23memory-views">https://docs.python.org/3/library/stdtypes.html#memory-views</a>)和“struct—Interpret bytes as packed binary data” (<a href="https://docs.python.org/3/library/struct.html">https://docs.python.org/3/library/struct.html</a>) 。</p>

<p>简要探讨 Python 的二进制序列类型之后，下面说明如何在它们和字符串之间转换。</p>

<h3 id="4-3-基本的编解码器">4.3 基本的编解码器</h3>

<p>Python自带了超过100种编解码器(codec, encoder/decoder)，用于在文本和字节之间相 互转换。每个编解码器都有一个名称，如’utf_8&rsquo;，而且经常有几个别名，如 &lsquo;utf8&rsquo;、&rsquo;utf-8•和’U8&rsquo;。这些名称可以传给</p>

<p>open()、 str.encode()、 bytes.decode() 等函数的 encoding 参数。示例 4-5 使用 3 个编解码器把相同的文本编码成不同的字节序列。</p>

<p>示例4-5使用3个编解码器编码字符串“El Nino”，得到的字节序列差异很大</p>

<p>&gt;&gt;&gt; for codec in [&lsquo;latin_1&rsquo;, &lsquo;utf_8&rsquo;, &lsquo;utf_16&rsquo;]:</p>

<p>… print(codec, &lsquo;El Nino&rsquo;.encode(codec), sep=&rsquo;\t&rsquo;)</p>

<p>latin_1 b&rsquo;El Ni\xf1o&rsquo; utf_8 b&rsquo;El Ni\xc3\xb1o&rsquo;</p>

<p>utf 16 b&rsquo;\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00&rsquo;</p>

<p>图4-1展示了不同编解码器对“A”和高音谱号等字符编码后得到的字节序列。注意，后3 种是可变长度的多字节编码。</p>

<p>图 4-1： 12 个字符，它们的码位及不同编码的字节表述(十六进制，星号表明该编 码不支持表示该字符)</p>

<p>图4-1中的星号表明，某些编码(如ASCII和多字节的GB2312)不能表示所有Unicode 字符。然而， UTF 编码的设计目的就是处理每一个 Unicode 码位。</p>

<p>图 4-1 中展示的是一些典型编码，介绍如下。</p>

<p>latinl (即 iso8859_1)</p>

<p>一种重要的编码，是其他编码的基础，例如ep1252和Unicode (注意，latinl与 ep1252 的字节值是一样的，甚至连码位也相同)。</p>

<p>ep1252</p>

<p>Microsoft 制定的 latin1 超集，添加了有用的符号，例如弯引号和€(欧元)；有些 Windows应用把它称为“ANSI”，但它并不是ANSI标准。 ep437</p>

<p>IBM PC 最初的字符集，包含框图符号。与后来出现的 latin1 不兼容。 gb2312</p>

<p>用于编码简体中文的陈旧标准；这是亚洲语言中使用较广泛的多字节编码之一。</p>

<p>utf-8</p>

<p>目前 Web 中最常见的 8 位编码；3 与 ASCII 兼容(纯 ASCII 文本是有效的 UTF-8 文 本)。</p>

<p>3W3Techs 发布的&rsquo;“Usage of character encodings for</p>

<p>websites” (<a href="https://w3techs.com/technologies/overview/character_encoding/all">https://w3techs.com/technologies/overview/character_encoding/all</a>)报告指出，截至 2014 年 9 月，81.4% 的网站 使用 UTF-8;而 Built With 发布的&rdquo;“Encoding Usage Statistics”(<a href="http://trends.builtwith.com/encoding">http://trends.builtwith.com/encoding</a>)估计的比例则是 79.4%。</p>

<p>utf-16le</p>

<p>UTF-16 的 16 位编码方案的一种形式；所有 UTF-16 支持通过转义序列(称为“代理 对”，surrogate pair)表示超过U+FFFF的码位。</p>

<p>UTF-16取代了 1996年发布的Unicode 1.0编码(UCS-2)。这个编码在很多 系统中仍在使用，但是支持的最大码位是U+FFFF。从Unicode 6.3起，分配的码位中 有超过50%。在U+10000以上，包括逐渐流行的表情符号(emoji pictograph)。</p>

<p>概述常规的编码之后，下面要处理编码和解码过程中存在的问题。</p>

<h3 id="4-4-了解编解码问题">4.4 了解编解码问题</h3>

<p>虽然有个一般性的 UnicodeError 异常，但是报告错误时几乎都会指明具体的异</p>

<p>常：UnicodeEncodeError （把字符串转换成二进制序列时）或</p>

<p>UnicodeDecodeError （把二进制序列转换成字符串时）。如果源码的编码与预期不符， 加载Python模块时还可能抛出SyntaxError。接下来的几节说明如何处理这些错误。</p>

<h4 id="出现与unicode有关的错误时-首先要明确异常的类型-导致编码问题的是-unicodeencodeerror-unicodedecodeerror-还是如-syntaxerror-的其他错">出现与Unicode有关的错误时，首先要明确异常的类型。导致编码问题的是 UnicodeEncodeError、UnicodeDecodeError，还是如 SyntaxError 的其他错</h4>

<p>误？解决问题之前必须清楚这一点。</p>

<p>4.4.1 处理 UnicodeEncodeError</p>

<p>多数非 UTF 编解码器只能处理 Unicode 字符的一小部分子集。把文本转换成字节序列 时，如果目标编码中没有定义某个字符，那就会抛出 UnicodeEncodeError 异常，除非 把 errors 参数传给编码方法或函数，对错误进行特殊处理。处理错误的方式如示例 4-6</p>

<p>所示。</p>

<p>示例 4-6 编码成字节序列：成功和错误处理</p>

<p>&gt;&gt;&gt; city = &lsquo;Sao Paulo&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;utf_8&rsquo;) O b&rsquo;S\xc3\xa3o Paulo&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;utf_16&rsquo;)</p>

<p>b&rsquo;\xff\xfeS\x00\xe3\x00o\x00 \x00P\x00a\x00u\x00l\x00o\x00&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;iso8859_1&rsquo;) © b&rsquo;S\xe3o Paulo&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;cp437&rsquo;) ©</p>

<p>Traceback (most recent call last):</p>

<p>File &ldquo;<stdin>&rdquo;, line 1, in <module></p>

<p>File &ldquo;/&hellip;/lib/python3.4/encodings/cp437.py&rdquo;, line 12, in encode return codecs.charmap_encode(input,errors,encoding_map) UnicodeEncodeError: &lsquo;charmap&rsquo; codec can&rsquo;t encode character &lsquo;\xe3&rsquo; in position 1: character maps to <undefined></p>

<p>&gt;&gt;&gt; city.encode(&lsquo;cp437&rsquo;, errors=&lsquo;ignore&rsquo;) o b&rsquo;So Paulo&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;cp437&rsquo;, errors=&lsquo;replace&rsquo;)❺ b&rsquo;S?o Paulo&rsquo;</p>

<p>&gt;&gt;&gt; city.encode(&lsquo;cp437&rsquo;, errors=&lsquo;xmlcharrefreplace&rsquo;) © b&rsquo;Sao Paulo&rsquo;</p>

<p>❶ &lsquo;utf_?&rsquo; 编码能处理任何字符串。</p>

<p>❷ &lsquo;iso8859_1&rsquo; 编码也能处理字符串 &lsquo;Sao Paulo&rsquo;。</p>

<h4 id="❸-cp437-无法编码-a-带波形符的-a-默认的错误处理方式-strict-抛出-unicodeencodeerror">❸&rsquo;cp437&rsquo;无法编码’a&rsquo;（带波形符的“a”）。默认的错误处理方式&rsquo;strict&rsquo;抛出 UnicodeEncodeError。</h4>

<p>❹ error=&lsquo;ignore&rsquo; 处理方式悄无声息地跳过无法编码的字符；这样做通常很是不妥。</p>

<p>❺编码时指定error=&lsquo;replace&rsquo;，把无法编码的字符替换成’？’；数据损坏了，但是用</p>

<p>户知道出了问题。</p>

<p>❻ &lsquo;xmlcharrefreplace&rsquo; 把无法编码的字符替换成 XML 实体。</p>

<p><img src="08414584Python-25.jpg" alt="img" /></p>

<p>编解码器的错误处理方式是可扩展的。你可以为errors参数注册额外的字符 串，方法是把一个名称和一个错误处理函数传给 codecs.register_error 函数。</p>

<p>参见 codecs.register_error 函数的文档 (<a href="https://docs.python.org/3/library/codecs.html%23codecs.register_error">https://docs+python+org/3/library/codecs+html#codecs+register_error</a>) 。</p>

<p>4.4.2 处理 UnicodeDecodeError</p>

<p>不是每一个字节都包含有效的 ASCII 字符，也不是每一个字符序列都是有效的 UTF-8 或 UTF-16。因此，把二进制序列转换成文本时，如果假设是这两个编码中的一个，遇到无 法转换的字节序列时会抛出 UnicodeDecodeError。</p>

<p>另一方面，很多陈旧的8位编码——如&rsquo;cp1252&rsquo;、&rsquo;iso8859_1&rsquo;和’koi8_r&rsquo;——能解</p>

<p>码任何字节序列流而不抛出错误，例如随机噪声。因此，如果程序使用错误的 8 位编码， 解码过程悄无声息，而得到的是无用输出。</p>

<p><img src="08414584Python-26.jpg" alt="img" /></p>

<p>乱码字符称为鬼符(gremlin)或mojibake (文字化什，“变形文本”的日文)。 示例 4-7 演示了使用错误的编解码器可能出现鬼符或抛出 UnicodeDecodeError。 示例 4-7 把字节序列解码成字符串：成功和错误处理</p>

<p>&lsquo;MontrMal&rsquo;</p>

<p>&gt;&gt;&gt; octets.decode(&lsquo;utf_8&rsquo;)❺</p>

<p>Traceback (most recent call last):</p>

<p>File &ldquo;<stdin>&rdquo;, line 1, in <module></p>

<p>UnicodeDecodeError: &lsquo;utf-8&rsquo; codec can&rsquo;t decode byte 0xe9 in position 5: invalid continuation byte</p>

<p>&gt;&gt;&gt; octets.decode(&lsquo;utf_8&rsquo;, errors=&lsquo;replace&rsquo;)    ©</p>

<p>&lsquo;Montral&rsquo;</p>

<p>❶这些字节序列是使用latinl编码的“Montreal”； ’ \xe9&rsquo;字节对应1”。</p>

<p>❷ 可以使用 &lsquo;cp1252&rsquo; (Windows 1252)解码，因为它是 latin1 的有效超集。</p>

<p>❸ ISO-8859-7 用于编码希腊文，因此无法正确解释 &lsquo;\xe9&rsquo; 字节，而且没有抛出错误。</p>

<p>❹KOI8-R用于编码俄文；这里，&rsquo;\xe9 &lsquo;表示西里尔字母“H”。</p>

<p>❺ &lsquo;utf_8&rsquo; 编解码器检测到 oetets 不是有效的 UTF-8 字符串，抛出</p>

<p>UnieodeDeeodeError。</p>

<p>❻使用’replaee&rsquo;错误处理方式，\xe9替换成了“分’（码位是U+FFFD），这是官方指 定的REPLACEMENT CHARACTER （替换字符），表示未知字符。</p>

<p>4.4.3使用预期之外的编码加载模块时抛出的SyntaxError</p>

<p>Python 3默认使用UTF-8编码源码，Python 2 （从2.5开始）则默认使用ASCII。如果加载 的 .py 模块中包含 UTF-8 之外的数据，而且没有声明编码，会得到类似下面的消息：</p>

<p>SyntaxError: Non-UTF-8 eode starting with &lsquo;\xe1&rsquo; in file ola.py on line 1, but no eneoding deelared; see <a href="http://python.org/dev/peps/pep-0263/">http://python.org/dev/peps/pep-0263/</a> for details</p>

<p>GNU/Linux和OS X系统大都使用UTF-8，因此打开在Windows系统中使用ep1252编码 的 .py 文件时可能发生这种情况。注意，这个错误在 Windows 版 Python 中也可能会发 生，因为 Python 3 为所有平台设置的默认编码都是 UTF-8。</p>

<p>为了修正这个问题，可以在文件顶部添加一个神奇的 eoding 注释，如示例 4-8 所示。</p>

<p>示例 4-8 ola.py： “你好，世界！”的葡萄牙语版</p>

<p># eoding: ep1252 print(&lsquo;Ola, Mundo!&rsquo;)</p>

<p>现在，Python 3的源码不再限于使用ASCII，而是默认使用优秀的UTF-8编 码，因此要修正源码的陈旧编码（如’ep1252&rsquo;）问题，最好将其转换成UTF-8，别 去麻烦eoding注释。如果你用的编辑器不支持UTF-8,那么是时候换一个了。 源码中能不能使用非 ASCII 名称</p>

<p>Python 3 允许在源码中使用非 ASCII 标识符：</p>

<table>
<thead>
<tr>
<th>&gt;&gt;&gt; aqao</th>
<th>= &lsquo;PBR&rsquo;</th>
<th># aqao</th>
<th>= stoek</th>
</tr>
</thead>

<tbody>
<tr>
<td>&gt;&gt;&gt; £ =</td>
<td>10**-6</td>
<td># £ =</td>
<td>epsilon</td>
</tr>
</tbody>
</table>

<p>有些人不喜欢这么做。支持始终使用 ASCII 标识符的人认为，这样便于所有人阅读和 编辑代码。这些人没切中要害：源码应该便于目标群体阅读和编辑，而不是“所有</p>

<p>人”。如果代码属于跨国公司，或者是开源的，想让来自世界各地的人作贡献，那么 标识符应该使用英语，也就是说只能使用 ASCII 字符。</p>

<p>但是，如果你是巴西的一位老师，那么使用葡萄牙语正确拼写变量和函数名更便于学</p>

<p>生阅读代码。而且，这些学生在本地化的键盘中不难打出变音符号和重音元音字母。</p>

<p>现在，Python能解析Unicode名称，而且源码的默认编码是UTF-8,我觉得没有任何 理由使用不带重音符号的葡萄牙语编写标识符。在 Python 2 中确实不能这么做，除非</p>

<p>你也想使用 Python 2 运行代码，否则不必如此。如果使用葡萄牙语命名标识符却不带</p>

<p>重音符号的话，这样写出的代码对任何人来说都不易阅读。</p>

<p>这是我作为说葡萄牙语的巴西人的观点，不过我相信也适用于其他国家和文化：选择</p>

<p>对团队而言易于阅读的人类语言，然后使用正确的字符拼写。</p>

<p>假如有个文本文件，里面保存的是源码或诗句，但是你不知道它的编码。如何查明真正的</p>

<p>编码呢？下一节使用一个推荐的库回答这个问题。</p>

<p>4.4.4 如何找出字节序列的编码</p>

<p>如何找出字节序列的编码？简单来说，不能。必须有人告诉你。</p>

<p>有些通信协议和文件格式，如HTTP和XML，包含明确指明内容编码的首部。可以肯定 的是，某些字节流不是ASCII，因为其中包含大于127的字节值，而且制定UTF-8和 UTF-16 的方式也限制了可用的字节序列。不过即便如此，我们也不能根据特定的位模式 来 100% 确定二进制文件的编码是 ASCII 或 UTF-8。</p>

<p>然而，就像人类语言也有规则和限制一样，只要假定字节流是人类可读的纯文本，就可能 通过试探和分析找出编码。例如，如果 b&rsquo;\x00&rsquo; 字节经常出现，那么可能是 16 位或 32 位编码，而不是 8 位编码方案，因为纯文本中不能包含空字符；如果字节序列 b&rsquo;\x20\x00&rsquo;经常出现，那么可能是UTF-16LE编码中的空格字符(U+0020)，而不是 鲜为人知的 U+2000 EN QUAD 字符——谁知道这是什么呢！</p>

<p>统一字符编码侦测包Chardet (<a href="https://pypi.python.org/pypi/chardet">https://pypi.python.org/pypi/chardet</a>)就是这样工作的，它能 识别所支持的 30 种编码。 Chardet 是一个 Python 库，可以在程序中使用，不过它也提供了 命令行工具chardetect。下面是它对本章书稿文件的检测报告：</p>

<p>$ chardetect 04-text-byte.asciidoc 04-text-byte.asciidoc: utf-8 with confidence 0.99</p>

<p>二进制序列编码文本通常不会明确指明自己的编码，但是 UTF 格式可以在文本内容的开 头添加一个字节序标记。参见下一节。</p>

<p>4.4.5 BOM:有用的鬼符</p>

<p>在示例 4-5 中，你可能注意到了， UTF-16 编码的序列开头有几个额外的字节，如下所</p>

<p>示:</p>

<p>&gt;&gt;&gt; u16 = &lsquo;El Nino&rsquo;.eneode(&lsquo;utf_16&rsquo;)</p>

<p>&gt;&gt;&gt; u16</p>

<p>b&rsquo;\xff\xfeE\x00l\x00 \x00N\x00i\x00\xf1\x00o\x00&rsquo;</p>

<p>我指的是b&rsquo; \xff\xfe &lsquo;。这是BOM，即字节序标记（byte-order mark），指明编码时使 用 Intel CPU 的小字节序。</p>

<p>在小字节序设备中，各个码位的最低有效字节在前面：字母’E&rsquo;的码位是U+0045 （十进 制数 69），在字节偏移的第 2 位和第 3 位编码为 69 和 0。</p>

<p>&gt;&gt;&gt; list(u16)</p>

<p>[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]</p>

<p>在大字节序CPU中，编码顺序是相反的；’E&rsquo;编码为0和69。</p>

<p>为了避免混淆， UTF-16 编码在要编码的文本前面加上特殊的不可见字符 ZERO WIDTH NO-BREAK SPACE （U+FEFF）。在小字节序系统中，这个字符编码为b&rsquo;\xff\xfe•（十 进制数 255, 254）。因为按照设计， U+FFFE 字符不存在，在小字节序编码中，字节序列</p>

<p>b&rsquo;\xff\xfe&rsquo;必定是ZERO WIDTH NO-BREAK SPACE，所以编解码器知道该用哪个字节</p>

<p>序。</p>

<p>UTF-16有两个变种：UTF-16LE，显式指明使用小字节序；UTF-16BE，显式指明使用大 字节序。如果使用这两个变种，不会生成 BOM：</p>

<p>&gt;&gt;&gt; u16le = &lsquo;El Nino&rsquo;.eneode(&lsquo;utf_16le&rsquo;)</p>

<p>&gt;&gt;&gt; list(u16le)</p>

<p>[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0] &gt;&gt;&gt; u16be = &lsquo;El Nino&rsquo;.eneode(&lsquo;utf_16be&rsquo;)</p>

<p>&gt;&gt;&gt; list(u16be)</p>

<p>[0, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111]</p>

<p>如果有 BOM， UTF-16 编解码器会将其过滤掉，为你提供没有前导 ZERO WIDTH NOBREAK SPACE 字符的真正文本。根据标准，如果文件使用 UTF-16 编码，而且没有 BOM，那么应该假定它使用的是UTF-16BE （大字节序）编码。然而，Intel x86架构用的 是小字节序，因此有很多文件用的是不带 BOM 的小字节序 UTF-16 编码。</p>

<p>与字节序有关的问题只对一个字（word）占多个字节的编码（如UTF-16和UTF-32）有 影响。 UTF-8 的一大优势是，不管设备使用哪种字节序，生成的字节序列始终一致，因此 不需要BOM。尽管如此，某些Windows应用（尤其是Notepad）依然会在UTF-8编码的 文件中添加BOM;而且，Excel会根据有没有BOM确定文件是不是UTF-8编码，否则， 它假设内容使用Windows代码页（codepage）编码。UTF-8编码的U+FEFF字符是一个三 字节序列： b&rsquo;\xef\xbb\xbf&rsquo; 。因此，如果文件以这三个字节开头，有可能是带有 BOM 的 UTF-8 文件。然而， Python 不会因为文件以 b&rsquo;\xef\xbb\xbf&rsquo; 开头就自动假定它是 UTF-8 编码的。</p>

<p>下面换个话题，讨论 Python 3 处理文本文件的方式。</p>

<h3 id="4-5-处理文本文件">4.5 处理文本文件</h3>

<p>处理文本的最佳实践是“Unicode三明治”(如图4-2所示)。4意思是，要尽早把输入(例 如读取文件时)的字节序列解码成字符串。这种三明治中的“肉片”是程序的业务逻辑，在 这里只能处理字符串对象。在其他处理过程中，一定不能编码或解码。对输出来说，则要 尽量晚地把字符串编码成字节序列。多数 Web 框架都是这样做的，使用框架时很少接触 字节序列。例如，在Django中，视图应该输出Unicode字符串；Django会负责把响应编 码成字节序列，而且默认使用 UTF-8 编码。</p>

<p>Uni code三明治</p>

<p>4我第一次见到‘“Unicode三明治”这种说法是在Ned Batchelder在US PyCon 2012上所做的精彩演讲中：“Pragmatic Unicode”(<a href="http://nedbatchelder.com/text/unipain/unipain.html">http://nedbatchelder.com/text/unipain/unipain.html</a>)。</p>

<p>0</p>

<p>//</p>

<p>-te -&gt;str</p>

<p>解码输入的字节序列，</p>

<p>只处理文本，</p>

<p>编码输出的文本。</p>

<p>\1007. str</p>

<p>图 4-2:Unicode 三明治——目前处理文本的最佳实践</p>

<p>在 Python 3 中能轻松地采纳 Unicode 三明治的建议，因为内置的 open 函数会在读取文件 时做必要的解码，以文本模式写入文件时还会做必要的编码，所以调用 my_file.read() 方法得到的以及传给 my_file.write(text) 方法的都是字符串对象。 5</p>

<p>5Python2.6或Python 2.7用户要使用io.open()函数才能得到读写文件时自动执行的解码和编码操作。</p>

<p>可以看出，处理文本文件很简单。但是，如果依赖默认编码，你会遇到麻烦。</p>

<p>看一下示例 4-9 中的控制台会话。你能发现问题吗？</p>

<p>示例 4-9 一个平台上的编码问题(如果在你的机器上运行，它可能会发生，也可能 不会)</p>

<h4 id="问题是-写入文件时指定了-utf-8-编码-但是读取文件时没有这么做-因此-python-假定-要使用系统默认的编码-windows-1252-于是文件的最后一个字节解码成了字符">问题是：写入文件时指定了 UTF-8 编码，但是读取文件时没有这么做，因此 Python 假定 要使用系统默认的编码(Windows 1252)，于是文件的最后一个字节解码成了字符</h4>

<p>&lsquo;A©&rsquo;，而不是&rsquo;e&rsquo;。</p>

<p>我是在 Windows 7 中运行示例 4-9 的。在新版 GNU/Linux 或 Mac OS X 中运行同样的语句 不会出问题，因为这几个操作系统的默认编码是UTF-8,让人误以为一切正常。如果打开 文件是为了写入，但是没有指定编码参数，会使用区域设置中的默认编码，而且使用那个 编码也能正确读取文件。但是，如果脚本要生成文件，而字节的内容取决于平台或同一平</p>

<p>台中的区域设置，那么就可能导致兼容问题。</p>

<p><img src="08414584Python-28.jpg" alt="img" /></p>

<p>需要在多台设备中或多种场合下运行的代码，一定不能依赖默认编码。打开文 件时始终应该明确传入 encoding= 参数，因为不同的设备使用的默认编码可能不 同，有时隔一天也会发生变化。</p>

<p>示例 4-9 中有个奇怪的细节：第一个语句中的 write 函数报告写入了 4 个字符，但是下 一行读取时却得到了 5 个字符。示例 4-10 是对示例 4-9 的扩展，对这个问题以及其他细 节做了说明。</p>

<p>示例 4-10 仔细分析在 Windows 中运行的示例 4-9，找出并修正问题</p>

<p>&gt;&gt;&gt; fp = open(&lsquo;cafe.txt&rsquo;, &lsquo;w&rsquo;, encoding=&lsquo;utf_8&rsquo;)</p>

<p>&gt;&gt;&gt; fp o</p>

<p>&lt;_io.TextIOWrapper name=&lsquo;cafe.txt&rsquo; mode=&lsquo;w&rsquo; encoding=&lsquo;utf_8&rsquo;&gt; &gt;&gt;&gt; fp.write(&lsquo;cafe&rsquo;)</p>

<p>4 ©</p>

<p>&gt;&gt;&gt; fp.close()</p>

<p>&gt;&gt;&gt; import os</p>

<p>&gt;&gt;&gt; os.stat(&lsquo;cafe.txt&rsquo;).st_size</p>

<p>5 ©</p>

<p>&gt;&gt;&gt; fp2 = open(&lsquo;cafe.txt&rsquo;)</p>

<p>&gt;&gt;&gt; fp2 ©</p>

<p>&lt;_io.TextIOWrapper name=&lsquo;cafe.txt&rsquo; mode=&lsquo;r&rsquo; encoding=&lsquo;cp1252&rsquo;&gt; &gt;&gt;&gt; fp2.encoding ❺</p>

<p>&lsquo;cp1252&rsquo;</p>

<p>&gt;&gt;&gt; fp2.read()</p>

<p>&lsquo;cafA©&rsquo; ©</p>

<p>&gt;&gt;&gt; fp3 = open(&lsquo;cafe.txt&rsquo;, encoding=&lsquo;utf_8&rsquo;) O &gt;&gt;&gt; fp3</p>

<p>&lt;_io.TextIOWrapper name=&lsquo;cafe.txt&rsquo; mode=&lsquo;r&rsquo; encoding=&lsquo;utf_8&rsquo;&gt; &gt;&gt;&gt; fp3.read()</p>

<p>&lsquo;cafe&rsquo; ©</p>

<p>&gt;&gt;&gt; fp4 = open(&lsquo;cafe.txt&rsquo;, &lsquo;rb&rsquo;)    0</p>

<p>&gt;&gt;&gt; fp4</p>

<p>&lt;_io.BuferedReader name=&rsquo; cafe.txt&rsquo; &gt;    ©</p>

<p>&gt;&gt;&gt; fp4.read() ® b&rsquo;caf\xc3\xa9&rsquo;</p>

<p>❶ 默认情况下， open 函数采用文本模式，返回一个 TextIOWrapper 对象。</p>

<p>❷ 在 TextIOWrapper 对象上调用 write 方法返回写入的 Unicode 字符数。</p>

<p>❸os.stat报告文件中有5个字节；UTF-8编码的W占两个字节，0xc3和0xa9。</p>

<p>❹ 打开文本文件时没有显式指定编码，返回一个 TextIOWrapper 对象，编码是区域设置 中的默认值。</p>

<p>❺ TextIOWrapper 对象有个 eneoding 属性；查看它，发现这里的编码是 ep1252。</p>

<p>❻在Windows ep1252编码中，0xc3字节是“A”（带波形符的A），0xa9字节是版权符 号。</p>

<p>❼ 使用正确的编码打开那个文件。</p>

<p>❽结果符合预期：得到的是四个Unicode字符’eafe&rsquo;。</p>

<p>❾ &lsquo;rb&rsquo; 标志指明在二进制模式中读取文件。</p>

<p>❿ 返回的是 BufferedReader 对象，而不是 TextIOWrapper 对象。</p>

<p>©读取返回的字节序列，结果与预期相符。</p>

<p>S除非想判断编码，否则不要在二进制模式中打开文本文件；即便如此，也应该 使用Chardet，而不是重新发明轮子（参见4.4.4节）。常规代码只应该使用二进制模 式打开二进制文件，如光栅图像。</p>

<p>示例 4-10 的问题是，打开文本文件时依赖默认设置。默认设置有许多来源，参见下一 节。</p>

<p>编码默认值：一团糟</p>

<p>有几个设置对 Python I/O 的编码默认值有影响，如示例 4-11 中的 default_encodings.py 脚本</p>

<p>所示。</p>

<p>示例 4-11 探索编码默认值</p>

<p>import sys, loeale</p>

<p>expressions = &ldquo;&rdquo;&rdquo;</p>

<p>loeale.getpreferredeneoding()</p>

<p>type(my_file)</p>

<p>my_file.eneoding</p>

<p>sys.stdout.isatty()</p>

<p>sys.stdout.eneoding</p>

<p>sys.stdin.isatty()</p>

<p>sys.stdin.eneoding</p>

<p>sys.stderr.isatty()</p>

<p>sys.stderr.eneoding</p>

<p>sys.getdefaulteneoding()</p>

<p>sys.getfilesystemencoding()</p>

<p>my_file = open(&lsquo;dummy&rsquo;, &lsquo;w&rsquo;)</p>

<p>for expression in expressions.split(): value = eval(expression)</p>

<p>print(expression.rjust(30), &lsquo;-&gt;&rsquo;, repr(value))</p>

<h4 id="示例-4-11-在-gnu-linux-ubuntu-14-04-和-os-x-mavericks-10-9-中的输出一样-表明这">示例 4-11 在 GNU/Linux (Ubuntu 14.04)和 OS X(Mavericks 10.9)中的输出一样，表明这</h4>

<p>些系统中始终使用 UTF-8:</p>

<p>$ python3 default_encodings.py locale.getpreferredencoding() -&gt; &lsquo;UTF-8&rsquo;</p>

<p>type(my_file) -&gt; <class '_io.TextIOWrapper'> my_file.encoding -&gt; &lsquo;UTF-8&rsquo; sys.stdout.isatty() -&gt; True sys.stdout.encoding -&gt; &lsquo;UTF-8&rsquo; sys.stdin.isatty() -&gt; True sys.stdin.encoding -&gt; &lsquo;UTF-8&rsquo; sys.stderr.isatty() -&gt; True sys.stderr.encoding -&gt; &lsquo;UTF-8&rsquo; sys.getdefaultencoding() -&gt; &lsquo;utf-8&rsquo; sys.getfilesystemencoding() -&gt; &lsquo;utf-8&rsquo;</p>

<h4 id="然而-在-windows-中的输出有所不同-如示例-4-12-所示">然而，在 Windows 中的输出有所不同，如示例 4-12 所示。</h4>

<h4 id="示例4-12在windows-7-sp1-巴西版中的cmd-exe中输出的默认编码-powershell">示例4-12在Windows 7 (SP1)巴西版中的cmd.exe中输出的默认编码；PowerShell</h4>

<p>输出的结果相同</p>

<table>
<thead>
<tr>
<th>Z:&gt;chcp O</th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>Pagina de codigo ativa: 850Z:&gt;python default_encodings.py ©</td>
<td></td>
</tr>

<tr>
<td>locale.getpreferredencoding() -&gt; &lsquo;cp1252&rsquo;</td>
<td>©</td>
</tr>

<tr>
<td>type(my_file) -&gt; &lt;class &lsquo;</td>
<td>io.TextIOWrapper&rsquo;&gt;</td>
</tr>

<tr>
<td>my_file.encoding -&gt; &lsquo;cp1252&rsquo;</td>
<td>o</td>
</tr>

<tr>
<td>sys.stdout.isatty() -&gt; True</td>
<td>❺</td>
</tr>

<tr>
<td>sys.stdout.encoding -&gt; &lsquo;cp850&rsquo; sys.stdin.isatty() -&gt; True sys.stdin.encoding -&gt; &lsquo;cp850&rsquo;sys.stderr.isatty() -&gt; True sys.stderr.encoding -&gt; &lsquo;cp850&rsquo; sys.getdefaultencoding() -&gt; &lsquo;utf-8&rsquo; sys.getfilesystemencoding() -&gt; &lsquo;mbcs&rsquo;</td>
<td>©</td>
</tr>
</tbody>
</table>

<h4 id="o-chcp输出当前控制台激活的代码页-850">O chcp输出当前控制台激活的代码页：850。</h4>

<h4 id="运行default-encodings-py-把结果输出到控制台">©运行default_encodings.py，把结果输出到控制台。</h4>

<h4 id="locale-getpreferredencoding-是最重要的设置">© locale.getpreferredencoding()是最重要的设置。</h4>

<p>© 文本文件默认使用 locale.getpreferredencoding()。</p>

<p>❺ 输出到控制台中，因此 sys.stdout.isatty() 返回 True。 © 因此， sys.stdout.encoding 与控制台的编码相同。 如果把输出重定向到文件，如下所示：</p>

<p>Z:&gt;python default_encodings.py &gt; encodings.log</p>

<p>sys.stdout.isatty() 的返回值会变成 False， sys.stdout.encoding 会设为 locale.getpreferredencoding()，在那台设备中是&rsquo;cp1252&rsquo;。</p>

<p>注意，示例 4-12 中有 4 种不同的编码。</p>

<p>•如果打开文件时没有指定encoding参数，默认值由 locale.getpreferredencoding() 提供(在示例 4-12 中是 &lsquo;cp1252&rsquo;)。</p>

<p>•如果设定了 PYTHONIOENCODING环境变量</p>

<p>( <a href="https://docs.python.org/3/using/cmdline.html%23envvar-PYTHONIOENCODING">https://docs.python.org/3/using/cmdline.html#envvar-PYTHONIOENCODING</a>%ef%bc%8c)<a href="https://docs.python.org/3/using/cmdline.html%23envvar-PYTHONIOENCODING">)，</a>%ef%bc%8c)<a href="https://docs.python.org/3/using/cmdline.html%23envvar-PYTHONIOENCODING"> sys.stdout/stdin/st</a>derr 的编码使用设定的值；否 则，继承自所在的控制台；如果输入 / 输出重定向到文件，则由</p>

<p>locale.getpreferredencoding() 定义。</p>

<p>•    Python在二进制数据和字符串之间转换时，内部使用sys.getdefaultencoding() 获得的编码； Python 3 很少如此，但仍有发生。 6 这个设置不能修改。 <a href="#bookmark6">1</a></p>

<p>•    sys.getfilesystemencoding()用于编解码文件名(不是文件内容)。把字符串 参数作为文件名传给 open() 函数时就会使用它；如果传入的文件名参数是字节序 列，那就不经改动直接传给OS API。“Unicode HOWTO”一文</p>

<p>(<a href="https://docs.python.org/3/howto/unicode.html">https://docs.python.org/3/howto/unicode.html</a>)中说：“在 Windows 中，Python 使用 mbcs这个名称引用当前配置的编码。”MBCS是Multi Byte Character Set (多字节字符 集)的首字母缩写，在 Windows 中是陈旧的变长编码，如 gb2312 或 Shift_JIS， 而不是 UTF-8。 [ 关于这个话题， Stack Overflow 中有一个很好的回答“， Difference between MBCS and UTF-8 on</p>

<p><a href="http://stackoverflow.com/questions/3298569/difference-between-mbcs-and-utf-8-on-windows">Windows” </a><a href="http://stackoverflow.com/questions/3298569/difference-between-mbcs-and-utf-8-on-windows">(http://stackoverflow.com/questions/3298569/difference-between-mbcs-and-utf-</a>8-on-windows)。 ]</p>

<p>6研究这个话题时，我在 Python 内部找不到把字节序列转换成字符串的情况。 Python 核心开发者 Antoine Pitrou 在 comp.python.devel 邮件列表中说(<a href="http://article.gmane.org/gmane.comp.python.devel/110036">http://article.gmane.org/gmane.comp.python.devel/110036</a>)，CPython 的内部函数“在</p>

<p>py3k 中很少这么做”。</p>

<p>在GNU/Linux和OS X中，这些编码的默认值都是UTF-8，而且多年来都是如 此，因此 I/O 能处理所有 Unicode 字符。在 Windows 中，不仅同一个系统中使用不同 的编码，还有只支持 ASCII 和 127 个额外的字符的代码页(如 &lsquo;cp850&rsquo; 或 &lsquo;cp1252&rsquo;)，而且不同的代码页之间增加的字符也有所不同。因此，若不多加小 心， Windows 用户更容易遇到编码问题。</p>

<p>综上， locale.getpreferredencoding() 返回的编码是最重要的：这是打开文件的默 认编码，也是重定向到文件的 sys.stdout/stdin/stderr 的默认编码。然而，文档也</p>

<p>说道(摘录部</p>

<p>分， <a href="https://docs.python.org/3/library/locale.html%23locale.getpreferredencoding">https://docs.python.org/3/library/locale.html#locale.getpreferredencoding</a>) ：</p>

<p>locale.getpreferredencoding(do_setlocale=True)</p>

<p>根据用户的偏好设置，返回文本数据的编码。用户的偏好设置在不同系统中的设定方</p>

<p>式不同，而且在某些系统中可能无法通过编程方式设置，因此这个函数返回的只是猜</p>

<p>测的编码……</p>

<p>因此，关于编码默认值的最佳建议是：别依赖默认值。</p>

<p>如果遵从 Unicode 三明治的建议，而且始终在程序中显式指定编码，那将避免很多问题。 可惜，即使把字节序列正确地转换成字符串， Unicode 仍有不尽如人意的地方。接下来的</p>

<p>两节讨论的话题对 ASCII 世界来说很简单，但是在 Unicode 领域就变得相当复杂：文本规 范化(即为了比较而把文本转换成统一的表述)和排序。</p>

<h3 id="4-6为了正确比较而规范化unicode字符串">4.6为了正确比较而规范化Unicode字符串</h3>

<p>因为 Unicode 有组合字符(变音符号和附加到前一个字符上的记号，打印时作为一个整</p>

<p>体)，所以字符串比较起来很复杂。</p>

<p>例如，“caft”这个词可以使用两种方式构成，分别有4个和5个码位，但是结果完全一</p>

<p>样：</p>

<p>&gt;&gt;&gt; s1 = &lsquo;eafe&rsquo;</p>

<p>&gt;&gt;&gt; s2 = &lsquo;eafe\u0301&rsquo; &gt;&gt;&gt; s1, s2 (&lsquo;eafe&rsquo;, &lsquo;eafe&rsquo;)</p>

<p>&gt;&gt;&gt; len(s1), len(s2) (4, 5)</p>

<p>&gt;&gt;&gt; s1 == s2 False</p>

<p>U+0301 是 COMBINING ACUTE ACCENT，加在“e”后面得到1”。在 Unicode 标准中，&rsquo;e&rsquo;</p>

<p>和&rsquo;e\u0301&rsquo;这样的序列叫“标准等价物”(canonical equivalent)，应用程序应该把它们</p>

<p>视作相同的字符。但是， Python 看到的是不同的码位序列，因此判定二者不相等。</p>

<p>这个问题的解决方案是使用 unieodedata.normalize 函数提供的 Unicode 规范化。这个 函数的第一个参数是这4个字符串中的一个：&rsquo;NFC&rsquo;、&rsquo;NFD&rsquo;、&rsquo;NFKC•和’NFKD&rsquo;。下面</p>

<p>先说明前两个。</p>

<p>NFC (Normalization Form C)使用最少的码位构成等价的字符串，而NFD把组合字符分 解成基字符和单独的组合字符。这两种规范化方式都能让比较行为符合预期：</p>

<p>&gt;&gt;&gt; from unieodedata import normalize</p>

<p>&gt;&gt;&gt; s1 = &lsquo;eafe&rsquo; #把&rdquo;e&rdquo;和重音符组合在一起 &gt;&gt;&gt; s2 = &lsquo;eafe\u0301&rsquo;    # 分解成&rdquo;e&rdquo;和重音符</p>

<p>&gt;&gt;&gt; len(s1), len(s2)</p>

<p>(4, 5)</p>

<p>&gt;&gt;&gt; len(normalize(&lsquo;NFC&rsquo;, s1)), len(normalize(&lsquo;NFC&rsquo;, s2)) (4, 4)</p>

<p>&gt;&gt;&gt; len(normalize(&lsquo;NFD&rsquo;, s1)), len(normalize(&lsquo;NFD&rsquo;, s2)) (5, 5)</p>

<p>&gt;&gt;&gt; normalize(&lsquo;NFC&rsquo;, s1) == normalize(&lsquo;NFC&rsquo;, s2)</p>

<p>True</p>

<p>&gt;&gt;&gt; normalize(&lsquo;NFD&rsquo;, s1) == normalize(&lsquo;NFD&rsquo;, s2)</p>

<p>True</p>

<p>西方键盘通常能输出组合字符，因此用户输入的文本默认是 NFC 形式。不过，安全起 见，保存文本之前，最好使用 normalize(&lsquo;NFC&rsquo;, user_text) 清洗字符串。 NFC 也是</p>

<p>W3C 的“Character Model for the World Wide Web: String Matching and Searching”规范 (<a href="https://www.w3.org/TR/charmod-norm/">https://www.w3.org/TR/charmod-norm/</a>)推荐的规范化形式。</p>

<p>使用NFC时，有些单字符会被规范成另一个单字符。例如，电阻的单位欧姆(Q)会被 规范成希腊字母大写的欧米加。这两个字符在视觉上是一样的，但是比较时并不相等，因</p>

<h4 id="此要规范化-防止出现意外">此要规范化，防止出现意外：</h4>

<p>&gt;&gt;&gt; from unicodedata import normalize, name &gt;&gt;&gt; ohm = &lsquo;\u2126&rsquo;</p>

<p>&gt;&gt;&gt; name(ohm)</p>

<p>&lsquo;OHM SIGN&rsquo;</p>

<p>&gt;&gt;&gt; ohm_c = normalize(&lsquo;NFC&rsquo;, ohm)</p>

<p>&gt;&gt;&gt; name(ohm_c)</p>

<p>&lsquo;GREEK CAPITAL LETTER OMEGA&rsquo;</p>

<p>&gt;&gt;&gt; ohm == ohm_c False</p>

<p>&gt;&gt;&gt; normalize(&lsquo;NFC&rsquo;, ohm) == normalize(&lsquo;NFC&rsquo;, ohm_c) True</p>

<h4 id="在另外两个规范化形式-nfkc和nfkd-的首字母缩略词中-字母k表">在另外两个规范化形式(NFKC和NFKD)的首字母缩略词中，字母K表</h4>

<p>示“compatibility”(兼容性)。这两种是较严格的规范化形式，对“兼容字符”有影响。虽 然 Unicode 的目标是为各个字符提供“规范的”码位，但是为了兼容现有的标准，有些字符 会出现多次。例如，虽然希腊字母表中有&gt;”这个字母(码位是U+03BC，GREEK SMALL LETTER MU)，但是Unicode还是加入了微符号’p&rsquo; (U+00B5)，以便与latinl相互转 换。因此，微符号是一个“兼容字符”。</p>

<p>在 NFKC 和 NFKD 形式中，各个兼容字符会被替换成一个或多个“兼容分解”字符，即便 这样有些格式损失，但仍是“首选”表述——理想情况下，格式化是外部标记的职责，不应 该由Unicode处理。下面举个例子。二分之一    (U+00BD)经过兼容分解后得到的是</p>

<p>三个字符序列’1/2&rsquo;;微符号’p&rsquo; (U+00B5)经过兼容分解后得到的是小写字母 ■p&rsquo; (U+03BC)。8</p>

<p>8微符号是“兼容字符”，而欧姆符号不是，这还真是奇怪。因此，NFC不会改动微符号，但是会把欧姆符号改成大写 的欧米加；而NFKC和NFKD会把欧姆和微符号都改成其他字符。</p>

<h4 id="下面是-nfkc-的具体应用">下面是 NFKC 的具体应用：</h4>

<p>&gt;&gt;&gt; from unicodedata import normalize, name &gt;&gt;&gt; half = &lsquo;%■</p>

<p>&gt;&gt;&gt; normalize(&lsquo;NFKC&rsquo;, half)</p>

<p>&lsquo;<sup>1</sup>&frasl;<sub>2</sub>&rsquo;</p>

<p>&gt;&gt;&gt; four_squared = &lsquo;42&rsquo;</p>

<p>&gt;&gt;&gt; normalize(&lsquo;NFKC&rsquo;, four_squared)</p>

<p>&lsquo;42&rsquo;</p>

<p>&gt;&gt;&gt; micro = &lsquo;p&rsquo;</p>

<p>&gt;&gt;&gt; micro_kc = normalize(&lsquo;NFKC&rsquo;, micro)</p>

<p>&gt;&gt;&gt; micro, micro_kc</p>

<p>(&lsquo;p&rsquo;, &lsquo;p&rsquo;)</p>

<p>&gt;&gt;&gt; ord(micro), ord(micro_kc)</p>

<p>(181, 956)</p>

<p>&gt;&gt;&gt; name(micro), name(micro_kc)</p>

<p>(&lsquo;MICRO SIGN&rsquo;, &lsquo;GREEK SMALL LETTER MU&rsquo;)</p>

<h4 id="使用-1-2-替代-x-可以接受-微符号也确实是小写的希腊字母-p-但是把-42-转换">使用’1/2&rsquo;替代’X&rsquo;可以接受，微符号也确实是小写的希腊字母’p&rsquo;，但是把’42&rsquo;转换</h4>

<p>成’42’就改变原意了。某些应用程序可以把&rsquo;42&rsquo;保存为’4<sup>2</sup>&lsquo;，但是 normalize 函数对格式一无所知。因此， NFKC 或 NFKD 可能会损失或曲解信息，但是 可以为搜索和索引提供便利的中间表述：用户搜索 &lsquo;1 / 2 inch&rsquo; 时，如果还能找到包 含’X inch&rsquo;的文档，那么用户会感到满意。</p>

<p>使用NFKC和NFKD规范化形式时要小心，而且只能在特殊情况中使用，例</p>

<p>如搜索和索引，而不能用于持久存储，因为这两种转换会导致数据损失。</p>

<p>为搜索或索引准备文本时，还有一个有用的操作，即下一节讨论的大小写折叠。</p>

<p>4.6.1 大小写折叠</p>

<p>大小写折叠其实就是把所有文本变成小写，再做些其他转换。这个功能由</p>

<p>str.casefold()方法(Python 3.3 新增)支持。</p>

<p>对于只包含 latin1 字符的字符串 s， s.casefold() 得到的结果与 s.lower() 一样，唯 有两个例外：微符号’p&rsquo;会变成小写的希腊字母“^’(在多数字体中二者看起来一样)； 德语 Eszett (“sharp s”， B)会变成“ss”。</p>

<p>&gt;&gt;&gt; micro = &lsquo;^&rsquo;</p>

<p>&gt;&gt;&gt; name(micro)</p>

<p>&lsquo;MICRO SIGN&rsquo;</p>

<p>&gt;&gt;&gt; micro_cf = micro.casefold() &gt;&gt;&gt; name(micro_cf)</p>

<p>&lsquo;GREEK SMALL LETTER MU&rsquo;</p>

<p>&gt;&gt;&gt; micro, micro_cf (’旷，’H&rsquo;)    &ldquo;</p>

<p>&gt;&gt;&gt; eszett = &lsquo;B&rsquo;</p>

<p>&gt;&gt;&gt; name(eszett)</p>

<p>&lsquo;LATIN SMALL LETTER SHARP S&rsquo;</p>

<p>&gt;&gt;&gt; eszett_cf = eszett.casefold() &gt;&gt;&gt; eszett, eszett_cf (&lsquo;B&rsquo;, &lsquo;ss&rsquo;)</p>

<p>自 Python 3.4 起， str.casefold() 和 str.lower() 得到不同结果的有 116 个码位。</p>

<p>Unicode 6.3 命名了 110 122 个字符，这只占 0.11%。</p>

<p>与 Unicode 相关的任何问题一样，大小写折叠是个复杂的问题，有很多语言上的特殊情 况，但是 Python 核心团队尽力提供了一种方案，能满足大多数用户的需求。 接下来的几节将使用这些规范化知识来开发几个实用的函数。</p>

<p>4.6.2 规范化文本匹配实用函数</p>

<p>由前文可知， NFC 和 NFD 可以放心使用，而且能合理比较 Unicode 字符串。对大多数应 用来说， NFC 是最好的规范化形式。不区分大小写的比较应该使用 str.casefold()。</p>

<p>如果要处理多语言文本，工具箱中应该有示例 4-13 中的 nfc_equal 和 fold_equal 函 数。</p>

<p>示例4-13 normeq.py:比较规范化Unicode字符串</p>

<p>Utility funetions for normalized Unieode string eomparison.</p>

<p>Using Normal Form C, ease sensitive:</p>

<p>&gt;&gt;&gt; s1 = &lsquo;eafe&rsquo;</p>

<p>&gt;&gt;&gt; s2 = &lsquo;eafe\u0301&rsquo;</p>

<p>&gt;&gt;&gt; s1 == s2</p>

<p>False</p>

<p>&gt;&gt;&gt; nfe_equal(s1, s2)</p>

<p>True</p>

<p>&gt;&gt;&gt; nfe_equal(&lsquo;A&rsquo;, &lsquo;a&rsquo;)</p>

<p>False</p>

<p>Using Normal Form C with ease folding:</p>

<p>&gt;&gt;&gt; s3 = &lsquo;StraBe&rsquo;</p>

<p>&gt;&gt;&gt; s4 = &lsquo;strasse&rsquo;</p>

<p>&gt;&gt;&gt; s3 == s4 False</p>

<p>&gt;&gt;&gt; nfe_equal(s3, s4)</p>

<p>False</p>

<p>&gt;&gt;&gt; fold_equal(s3, s4)</p>

<p>True</p>

<p>&gt;&gt;&gt; fold_equal(s1, s2)</p>

<p>True</p>

<p>&gt;&gt;&gt; fold_equal(&lsquo;A&rsquo;, &lsquo;a&rsquo;)</p>

<p>True</p>

<p>from unieodedata import normalize def nfe_equal(str1, str2):</p>

<p>return normalize(&lsquo;NFC&rsquo;, str1) == normalize(&lsquo;NFC&rsquo;, str2)</p>

<p>def fold_equal(str1, str2):</p>

<p>return (normalize(&lsquo;NFC&rsquo;, str1).easefold() ==</p>

<p>normalize(&lsquo;NFC&rsquo;, str2).easefold())</p>

<p>除了 Unicode 规范化和大小写折叠（二者都是 Unicode 标准的一部分）之外，有时需要进 行更为深入的转换，例如把&rsquo;eafe&rsquo;变成’eafe&rsquo;。下一节说明何时以及如何进行这种转 换。</p>

<p>4.6.3 极端“规范化”：去掉变音符号</p>

<p>Google 搜索涉及很多技术，其中一个显然是忽略变音符号（如重音符、下加符等），至 少在某些情况下会这么做。去掉变音符号不是正确的规范化方式，因为这往往会改变词的</p>

<p>意思，而且可能误判搜索结果。但是对现实生活却有所帮助：人们有时很懒，或者不知道</p>

<p>怎么正确使用变音符号，而且拼写规则会随时间变化，因此实际语言中的重音经常变来变</p>

<p>去。</p>

<p>除了搜索，去掉变音符号还能让 URL 更易于阅读，至少对拉丁语系语言是如此。下面是</p>

<p>维基百科中介绍圣保罗市（Sao Paulo）的文章的URL：</p>

<p><a href="http://en.wikipedia.org/wiki/S%C3%A3o_Paulo">http://en.wikipedia.org/wiki/S%C3%A3o_Paulo</a></p>

<h4 id="其中-c3-a3-是utf-8编码-a-字母-带有波形符的-a-转义后得到的结果-下述形">其中，“°%C3°%A3”是UTF-8编码“a”字母(带有波形符的“a”)转义后得到的结果。下述形</h4>

<p>式更友好，尽管拼写是错误的：</p>

<p><a href="http://en.wikipedia.org/wiki/Sao_Paulo">http://en.wikipedia.org/wiki/Sao_Paulo</a></p>

<h4 id="如果想把字符串中的所有变音符号都去掉-可以使用示例-4-14-中的函数">如果想把字符串中的所有变音符号都去掉，可以使用示例 4-14 中的函数</h4>

<h4 id="示例-4-14-去掉全部组合记号的函数-在-sanitize-py-模块中">示例 4-14 去掉全部组合记号的函数(在 sanitize.py 模块中)</h4>

<p>import unicodedata import string</p>

<p>def shave_marks(txt):</p>

<p>&rdquo;&ldquo;&ldquo;去掉全部变音符号 &ldquo;&rdquo;&rdquo;</p>

<p>norm_txt = unicodedata.normalize(&lsquo;NFD&rsquo;, txt) O shaved = &ldquo;.join(c for c in norm_txt</p>

<p>if not unicodedata.combining&copy;) © return unicodedata.normalize(&lsquo;NFC&rsquo;, shaved) &amp;</p>

<h4 id="o-把所有字符分解成基字符和组合记号">O 把所有字符分解成基字符和组合记号。</h4>

<h4 id="过滤掉所有组合记号">© 过滤掉所有组合记号。</h4>

<h4 id="o重组所有字符">o重组所有字符。</h4>

<p>示例 4-15 是 shave_marks 函数的两个使用示例。</p>

<p>示例 4-15 示例 4-14 中 shave_marks 函数的两个使用示例</p>

<p>&gt;&gt;&gt; order = &lsquo;“Herr VoB: • X cup of OEtker™ caffe latte • bowl of aqai.”&rsquo;</p>

<p>&gt;&gt;&gt; shave_marks(order)</p>

<p>&lsquo;“Herr VoB: • X cup of OEtker™ caffe latte • bowl of acai.”&rsquo; O &gt;&gt;&gt; Greek = &lsquo;Zs^upo^, Zefiro&rsquo;</p>

<p>&gt;&gt;&gt; shave_marks(Greek)</p>

<p>■Zs中upoq, Zefiro&rsquo; ©</p>

<h4 id="o只替换了-和-r三个字符">O只替换了 ％”“?”和“r三个字符。</h4>

<p>© T和T都被替换了。</p>

<p>示例 4-14 中定义的 shave_marks 函数使用起来没问题，但是也许做得太多了。通常，去 掉变音符号是为了把拉丁文本变成纯粹的ASCII，但是shave_marks函数还会修改非拉 丁字符(如希腊字母)，而只去掉重音符并不能把它们变成 ASCII 字符。因此，我们应该 分析各个基字符，仅当字符在拉丁字母表中时才删除附加的记号，如示例 4-16 所示。</p>

<h4 id="示例4-16删除拉丁字母中组合记号的函数-import语句省略了-因为这是示例4-14-中定义的-sanitize-py-模块的一部分">示例4-16删除拉丁字母中组合记号的函数(import语句省略了，因为这是示例4-14 中定义的 sanitize.py 模块的一部分)</h4>

<p>def shave_marks_latin(txt):</p>

<p>&rdquo;&ldquo;&ldquo;把拉丁基字符中所有的变音符号删除&rdquo;&ldquo;&rdquo;</p>

<p>norm_txt = unicodedata.normalize(&lsquo;NFD&rsquo;, txt) O</p>

<p>latin_base = False</p>

<p>keepers = []</p>

<p>for c in norm_txt:</p>

<p>if unicodedata.combining&copy; and latin_base: © continue # 忽略拉丁基字符上的变音符号</p>

<p>keepers.append&copy;    ©</p>

<p># 如果不是组合字符，那就是新的基字符 if not unicodedata.combining&copy;:    ©</p>

<p>latin_base = c in string.ascii_letters shaved = &ldquo;.join(keepers)</p>

<p>return unicodedata.normalize(&lsquo;NFC&rsquo;, shaved) ❺</p>

<h4 id="o-把所有字符分解成基字符和组合记号-1">O 把所有字符分解成基字符和组合记号。</h4>

<h4 id="基字符为拉丁字母时-跳过组合记号">© 基字符为拉丁字母时，跳过组合记号。</h4>

<h4 id="否则-保存当前字符">© 否则，保存当前字符。</h4>

<h4 id="检测新的基字符-判断是不是拉丁字母">© 检测新的基字符，判断是不是拉丁字母。</h4>

<h4 id="❺-重组所有字符">❺ 重组所有字符。</h4>

<p>更彻底的规范化步骤是把西文文本中的常见符号(如弯引号、长破折号、项目符号，等 等)替换成 ASCII 中的对等字符。示例 4-17 中的 asciize 函数就是这么做的。</p>

<p>示例 4-17 把一些西文印刷字符转换成 ASCII 字符(这个代码片段也是示例 4-14 中 sanitize.py 模块的一部分)</p>

<p>single_map = str.maketrans(&ldquo;&rdquo;&ldquo;‘&rsquo;“”•&ndash;&lsquo;&gt;&rdquo;&ldquo;&rdquo;, O</p>

<p>llllll’fll*八&lt;’’1111    &gt;1111&rdquo;)</p>

<p>multi_map = str.maketrans({ ©</p>

<p>&lsquo;€&rsquo;: &lsquo;<euro>&rsquo;,</p>

<p>&lsquo;…&rsquo;: &lsquo;&hellip;&rsquo;,</p>

<p>&lsquo;OE&rsquo;: &lsquo;OE&rsquo;,</p>

<p>&lsquo;™&rsquo;: &lsquo;&trade;&rsquo;,</p>

<p>&lsquo;oe&rsquo;: &lsquo;oe&rsquo;,</p>

<p>■知&rsquo;：&rsquo;<per mille>&rsquo;,</p>

<p>’j ’：    &lsquo;**&rsquo;</p>

<p>})</p>

<p>multi_map.update(single_map) ©</p>

<p>def dewinize(txt):</p>

<p>&rdquo;&ldquo;&ldquo;把Win1252符号替换成ASCII字符或序列 return txt.translate(multi_map) ©</p>

<p>z</p>

<p>i</p>

<p>i</p>

<p>e</p>

<p>s</p>

<p>a</p>

<p>ef</p>

<p>d</p>

<p>no_marks = shave_marks_latin(dewinize(txt))</p>

<p>no_marks = no_marks.replaee(&lsquo;B&rsquo;, &lsquo;ss&rsquo;) return unieodedata.normalize(&lsquo;NFKC&rsquo;, no_marks)</p>

<p>❶ 构建字符替换字符的映射表。</p>

<p>❷ 构建字符替换字符串的映射表。</p>

<p>❸ 合并两个映射表。</p>

<p>❹ dewinize 函数不影响 ASCII 或 latin1 文本，只替换 Microsoft 在 ep1252 中为 latin1 额外添加的字符。</p>

<p>❺ 调用 dewinize 函数，然后去掉变音符号。</p>

<p>❻把德语Eszett替换成“ss”（这里没有使用大小写折叠，因为我们想保留大小写）。 ❼ 使用 NFKC 规范化形式把字符和与之兼容的码位组合起来。</p>

<p>示例 4-18 是 aseiize 函数的使用示例。</p>

<p>示例 4-18 示例 4-17 中 aseiize 函数的使用示例</p>

<p>&gt;&gt;&gt; order = &lsquo;“Herr VoB: • % eup of OEtker™ eaffe latte • bowl of aqai.” &gt;&gt;&gt; dewinize(order)</p>

<p>&rsquo;&ldquo;Herr VoB: - % eup of OEtker&trade; eaffe latte - bowl of aqai.&ldquo;&rsquo; O &gt;&gt;&gt; aseiize(order)</p>

<p>&rsquo;&ldquo;Herr Voss: - <sup>1</sup>&frasl;<sub>2</sub> eup of OEtker&trade; eaffe latte - bowl of aeai.&ldquo;&rsquo; ©</p>

<p>O dewinize函数替换弯引号、项目符号和™ （商标符号）。</p>

<p>© aseiize 函数调用 dewinize 函数，去掉变音符号，还会替换 &lsquo;B&rsquo;。</p>

<p>不同语言删除变音符号的规则也有所不同。例如，德语把’U&rsquo;变成’ue&rsquo;。 我们定义的 aseiize 函数没这么精确，因此可能适合你的语言，也可能不适合。不</p>

<p>过，它对葡萄牙语的处理是可接受的。</p>

<p>综上， sanitize.py 中的函数做的事情超出了标准的规范化，而且会对文本做进一步处理，</p>

<p>很有可能会改变原意。只有知道目标语言、目标用户群和转换后的用途，才能确定要不要</p>

<p>做这么深入的规范化。</p>

<p>我们对 Unicode 文本规范化的讨论到此结束。</p>

<p>接下来要解决的 Unicode 问题是……排序。</p>

<h3 id="4-7-unicode文本排序">4.7 Unicode文本排序</h3>

<p>Python 比较任何类型的序列时，会一一比较序列里的各个元素。对字符串来说，比较的是 码位。可是在比较非 ASCII 字符时，得到的结果不尽如人意。</p>

<p>下面对一个生长在巴西的水果的列表进行排序：</p>

<p>&gt;&gt;&gt; fruits = [&lsquo;caju&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;caja&rsquo;, &lsquo;aqai&rsquo;, &lsquo;acerola&rsquo;]</p>

<p>&gt;&gt;&gt; sorted(fruits)</p>

<p>[&lsquo;acerola&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;aqai&rsquo;, &lsquo;caju&rsquo;, &lsquo;caja&rsquo;]</p>

<p>不同的区域采用的排序规则有所不同，葡萄牙语等很多语言按照拉丁字母表排序，重音符</p>

<p>号和下加符对排序几乎没什么影响。9因此，排序时“cajF视作“caja”，必定排在“caju”前 面。</p>

<p>9变音符号对排序有影响的情况很少发生，只有两个词之间唯有变音符号不同时才有影响。此时，带有变音符号的词排 在常规词的后面。</p>

<p>排序后的 fruits 列表应该是：</p>

<p>[&lsquo;aqai&rsquo;, &lsquo;acerola&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;caja&rsquo;, &lsquo;caju&rsquo;]</p>

<p>在 Python 中，非 ASCII 文本的标准排序方式是使用 locale.strxfrm 函数，根据 locale 模块的文档(<a href="https://docs.python.org/3/library/locale.html?highlight=strxfrm%23locale.strxfrm">https://docs.python.org/3/library/locale.html?highlight=strxfrm#locale.strxfrm</a>)，</p>

<p>这 个函数会“把字符串转换成适合所在区域进行比较的形式”。</p>

<p>使用 locale.strxfrm 函数之前，必须先为应用设定合适的区域设置，还要祈祷操作系 统支持这项设置。在区域设为 pt_BR 的 GNU/Linux(Ubuntu 14.04)中，可以使用示例 419 中的命令。</p>

<p>示例 4-19 使用 locale.strxfrm 函数做排序键</p>

<p>&gt;&gt;&gt; import locale</p>

<p>&gt;&gt;&gt; locale.setlocale(locale.LC_COLLATE, &lsquo;pt_BR.UTF-8&rsquo;)</p>

<p>&lsquo;pt_BR.UTF-8&rsquo;</p>

<p>&gt;&gt;&gt; fruits = [&lsquo;caju&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;caja&rsquo;, &lsquo;aqai&rsquo;, &lsquo;acerola&rsquo;]</p>

<p>&gt;&gt;&gt; sorted_fruits = sorted(fruits, key=locale.strxfrm)</p>

<p>&gt;&gt;&gt; sorted_fruits</p>

<p>[&lsquo;aqai&rsquo;, &lsquo;acerola&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;caja&rsquo;, &lsquo;caju&rsquo;]</p>

<p>因此，使用 locale.strxfrm 函数做排序键之前，要调用 setlocale(LC_COLLATE, «your_locale»)。</p>

<p>不过，有几点要注意。</p>

<p>•区域设置是全局的，因此不推荐在库中调用setlocale函数。应用或框架应该在进</p>

<p>程启动时设定区域设置，而且此后不要再修改。</p>

<p>•操作系统必须支持区域设置，否则setlocale函数会抛出locale.Error: unsupported locale setting 异常。</p>

<p>•必须知道如何拼写区域名称。它在Unix衍生系统中几乎己经形成标准，要通过 &lsquo;language_code.encoding&rsquo; 获取。 10 但是在 Windows 中，句法复杂一 些：Language Name-Language Variant_Region Name.codepage。注 意，“Language Name” (语言名称)、“Language Variant” (语言变体)和“Region Name” (区域名)中可以包含空格；除了第一部分之外，其他部分的前面是不同的字 符：一个连字符、一个下划线和一个点号。除了语言名称之外，其他部分好像都是可 选的。例如，English_United States.850，它的语言名称是“English”，区域 是“United States”，代码页是“850”。Windows能理解的语言名称和区域名见于MSDN 中的文章“Language Identifier Constants and Strings” (<a href="https://msdn.microsoft.com/en-us/library/dd318693.aspx">https://msdn.microsoft.com/en-us/library/dd318693.aspx</a>%ef%bc%8c%e8%bf%98%e6%9c%89%e2%80%9cCode)<a href="https://msdn.microsoft.com/en-us/library/dd318693.aspx">)，还有“Code</a>%ef%bc%8c%e8%bf%98%e6%9c%89%e2%80%9cCode)<a href="https://msdn.microsoft.com/en-us/library/windows/desktop/dd317756(v=vs.85).aspx"> Page Identifiers” (https://msdn.microsoft.com/en-</a>us/library/windows/desktop/dd317756(v=vs.85).aspx) 一文列出了最后一部分的代码页 数字。 11</p>

<p>•操作系统的制作者必须正确实现了所设的区域。我在Ubuntu 14.04中成功了，但在 OS X(Mavericks 10.9)中却失败了。在两台 Mac 中，调用 setlocale(LC_COLLATE, &lsquo;pt_BR.UTF-8&rsquo;) 返回的都是字符串 &lsquo;pt_BR.UTF-8&rsquo;， 没有任何问题。但是， sorted(fruits, key=locale.strxfrm) 得到的结果与 sorted(fruits) 一样，是错误的。我还在 OS X 中尝试了 fr_FR、 es_ES 和 de_DE，但是 locale.strxfrm 并未起作用。12</p>

<p>10在Linux操作系统中，中国大陆的读者可以使用zh_CN.UTF-8,简体中文会按照汉语拼音顺序进行排序，它也能对 葡萄牙语进行正确排序。一编者注</p>

<p>I11感谢Leonardo Rochael，他所做的工作超出了身为技术审校的职责，虽然他是GNU/Linux用户，但却研宄了这些 Windows 细节。</p>

<p>12同样，我没找到解决方案，不过却发现其他人也报告了同样的问题。本书技术审校之一 Alex Martel!在他装有OS X 10.9的Mac电脑中使用setlocale和locale.strxfrm时没有遇到问题。综上：结果因人而异。</p>

<p>因此，标准库提供的国际化排序方案可用，但是似乎只支持GNU/Linux (可能也支持 Windows，但你得是专家)。即便如此，还要依赖区域设置，而这会为部署带来问题。 幸好，有个较为简单的方案： PyPI 中的 PyUCA 库。</p>

<p>使用Unicode排序算法排序</p>

<p>James Tauber，一位高产的Django贡献者，他一定是感受到了这一痛点，因此开发了 PyUCA 库(<a href="https://pypi.python.org/pypi/pyuca/">https://pypi.python.org/pypi/pyuca/</a>)，这是 Unicode 排序算法(Unicode Collation Algorithm， UCA)的纯Python实现。示例4-20展示了它的简单用法。</p>

<p>示例 4-20 使用 pyuca.Collator.sort_key 方法</p>

<p>&gt;&gt;&gt; import pyuea</p>

<p>&gt;&gt;&gt; eoll = pyuea.Collator()</p>

<p>&gt;&gt;&gt; fruits = [&lsquo;eaju&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;eaja&rsquo;, &lsquo;aqai&rsquo;, &lsquo;aeerola&rsquo;] &gt;&gt;&gt; sorted_fruits = sorted(fruits, key=eoll.sort_key)</p>

<p>&gt;&gt;&gt; sorted_fruits</p>

<p>[&lsquo;aqai&rsquo;, &lsquo;aeerola&rsquo;, &lsquo;atemoia&rsquo;, &lsquo;eaja&rsquo;, &lsquo;eaju&rsquo;]</p>

<p>这样做更友好，而且恰好可用。我在 GNU/Linux、 OS X 和 Windows 中做过测试。目前， PyUCA 只支持 Python 3.x。 13</p>

<p>132015 年 5 月，PyUCA 重新支持 Python 2.x，参见：<a href="http://jktauber.com/2015/05/13/pyuca-supports-python-2-again。-编">http://jktauber.com/2015/05/13/pyuca-supports-python-2-again。-编</a></p>

<p>者注</p>

<p>PyUCA 没有考虑区域设置。如果想定制排序方式，可以把自定义的排序表路径传给 Collator() 构造方法。 PyUCA 默认使用项目自带的</p>

<p>allkeys .txt (<a href="https://github.com/jtauber/pyuca">https://github.com/jtauber/pyuca</a>)，这就是 Unicode 6.3.0 的“Default Unicode Collation Element Table” (<a href="http://www.unicode.org/Public/UCA/6.3.0/allkeys.txt">http://www.unicode.org/Public/UCA/6.3.0/allkeys.txt</a>)的副本。 顺便说一下，那个表是 Unicode 数据库中众多表中的一个。下一节会讨论这个话题。</p>

<p>Unicode 标准提供了一个完整的数据库(许多格式化的文本文件)，不仅包括码位与字符 名称之间的映射，还有各个字符的元数据，以及字符之间的关系。例如， Unicode 数据库 记录了字符是否可以打印、是不是字母、是不是数字，或者是不是其他数值符号。字符串</p>

<p>的 isidentifier、isprintable、isdecimal 和 isnumeric 等方法就是靠这些信息作 判断的。 str.casefold 方法也用到了 Unicode 表中的信息。</p>

<p>unicodedata 模块中有几个函数用于获取字符的元数据。例如，字符在标准中的官方名称是 不是组合字符(如结合波形符构成的变音符号等)，以及符号对应的人类可读数值(不是 码位)。示例 4-21 展示了 unicodedata.name() 和 unicodedata.numeric() 函数，以 及字符串的 .isdecimal() 和 .isnumeric() 方法的用法。</p>

<p>示例 4-21 Unicode 数据库中数值字符的元数据示例(各个标号说明输出中的各列)</p>

<p>import unicodedata import re</p>

<p>re_digit = re.compile(r&rsquo;\d&rsquo;)</p>

<p>sample = &lsquo;1\xbc\xb2\u0969\u136b\u216b\u2466\u2480\u3285&rsquo;</p>

<p>for char in sample:</p>

<p>print(&lsquo;U+%04x&rsquo; % ord(char), char.center(6),</p>

<p>&rsquo;re_dig&rsquo; if re_digit.match(char) else &lsquo;-&rsquo;, &lsquo;isdig&rsquo; if char.isdigit() else &lsquo;-&rsquo;,</p>

<p>&lsquo;isnum&rsquo; if char.isnumeric() else &lsquo;-&rsquo;, format(unicodedata.numeric(char), &lsquo;5.2f&rsquo;), unicodedata.name(char),</p>

<p>sep=&rsquo;\t&rsquo;)</p>

<p>O U+0000 格式的码位。</p>

<p>© 在长度为 6 的字符串中居中显示字符。</p>

<p>O如果字符匹配正则表达式r&rsquo;\d&rsquo;，显示re_dig。</p>

<p>0 如果 char.isdigit()返回 True，显示 isdig。</p>

<p>© 如果 char.isnumeric()返回 True，显示 isnum。</p>

<p>©使用长度为5、小数点后保留2位的浮点数显示数值。 © Unicode标准中字符的名称。</p>

<p>运行示例 4-21 得到的结果如图 4-3 所示。</p>

<p>图 4-3 中的第 6 列是在字符上调用 unieodedata.numerie(ehar) 函数得到的结果。这 表明， Unicode 知道表示数字的符号的数值。因此，如果你想创建一个支持泰米尔数字和</p>

<p>罗马数字的电子表格应用，那就尽管去做吧！</p>

<table>
<thead>
<tr>
<th>$ python3 numeri.cs_demo.py</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>U+0031</td>
<td>1</td>
<td>re_dig</td>
<td>isdig</td>
<td>isnum</td>
<td>1.00</td>
<td>DIGIT ONE</td>
</tr>

<tr>
<td>U+00bc</td>
<td>%</td>
<td></td>
<td></td>
<td>isnum</td>
<td>0.25</td>
<td>VULGAR FRACTION ONE QUARTER</td>
</tr>

<tr>
<td>U+00b2</td>
<td>z</td>
<td></td>
<td>isdig</td>
<td>isnum</td>
<td>2.00</td>
<td>SUPERSCRIPT TWO</td>
</tr>

<tr>
<td>U+0969</td>
<td>廷</td>
<td>re_dig</td>
<td>isdig</td>
<td>isnum</td>
<td>3.00</td>
<td>DEVANAGARI DIGIT THREE</td>
</tr>

<tr>
<td>U+136b</td>
<td>r</td>
<td></td>
<td>isdig</td>
<td>isnum</td>
<td>3.00</td>
<td>ETHIOPIC DIGIT THREE</td>
</tr>

<tr>
<td>U+216b</td>
<td>XII</td>
<td></td>
<td></td>
<td>isnum</td>
<td>12.00</td>
<td>ROMAN NUMERAL TWELVE</td>
</tr>

<tr>
<td>U+2466</td>
<td>⑦</td>
<td></td>
<td>isdig</td>
<td>isnum</td>
<td>7.00</td>
<td>CIRCLED DIGIT SEVEN</td>
</tr>

<tr>
<td>U+2480</td>
<td>o</td>
<td></td>
<td></td>
<td>isnum</td>
<td>13.00</td>
<td>PARENTHESIZED NUMBER THIRTEEN</td>
</tr>

<tr>
<td>U+3285$■</td>
<td>㊅</td>
<td></td>
<td></td>
<td>isnum</td>
<td>6.00</td>
<td>CIRCLED IDEOGRAPH SIX</td>
</tr>
</tbody>
</table>

<p>图4-3: 9个数值字符及其元数据；re_dig表示字符匹配正则表达式r&rsquo;\d&rsquo;</p>

<p>图 4-3 表明，正则表达式 r&rsquo;\d&rsquo; 能匹配数字“1”和梵文数字 3，但是不能匹配 isdigit 方 法判断为数字的其他字符。 re 模块对 Unicode 的支持并不充分。 PyPI 中有个新开发的</p>

<p>regex 模块，它的最终目的是取代 re 模块，以提供更好的 Unicode 支持。 14 下一节会回 过头来讨论 re 模块。</p>

<p>14不过在这个示例中，它在识别数字方面的表现没有re模块好。</p>

<p>本章使用了 unieodedata 模块中的几个函数，但是还有很多没有用到。详情参阅标准库 文档对 unieodedata 模块的说明(<a href="https://docs.python.org/3/library/unicodedata.html">https://docs.python+org/3/library/unicodedata.html</a>)。</p>

<p>在结束对字符串和字节序列的讨论之前，我们还要简要说明一个新的趋势——双模式</p>

<p>API，即提供的函数能接受字符串或字节序列为参数，然后根据类型进行特殊处理。</p>

<h3 id="4-9支持字符串和字节序列的双模式api">4.9支持字符串和字节序列的双模式API</h3>

<p>标准库中的一些函数能接受字符串或字节序列为参数，然后根据类型展现不同的行 为。 re 和 os 模块中就有这样的函数。</p>

<p>4.9.1 正则表达式中的字符串和字节序列</p>

<p>如果使用字节序列构建正则表达式， \d 和 \w 等模式只能匹配 ASCII 字符；相比之下，如 果是字符串模式，就能匹配 ASCII 之外的 Unicode 数字或字母。示例 4-22 和图 4-4 展示了 字符串模式和字节序列模式中字母、 ASCII 数字、上标和泰米尔数字的匹配情况。</p>

<p>示例4-22 ramanujan.py:比较简单的字符串正则表达式和字节序列正则表达式的行 为</p>

<p>import re</p>

<p>re_numbers_str = re.compile(r&rsquo;\d+&lsquo;) O re_words_str = re.compile(r&rsquo;\w+&lsquo;) re_numbers_bytes = re.compile(rb&rsquo;\d+&lsquo;) © re_words_bytes = re.compile(rb&rsquo;\w+&lsquo;)</p>

<p>text_str = (lRamanujan saw \u0be7\u0bed\u0be8\u0befl © &ldquo;as 1729 = 13 + 123 = 93 + 103.&rdquo;)    ©</p>

<p>text_bytes = text_str.encode(&lsquo;utf_8&rsquo;) ❺</p>

<p>print(&lsquo;Text&rsquo;, repr(text_str), sep=&rsquo;\n &lsquo;) print(&lsquo;Numbers&rsquo;)</p>

<p>print(&rsquo; str : print(&rsquo; bytes: print(&lsquo;Words&rsquo;) print(&rsquo; str : print(&rsquo; bytes:</p>

<p>re_numbers_str.findall(text_str))</p>

<p>re_numbers_bytes.findall(text_bytes))</p>

<p>re_words_str.findall(text_str))</p>

<p>re_words_bytes.findall(text_bytes))</p>

<p>©</p>

<p>&amp;</p>

<p>©</p>

<p>&amp;</p>

<p>❶ 前两个正则表达式是字符串类型。</p>

<p>❷ 后两个正则表达式是字节序列类型。</p>

<p>❸ 要搜索的 Unicode 文本，包括 1729 的泰米尔数字（逻辑行直到右括号才结束）。</p>

<p>❹ 这个字符串在编译时与前一个拼接起来(参见 Python 语言参考手册中的“2.4.2. String <a href="https://docs.python.org/3/reference/lexical_analysis.html%23string-literal-concatenation">literal concatenation”</a><a href="https://docs.python.org/3/reference/lexical_analysis.html%23string-literal-concatenation">， https://docs.python.org/3/reference/lexical_analysis.html#string-literal-</a>concatenation)。</p>

<p>❺ 字节序列只能用字节序列正则表达式搜索。</p>

<p>❻ 字符串模式 r&rsquo;\d+&rsquo; 能匹配泰米尔数字和 ASCII 数字。</p>

<p>❼ 字节序列模式 rb&rsquo;\d+&rsquo; 只能匹配 ASCII 字节中的数字。</p>

<p>❽ 字符串模式 r&rsquo;\w+&rsquo; 能匹配字母、上标、泰米尔数字和 ASCII 数字。</p>

<p>❾ 字节序列模式 rb&rsquo;\w+&rsquo; 只能匹配 ASCII 字节中的字母和数字。</p>

<p>© O O    1. bash    Ka</p>

<p>$ python3 ramanujan.py I Text</p>

<p>Ramanujan saw 娜企脉 as 1729 = l3 + 123 = 93 + 103,’</p>

<p>Numbers</p>

<p>str :[’ £b61^.€t» ’，，1729,，’r，.121，f9.，&rsquo;101] bytes: [b.17291, b&rsquo;l1, b&rsquo;lZ., bT9\ b&rsquo;lO1]</p>

<p>Words</p>

<p>str : E&rsquo;Ramanujan1, ’saw，，’    \ ’as\ l172^, &lsquo;I3&rsquo;,    , f931, &lsquo;lG3.]</p>

<p>bytes: [b1 Ramanujan1, t/saw1，b&rsquo;as1,卜1729\ b&rsquo;l1, b&rsquo;lZ1，b&rsquo;91, b&rsquo;101]</p>

<p>$ ■    I</p>

<p>图 4-4：运行示例 4-22 中的 ramanujan.py 脚本时的截图</p>

<p>示例 4-22 是随便举的例子，为的是说明一个问题：可以使用正则表达式搜索字符串和字</p>

<p>节序列，但是在后一种情况中， ASCII 范围外的字节不会当成数字和组成单词的字母。</p>

<p>字符串正则表达式有个 re.ASCII 标志，它让 \w、 \W、 \b、 \B、 \d、 \D、 \s 和 \S 只匹</p>

<p>配 ASCII 字符。详情参阅 re 模块的文档(<a href="https://docs.python.org/3/library/re.html">https://docs+python+org/3/library/re+html</a>)。</p>

<p>另一个重要的双模式模块是 os。</p>

<p>4.9.2 os函数中的字符串和字节序列</p>

<p>GNU/Linux内核不理解Unicode，因此你可能发现了，对任何合理的编码方案来说，在文 件名中使用字节序列都是无效的，无法解码成字符串。在不同操作系统中使用各种客户端</p>

<p>的文件服务器，在遇到这个问题时尤其容易出错。</p>

<p>为了规避这个问题， os 模块中的所有函数、文件名或路径名参数既能使用字符串，也能 使用字节序列。如果这样的函数使用字符串参数调用，该参数会使用 sys.getfilesystemencoding() 得到的编解码器自动编码，然后操作系统会使用相同 的编解码器解码。这几乎就是我们想要的行为，与 Unicode 三明治最佳实践一致。</p>

<p>但是，如果必须处理(也可能是修正)那些无法使用上述方式自动处理的文件名，可以把 字节序列参数传给 os 模块中的函数，得到字节序列返回值。这一特性允许我们处理任何 文件名或路径名，不管里面有多少鬼符，如示例 4-23 所示。</p>

<p>示例 4-23 把字符串和字节序列参数传给 listdir 函数得到的结果</p>

<p>O第二个文件名是“digits-of-n.txt”(有一个希腊字母n)。</p>

<p>© 参数是字节序列， listdir 函数返回的文件名也是字节序列： b&rsquo;\xcf\x80&rsquo; 是希腊字</p>

<p>母n的UTF-8编码。</p>

<p>为了便于手动处理字符串或字节序列形式的文件名或路径名， os 模块提供了特殊的编码 和解码函数。</p>

<p>fsencode(filename)</p>

<p>如果 filename 是 str 类型(此外还可能是 bytes 类型)，使用 sys.getfilesystemencoding() 返回的编解码器把 filename 编码成字节序列；否则， 返回未经修改的 filename 字节序列。</p>

<p>fsdecode(filename)</p>

<p>如果 filename 是 bytes 类型(此外还可能是 str 类型)，使用 sys.getfilesystemencoding() 返回的编解码器把 filename 解码成字符串；否则，返 回未经修改的 filename 字符串。</p>

<p>在 Unix 衍生平台中，这些函数使用 surrogateescape 错误处理方式(参见下述附注 栏)以避免遇到意外字节序列时卡住。 Windows 使用的错误处理方式是 strict。</p>

<p>使用 surrogateescape 处理鬼符</p>

<p>Python 3.1 引入的 surrogateescape 编解码器错误处理方式是处理意外字节序列或 未知编码的一种方式，它的说明参见“PEP 383 — Non-decodable Bytes in System Character Interfaces” (<a href="https://www.python.org/dev/peps/pep-0383/">https://www.python.org/dev/peps/pep-0383/</a>) 。</p>

<p>这种错误处理方式会把每个无法解码的字节替换成 Unicode 中 U+DC00 到 U+DCFF 之 间的码位(Unicode标准把这些码位称为“Low Surrogate Area”)，这些码位是保留 的，没有分配字符，供应用程序内部使用。编码时，这些码位会转换成被替换的字节 值，如示例 4-24 所示。</p>

<p>示例 4-24 使用 surrogateescape 错误处理方式</p>

<p>&gt;&gt;&gt; os.listdir(&lsquo;.&rsquo;) O [&lsquo;abc.txt&rsquo;, &lsquo;digits-of-n.txt&rsquo;]</p>

<p>&gt;&gt;&gt; os.listdir(b&rsquo;.&lsquo;) ©</p>

<p>[b&rsquo;abc.txt&rsquo;, b&rsquo;digits-of-\xcf\x80.txt&rsquo;]</p>

<p>&gt;&gt;&gt; pi_name_bytes = os.listdir(b&rsquo;.&lsquo;)[1] ©</p>

<p>&gt;&gt;&gt; pi_name_str = pi_name_bytes.decode(&lsquo;ascii&rsquo;, &lsquo;surrogateescape&rsquo;) © &gt;&gt;&gt; pi_name_str ❺</p>

<p>&lsquo;digits-of-\udccf\udc80.txt&rsquo;</p>

<p>&gt;&gt;&gt; pi_name_str.encode(&lsquo;ascii&rsquo;, &lsquo;surrogateescape&rsquo;) © b&rsquo;digits-of-\xcf\x80.txt</p>

<p>O列出目录里的文件，有个文件名中包含非ASCII字符。</p>

<p>©假设我们不知道编码，获取文件名的字节序列形式。</p>

<p>© pi_names_bytes是包含n的文件名。</p>

<p>O使用’aseii&rsquo;编解码器和’surrogateeseape&rsquo;错误处理方式把它解码成字符</p>

<p>串。</p>

<p>©各个非ASCII字节替换成代替码位：&rsquo;\xef\x80&rsquo;变成了’\udeef\ude80&rsquo;。</p>

<p>©编码成ASCII字节序列：各个代替码位还原成被替换的字节。</p>

<p>我们对字符串和字节序列的探讨到此结束。如果你坚持读到这里，恭喜你！</p>

<h3 id="4-10-本章小结">4.10 本章小结</h3>

<p>本章首先澄清了人们对一个字符等于一个字节的误解。随着 Unicode 的广泛使用（80% 的 网站己经使用UTF-8），我们必须把文本字符串与它们在文件中的二进制序列表述区分 开，而 Python 3 中这个区分是强制的。</p>

<p>对 bytes、bytearray 和 memoryview 等二进制序列数据类型做了简要概述之后，我们 转到了编码和解码话题，通过示例展示了重要的编解码器；随后讨论了如何避免和处理臭</p>

<p>名昭著的 UnieodeEneodeError 和 UnieodeDeeodeError，以及由于 Python 源码文件编</p>

<p>码错误导致的 SyntaxError。</p>

<p>讨论源码的编码问题时，我表明了自己对非 ASCII 标识符的观点：如果代码基的维护者想 使用包含非 ASCII 字符的人类语言命名标识符，那就去做，除非还想在 Python 2 中运行代</p>

<p>码。但是，如果项目想吸引世界各国的贡献者，那么标识符应该使用英语单词，此时</p>

<p>ASCII 就够用了。</p>

<p>然后，我们说明了在没有元数据的情况下检测编码的理论和实际情况：理论上，做不到这 一点；但是实际上， Chardet 包能够正确处理一些流行的编码。随后介绍了字节序标记， 这是 UTF-16 和 UTF-32 文件中常见的编码提示，某些 UTF-8 文件中也有。</p>

<p>随后的一节演示了如何打开文本文件，这是一项简单的任务，不过有个陷阱：打开文本文 件时， eneoding= 关键字参数不是必需的，但是应该指定。如果没有指定编码，那么程 序会想方设法生成“纯文本”，如此一来，不一致的默认编码就会导致跨平台不兼容性。然</p>

<p>后，我们说明了 Python 用作默认值的几个编码设置，以及如何检测它</p>

<p>们： loeale.getpreferredeneoding（）、sys.getfilesystemeneoding（）、sys.getd 以及标准I/O文件（如sys.stdout.eneoding）的编码。对Windows用户来说，现实不</p>

<p>容乐观：这些设置在同一台设备中往往有不同的值，而且各个设置相互不兼容。而对</p>

<p>GNU/ Linux 和 OS X 用户来说，情况就好多了，几乎所有地方使用的默认值都是 UTF-8。</p>

<p>文本比较是个异常复杂的任务，因为 Unicode 为某些字符提供了不同的表示，所以匹配文</p>

<p>本之前一定要先规范化。说明规范化和大小写折叠之后，我们提供了几个实用函数，你可</p>

<p>以根据自己的需求改编。其中有个函数所做的是极端转换，比如去掉所有重音符号。随 后，我们说明了如何使用标准库中的 loeale 模块正确地排序 Unicode 文本（有一些注意 事项）；此外，还可以使用外部的 PyUCA 包，从而无需依赖捉摸不定的区域配置。</p>

<p>最后简要介绍了 Unicode 数据库（包含每个字符的元数据），还简单讨论了双模式 API （例如re和os模块，这两个模块中的某些函数可以接受字符串或字节序列参数，返</p>

<p>回不同但合适的结果）。</p>

<p><a href="#footnote1">1</a></p>

<p>Python 2 对 sys.setdefaultencoding 函数的使用方式不当， Python 3 的文档中已经没有这个函数。这个函数是供核 心开发者使用的，用于在内部的默认编码未定时设置编码。在 comp.python.devel 邮件列表的那个话题中 (<a href="http://article.gmane.org/gmane.comp.python.devel/109916">http://article.gmane.org/gmane.comp.python.devel/109916</a>)， Marc-Andre Lemburg 说，用户代码一定不能调用 sys.setdefaultencoding函数，而且对CPython来说，它的值在Python 2中只能是’ascii&rsquo;，在Python 3中只能是 &lsquo;utf-8&rsquo; 。</p>

<h3 id="4-11-延伸阅读">4.11 延伸阅读</h3>

<p>Ned Batchelder 在 2012 年的 PyCon US 所做的演讲“Pragmatic Unicode—or—How Do I Stop the Pain?”(<a href="http://nedbatchelder.com/text/unipain.html">http://nedbatchel der+ com/text/unipain+html </a>)非常出色。 Ned 很专业，除了幻灯片 和视频之外，他还提供了完整的文字记录。 Esther Nam 和 Travis Fischer 在 PyCon 2014 做 了一场精影的演讲：“Character encoding and Unicode in Python: How to ( J ° □ °)</p>

<p><a href="http://www.slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863">J</a><a href="http://www.slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863">-</a><a href="http://www.slideshare.net/fischertrav/character-encoding-unicode-how-to-with-dignity-33352863">L with dignity”［幻灯片(http://www+slideshare+net/fischertrav/character-encoding-</a></p>

<p>unicode-how-to-with-dignity-33352863)，视步页(<a href="http://pyvideo+org/pycon-us-2014/character-encoding-and-unicode-in-python+html[">http://pyvideo+org/pycon-us-2014/character-encoding-and-unicode-in-python+html[</a> ](<a href="http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html)[">http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html)[</a>) ］。本章开头那句简短有力的话就是出自这次演](<a href="http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html">http://pyvideo.org/pycon-us-2014/character-encoding-and-unicode-in-python.html</a>) 讲： “人类使用文本，计算机使用字节序列。 ”本书的技术审校之一 Lennart Regebro 在“Unconfusing Unicode: What Is</p>

<p>Unicode?” (<a href="https://regebro.wordpress.com/2011/03/23/unconfusing-unicode-what-is-unicode/">https://regebro+wordpress+com/2011/03/23/unconfusing-unicode-what-is-unicode/</a>) 这篇短文中提出了“Useful Mental Model of Unicode (UMMU) ”。Unicode 是个复杂的标 准， Lennart 提出的 UMMU 是个很好的切入点。</p>

<p>Python 文档中的“Unicode HOWTO”一文(<a href="https://docs.python.org/3/howto/unicode.html">https://docs+python+org/3/howto/unicode+html</a>)从几 个不同的角度对本章所涉及的话题做了讨论，从编码历史到句法细节、编解码器、正则表 达式、文件名和 Unicode 的 I/O 最佳实践(即 Unicode 三明治)，而且各节都给出了大量 参考资料链接。Dive into Python 3是一本非常优秀的书(Mark Pilgrim</p>

<p>著， <a href="http://www.diveintopython3.net">http: //www+diveintopython3 +net</a>) ，其中第 4</p>

<p>章“Strings”(<a href="http://www.diveintopython3.net/strings.html">http://www+diveintopython3+net/strings+html</a>)对 Python 3 对 Unicode 的支持做了 <a href="http://getpython3.com/diveintopython3/case-study-porting-chardet-to-python-3.html">很好的介绍。此外，该书的第 </a><a href="http://getpython3.com/diveintopython3/case-study-porting-chardet-to-python-3.html">15 章( http: //getpython3 +com/diveintopython3/case-study-</a>porting-chardet-to-python-3 +html)阐述了 Chardet 库从 Python 2 移植到 Python 3 的过程，这</p>

<p>是一个宝贵的案例分析，从中可以看出，从旧的 str 类型转到新的 bytes 类型是造成迁 移如此痛苦的主要原因，也是检测编码的库应该关注的重点。</p>

<p>如果你用过Python 2，但是刚接触Python 3，可以阅读Guido van Rossum写的“What&rsquo;s New <a href="https://docs.python.org/3.0/whatsnew/3.0.html%23text-vs-data-instead-of-unicode-vs-8-bit">in Python 3 +0” </a><a href="https://docs.python.org/3.0/whatsnew/3.0.html%23text-vs-data-instead-of-unicode-vs-8-bit">( https: //docs+python+org/3 +0/whatsnew/3 +0+html#text-vs-data-instead-of-unicode-</a>vs-8-bit)，这篇文章简要列出了新版的15点变化，而且附有很多链接。Guido开门见山 地说道： “你自以为知道的二进制数据和 Unicode 知识全都变了。 ”Armin Ronacher 的博客 <a href="http://lucumr.pocoo.org/2013/7/2/the-updated-guide-to-unicode/">文章</a><a href="http://lucumr.pocoo.org/2013/7/2/the-updated-guide-to-unicode/">“The Updated Guide to Unicode on Python” (http://lucumr+pocoo+org/2013/7/2/the-updated-</a>guide-to-unicode/)深入分析了 Python 3中Unicode的一些陷阱(Armin不是很熟衷于 Python 3)。</p>

<p>《Python Cookbook (第 3 版)中文版》(David Beazley 和 Brian K+ Jones 著)的第 2 章“字 符串和文本”中有几个诀窍谈到了 Unicode 规范化、清洗文本，以及在字节序列上执行面 向文本的操作。第 5 章涵盖文件和 I/O， “5+17 将字节数据写入文本文件”指出，任何文本 文件的底层都有一个二进制流，如果需要可以直接访问。之后的“6+11 读写二进制结构的 数组”用到了 struct 模块。</p>

<p>Nick Coghlan的“Python Notes”博客中有两篇文章与本章的话题十分相关：“Python 3 and ASCII Compatible Binary Protocols”(<a href="http://python-">http://python-</a></p>

<p><a href="http://python-notes.curiousefficiency.org/en/latest/python3/binary_protocols.html">notes+curiousefficiency+org/en/latest/python3/binary_protocols+html</a>)和“Processing Text Files in Python 3”(<a href="http://python-">http://python-</a></p>

<p><a href="http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html">notes+curiousefficiency+org/en/latest/python3/text_file_processing+html </a>) 。强烈推荐阅读。</p>

<p>Python 3.5 将为二进制序列引入新的构造方法和方法，而且会废弃目前使用的构造方法签 名(参见“PEP 467—Minor API improvements for binary</p>

<p>sequences”， <a href="https://www.python.org/dev/peps/pep-0467/">https://www+python+org/dev/peps/pep-0467/</a>)。此外，Python 3.5 还会实现“PEP <a href="https://www.python.org/dev/peps/pep-0461/">461—Adding % formatting to bytes and bytearray”</a><a href="https://www.python.org/dev/peps/pep-0461/">(https://www.python.org/dev/peps/pep-</a></p>

<p>0461/)。</p>

<p>Python支持的编码列表参见codecs模块文档的“Standard Encodings”一节 (<a href="https://docs.python.org/3/library/codecs.html%23standard-encodings">https://docs.python.org/3/library/codecs.html#standard-encodings</a>) 。如果需要通过编程的方</p>

<p>式获得那个列表，看看 CPython 源码中 /Tools/unicode/listcodecs.py 脚本 (<a href="https://hg.python.org/cpython/file/6dcc96fa3970/Tools/unicode/listcodecs.py">https://hg+python+org/cpython/file/6dcc96fa3970/Tools/unicode/listcodecs+py</a>)是怎么做的。</p>

<p>Martijn Faassen 的文章“Changing the Python Default Encoding Considered</p>

<p><a href="http://blog.startifact.com/posts/older/changing-the-python-default-encoding-considered-harmful.html">Harmful” </a><a href="http://blog.startifact.com/posts/older/changing-the-python-default-encoding-considered-harmful.html">(http://blog.startifact.com/posts/older/changing-the-python-default-encoding-</a></p>

<p>considered-harmful.html)和 Tarek Ziad^ 的文章“sys.setdefaultencoding Is</p>

<p>Evil” (<a href="http://blog.ziade.org/2008/01/08/syssetdefaultencoding-is-evil/">http://blog+ziade+org/2008/01/08/syssetdefaultencoding-is-evil/</a>)解释了为什么一定不</p>

<p>能修改 sys.getdefaultencoding() 获取的编码，即便知道怎么做也不能改。</p>

<p>Unicode Explained( Jukka K. Korpela 著， O&rsquo;Reilly 出版</p>

<p>社，<a href="http://shop.oreilly.com/product/9780596101213.do">http:&ldquo;shop+oreilly+com/product/9780596101213+do</a>)和 Unicode Demystified (Richard <a href="http://www.informit.com/store/unicode-demystified-a-practical-programmers-guide-to-9780201700527">Gillam </a><a href="http://www.informit.com/store/unicode-demystified-a-practical-programmers-guide-to-9780201700527">著， Addison-Wesl ey 出版社， http://www.informit.com/store/unicode-demystified-a-</a>practical-programmers-guide-to-9780201700527)这两本书不是针对 Python 的，但在我学习 Unicode 相关概念时给了我很大的帮助。 Victor Stinner 的著作 Programming with Unicode(<a href="http://unicodebook.readthedocs.org/index.html">http://unicodebook+readthedocs+org/index+html</a>)是一本免费的自出版图书(遵守 CC BY-SA 协议)，其中讨论了一般的 Unicode 话题，以及主流操作系统和几门编程语言</p>

<p>(包括Python)中的相关工具和API。</p>

<p>W3C 网站中的“Case Folding: An</p>

<p>Introduction” (<a href="https://www.w3.org/International/wiki/Case_folding">https://www+w3+org/International/wiki/Case_folding</a>) ^D“Character Model for <a href="https://www.w3.org/TR/charmod-norm/">the World Wide Web: String Matching and Searching”</a><a href="https://www.w3.org/TR/charmod-norm/">(https://www.w3.org/TR/charmod-</a>norm/)讨论了规范化相关的概念，前者是介绍性文章，后者则是以枯燥的标准用语写就 的工作草案-“Unicode Standard Annex #15—Unicode Normalization</p>

<p>Forms” (<a href="http://unicode.org/reports/tr15/">http://unicode.org/reports/tr15/</a>)也是这种风格。Unicode.org 网站中的“Frequently Asked Questions / Normalization” (<a href="http://www.unicode.org/faq/normalization.html">http://www+unicode+org/faq/normalization.html</a>)更容易理 解，Mark Davis 写的“NFC FAQ” (<a href="http://www.macchiato.com/unicode/nfc-faq">http://www+macchiato+com/unicode/nfc-faq</a>)也是如此。 Mark 是多个 Unicode 算法的作者，在我写作本书时，他还担任 Unicode 联盟的主席。</p>

<p>杂谈</p>

<p>“纯文本”是什么</p>

<p>对于经常处理非英语文本的人来说，“纯文本”并不是指“ASCII”。Unicode词汇表 (<a href="http://www.unicode.org/glossary/%23plain_text">http://www+unicode+org/glossary/#plain_text</a>)是这样定义纯文本的：</p>

<p>只由特定标准的码位序列组成的计算机编码文本，其中不含其他格式化或结构化</p>

<p>信息。</p>

<p>这个定义的前半句说得很好，但是我不同意后半句。 HTML 就是包含格式化和结构化</p>

<p>信息的纯文本格式，但它依然是纯文本，因为 HTML 文件中的每个字节都表示文本 字符（通常使用 UTF-8 编码），没有任何字节表示文本之外的信息。 .png 或 .xsl 文档 则不同，其中多数字节表示打包的二进制值，例如 RGB 值和浮点数。在纯文本中， 数字使用数字符号序列表示。</p>

<p>这本书是我用一种名为 AsciiDoc （<a href="http://www.methods.co.nz/asciidoc/">http://www.methods.co.nz/asciidoc/</a>，很讽刺）的纯 文本格式撰写的，它是 O&rsquo;Reilly 优秀的图书出版平台 Atlas （<a href="https://atlas.oreilly.com/）">https://atlas.oreilly.com/）</a> 的工具链中的一部分。 AsciiDoc 的源文件是纯文本，但用的是 UTF-8 编码，而不是 ASCII。如果不这样做的话，撰写本章必定痛苦不堪。姑且不管名称，AsciiDoc是个 很棒的工具。</p>

<p>Unicode 的世界正在不断扩张，但是有些边缘场景缺少支持工具。因此图 4-1、图 4-3</p>

<p>和图 4-4 中的内容要使用图像，因为渲染本书的字体中缺少一些我想展示的字符。不</p>

<p>过，Ubuntu 14.04和OS X 10.9的终端能正确显示，包括“mojibake”（文字化什）这个</p>

<p>日文的词。</p>

<p>捉摸不透的 Unicode</p>

<p>讨论 Unicode 规范化时，我经常使用“往往”“多数”和“通常”等不确定的修饰语。很遗 憾，我不能提供更可靠的建议，因为 Unicode 规则有很多例外，很难百分之百确定。</p>

<p>例如，（微符号）是“兼容字符”，而Q （欧姆）和A （埃）符号却不是。这种差别 是有真实影响的：NFC规范化形式（推荐用于文本匹配）会把Q （欧姆）替换成 Q （大写希腊字母欧米加），把A （埃）替换成A （上有圆圈的大写字母A）。但 是，作为“兼容字符”的g （微符号）不会替换成视觉等效的g （小写希腊字母^）; 不过在使用更极端的 NFKC 或 NFKD 规范化形式时会替换，但这是有损转换。</p>

<p>我能理解为什么把g （微符号）纳入Unicode，因为latinl编码中有它，如果换成 希腊字母g，会破坏两种编码之间的转换。说到底，这就是微符号是“兼容字符”的原 因。但是，如果是由于兼容原因而没把欧姆和埃符号纳入Unicode，那为什么这两个</p>

<p>符号要存在？ Unicode 己经为 GREEK CAPITAL LETTER OMEGA 和 LATIN CAPITAL LETTER A WITH RING ABOVE 分配了码位，它们的外观一样，而且 NFC 规范化形式 会替换它们。想想看吧。</p>

<p>研究 Unicode 几小时之后，我猜测的原因是： Unicode 异常复杂，充满特殊情况，而</p>

<p>且要覆盖各种人类语言和产业标准策略。</p>

<p>在 RAM 中如何表示字符串</p>

<p>Python 官方文档对字符串的码位在内存中如何存储避而不谈。毕竟，这是实现细节。</p>

<p>理论上，怎么存储都没关系：不管内部表述如何，输出时每个字符串都要编码成字节</p>

<p>序列。</p>

<p>在内存中， Python 3 使用固定数量的字节存储字符串的各个码位，以便高效访问各个 字符或切片。</p>

<p>在 Python 3.3 之前，编译 CPython 时可以配置在内存中使用 16 位或 32 位存储各个码 位。16位是“窄构建”（narrow build） ， 32位是“宽构建”（wide build）。如果想知道</p>

<p>用的是哪个，要查看 sys.maxunieode 的值： 65535 表示“窄构建”，不能透明地处理 U+FFFF 以上的码位。 “宽构建”没有这个限制，但是消耗的内存更多：每个字符占 4 个字节，就算是中文象形文字的码位大多数也只占 2 个字节。这两种构建没有高下之</p>

<p>分，应该根据自己的需求选择。</p>

<p>从 Python 3.3 起，创建 str 对象时，解释器会检查里面的字符，然后为该字符串选择 最经济的内存布局：如果字符都在 latin1 字符集中，那就使用 1 个字节存储每个码 位；否则，根据字符串中的具体字符，选择 2 个或 4 个字节存储每个码位。这是简</p>

<p>述，完整细节参阅“PEP 393—Flexible String</p>

<p>Representation” (<a href="https://www.python.org/dev/peps/pep-0393/">https://www.python.org/dev/peps/pep-0393/</a>) 。</p>

<p>灵活的字符串表述类似于 Python 3 对 int 类型的处理方式：如果一个整数在一个机 器字中放得下，那就存储在一个机器字中；否则解释器切换成变长表述，类似于 Python 2 中的 long 类型。这种聪明的做法得到推广，真是让人欢喜！</p>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/%E6%B5%81%E7%95%85%E7%9A%84-python/03-%E5%AD%97%E5%85%B8%E5%92%8C%E9%9B%86%E5%90%88/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">03 字典和集合</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/02-python/%E6%B5%81%E7%95%85%E7%9A%84-python/05-%E4%B8%80%E7%AD%89%E5%87%BD%E6%95%B0/">
            <span class="next-text nav-default">05 一等函数</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
