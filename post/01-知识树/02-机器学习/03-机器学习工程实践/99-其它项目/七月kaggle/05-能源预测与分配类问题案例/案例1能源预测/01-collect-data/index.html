<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01 collect data - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="需要补充的 还是非常全面的，完整的描述了一个项目从什么都没有，到做出真正可以用的模型之间的过程。 数据链接还是要补充进来的 - 关于天气的信息，如果" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/99-%E5%85%B6%E5%AE%83%E9%A1%B9%E7%9B%AE/%E4%B8%83%E6%9C%88kaggle/05-%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B%E4%B8%8E%E5%88%86%E9%85%8D%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A1%88%E4%BE%8B/%E6%A1%88%E4%BE%8B1%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B/01-collect-data/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="01 collect data" />
<meta property="og:description" content="需要补充的 还是非常全面的，完整的描述了一个项目从什么都没有，到做出真正可以用的模型之间的过程。 数据链接还是要补充进来的 - 关于天气的信息，如果" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/99-%E5%85%B6%E5%AE%83%E9%A1%B9%E7%9B%AE/%E4%B8%83%E6%9C%88kaggle/05-%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B%E4%B8%8E%E5%88%86%E9%85%8D%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A1%88%E4%BE%8B/%E6%A1%88%E4%BE%8B1%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B/01-collect-data/" /><meta property="article:published_time" content="2018-07-25T21:07:13&#43;00:00"/>
<meta property="article:modified_time" content="2018-07-25T21:07:13&#43;00:00"/>
<meta itemprop="name" content="01 collect data">
<meta itemprop="description" content="需要补充的 还是非常全面的，完整的描述了一个项目从什么都没有，到做出真正可以用的模型之间的过程。 数据链接还是要补充进来的 - 关于天气的信息，如果">


<meta itemprop="datePublished" content="2018-07-25T21:07:13&#43;00:00" />
<meta itemprop="dateModified" content="2018-07-25T21:07:13&#43;00:00" />
<meta itemprop="wordCount" content="1718">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="01 collect data"/>
<meta name="twitter:description" content="需要补充的 还是非常全面的，完整的描述了一个项目从什么都没有，到做出真正可以用的模型之间的过程。 数据链接还是要补充进来的 - 关于天气的信息，如果"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">最新</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">最新</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01 collect data</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-07-25 </span>
        
        <span class="more-meta"> 1718 words </span>
        <span class="more-meta"> 4 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#需要补充的">需要补充的</a></li>
<li><a href="#获取数据">获取数据</a></li>
<li><a href="#直接下载数据">直接下载数据</a></li>
<li><a href="#清洗和了解数据">清洗和了解数据</a></li>
<li><a href="#建立-天气站-weather-stations-的映射关系">建立<strong>天气站/weather stations</strong>的映射关系</a></li>
<li><a href="#把数据按区域切分">把数据按区域切分</a></li>
</ul></li>
<li><a href="#输出2012年的数据用于测试">输出2012年的数据用于测试</a>
<ul>
<li><a href="#下载nyiso的预测结果">下载NYISO的预测结果</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h2 id="需要补充的">需要补充的</h2>

<ul>
<li>还是非常全面的，完整的描述了一个项目从什么都没有，到做出真正可以用的模型之间的过程。</li>
<li>数据链接还是要补充进来的
-</li>
</ul>

<p>关于天气的信息，如果是你在公司里工作做项目，实际上不一定有人提供好你给的，比如滴滴要做一些需求，他需要天气数据就直接从气象局买的，有些是可以自己采集到的。</p>

<h2 id="获取数据">获取数据</h2>

<p>这个项目的数据是从 New York State Independent Service Authority (NYISO) 获得的。他们把所有的历史数据都以 CSV 格式存储在 FTP 服务器上。</p>

<p>想了解更多的信息可以戳下面的页面: <a href="http://www.nyiso.com/public/markets_operations/market_data/load_data/index.jsp">http://www.nyiso.com/public/markets_operations/market_data/load_data/index.jsp</a></p>

<p>数据也可以从 <a href="http://mis.nyiso.com/public/P-58Blist.htm">这个页面</a> 直接获得。</p>

<p>整个纽约州的电能由12个“区域”生产和提供，这12个区有自己独立的能源市场。下面这张图可以给你一个直观的印象，大概的一个分布状况。我们这里采集到的数据，也会按照这12个区域做分割，其中区域的名称会写在&rdquo;name&rdquo;字段里。<span style="color:red;">嗯。</span></p>

<p><img src="http://images.iterate.site/blog/image/180724/FaekHBH3AG.png?imageslim" alt="mark" /></p>

<pre><code class="language-python">import zipfile
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
import urllib
import os
import pandas as pd
import numpy as np
</code></pre>

<h2 id="直接下载数据">直接下载数据</h2>

<p>我们直接找到数据源下载纽约州 2001-2015 年的相关数据。</p>

<p>直接拉下来的数据会以 zip 形式存储在 <code>../data/nyiso</code> 文件夹下。</p>

<p>然后咱们解压缩打包文件到 <code>../data/nyiso/all/raw_data</code> 文件夹。</p>

<pre><code class="language-python">print &quot;download and unzipping...&quot;

# 把需要遍历的日期都产生出来
dates = pd.date_range(pd.to_datetime('2001-01-01'), \
                       pd.to_datetime('2015-12-31'), freq='M')

for date in dates:
    url = 'http://mis.nyiso.com/public/csv/pal/{0}{1}01pal_csv.zip'.format(date.year, str(date.month).zfill(2))
    urllib.urlretrieve(url, &quot;../data/nyiso/{0}&quot;.format(url.split('/')[-1]))


</code></pre>

<pre><code>download and unzipping...
</code></pre>

<p>解压缩：</p>

<pre><code class="language-python">zips = []
for file in os.listdir(&quot;../data/nyiso&quot;):
    if file.endswith(&quot;.zip&quot;):
        zips.append(file)

def unzip(source_filename, dest_dir):
    with zipfile.ZipFile(source_filename) as zf:
        try:
            zf.extractall(dest_dir)
        except:
            print source_filename
            return

for z in zips:
    try:
        unzip('../data/nyiso/' + z, '../data/nyiso/all/raw_data')
        print '../data/nyiso/' + z + &quot;extract done!&quot;
    except:
        print '../data/nyiso/' + z
        continue
</code></pre>

<pre><code>../data/nyiso/20010101pal_csv.zip
../data/nyiso/20010201pal_csv.zip
../data/nyiso/20010301pal_csv.zip
../data/nyiso/20010401pal_csv.zip
../data/nyiso/20010501pal_csv.zipextract done!
../data/nyiso/20010601pal_csv.zipextract done!
../data/nyiso/20010701pal_csv.zipextract done!
../data/nyiso/20010801pal_csv.zipextract done!
../data/nyiso/20010901pal_csv.zipextract done!
../data/nyiso/20011001pal_csv.zipextract done!
... 此处略去很多
../data/nyiso/20150901pal_csv.zipextract done!
../data/nyiso/20151001pal_csv.zipextract done!
../data/nyiso/20151101pal_csv.zipextract done!
../data/nyiso/20151201pal_csv.zipextract done!
</code></pre>

<p>文件多了处理起来麻烦，咱们整合到一个合并的文件里吧: combined_nyiso.csv</p>

<p>把文件的地址放到一个 list 里面：</p>

<pre><code class="language-python">csvs = []
for file in os.listdir(&quot;../data/nyiso/all/raw_data&quot;):
    if file.endswith(&quot;pal.csv&quot;):
        csvs.append(file)
</code></pre>

<p>把 csv 合并起来。</p>

<pre><code class="language-python">fout=open(&quot;../data/nyiso/all/combined_iso.csv&quot;,&quot;a&quot;)

# 第一个文件咱们保存头部column name信息:
for line in open(&quot;../data/nyiso/all/raw_data/&quot;+csvs[0]):
    fout.write(line)# 把 column 信息保存下来

# 后面的部分可以跳过 headers:
for file in csvs[1:]:
    f = open(&quot;../data/nyiso/all/raw_data/&quot;+file)
    f.next() # 跳过 header 开始读取
    for line in f:
         fout.write(line)
    f.close() # 关闭文件

fout.close()
</code></pre>

<p>为什么手写一个文件合并呢？因为数据量非常大，而 pandas 的合并都是要放到内存里的，因此内存会爆掉。而这样的手写，每次只会加载一个文件。<span style="color:red;">嗯。</span></p>

<h2 id="清洗和了解数据">清洗和了解数据</h2>

<p>这里总共有 14 年的数据，我们把它们放到一个完整的 pandas 数据帧(dataframe)里。</p>

<pre><code class="language-python">df = pd.read_csv(&quot;../data/nyiso/all/combined_iso.csv&quot;)
</code></pre>

<p>这里所谓的数据清洗实际上是一个数据的选择过程，我们留下来我们感兴趣的 4 列: timestamp, region name, id, and load (说明一下，load 是电力需求，单位是 <strong>兆瓦/Megawatts</strong> ).</p>

<pre><code class="language-python">cols = df.columns
df.columns = [col.lower().replace(' ', '') for col in cols]
df = df[['timestamp', 'name', 'ptid', 'load']]
</code></pre>

<p>重新把需要的数据写回 csv 文件中</p>

<pre><code class="language-python">df.to_csv('../data/nyiso/all/combined_iso.csv', index=False)
</code></pre>

<p>看一下具体有哪些区域：之所以要看有哪些区，是因为我们要看看这些区的天气状况。</p>

<pre><code class="language-python">df.name.unique()
</code></pre>

<pre><code>array(['CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL', 'MHK VL',
       'MILLWD', 'N.Y.C._LONGIL', 'NORTH', 'WEST', 'LONGIL', 'N.Y.C.'], dtype=object)
</code></pre>

<h2 id="建立-天气站-weather-stations-的映射关系">建立<strong>天气站/weather stations</strong>的映射关系</h2>

<p>我们的数据帧里区域的名称已经有了，我们要建立起它们和对应的城市还有天气站之间的映射关系（简单地理解就是需要关联几个数据表用）。我们直接把它们放在一个<code>python dict/字典</code>里，一会儿下一个 notebook 会用到这个映射关系。</p>

<p>这些区在气象局的网站上并不会一定以这些名字来命名，所以这里我们建立了映射表。</p>

<p><span style="color:red;">看来 python 的基本语法在数据分析的时候也要掌握，因为这种基础的构造数据集的操作和一些不能使用 pandas 直接操作的也要自己来做。</span></p>

<pre><code class="language-python">regions = list(df.name.unique())
region_names = ['Capital', 'Central', 'Dunwoodie', 'Genese', 'Hudson Valley', 'Long Island', 'Mohawk Valley', 'Millwood', 'NYC', 'North', 'West']
cities = ['Albany', 'Syracuse', 'Yonkers', 'Rochester', 'Poughkeepsie', 'NYC', 'Utica', 'Yonkers', 'NYC', 'Plattsburgh', 'Buffalo']
weather_stations = ['kalb', 'ksyr', 'klga', 'kroc', 'kpou', 'kjfk', 'krme', 'klga', 'kjfk', 'kpbg', 'kbuf']
</code></pre>

<pre><code class="language-python">weather_dict = dict(zip(regions, zip(weather_stations, region_names, cities)))
weather_dict
</code></pre>

<pre><code>{'CAPITL': ('kalb', 'Capital', 'Albany'),
 'CENTRL': ('ksyr', 'Central', 'Syracuse'),
 'DUNWOD': ('klga', 'Dunwoodie', 'Yonkers'),
 'GENESE': ('kroc', 'Genese', 'Rochester'),
 'HUD VL': ('kpou', 'Hudson Valley', 'Poughkeepsie'),
 'LONGIL': ('kbuf', 'West', 'Buffalo'),
 'MHK VL': ('kjfk', 'Long Island', 'NYC'),
 'MILLWD': ('krme', 'Mohawk Valley', 'Utica'),
 'N.Y.C._LONGIL': ('klga', 'Millwood', 'Yonkers'),
 'NORTH': ('kjfk', 'NYC', 'NYC'),
 'WEST': ('kpbg', 'North', 'Plattsburgh')}
</code></pre>

<pre><code class="language-python">import cPickle as pickle
pickle.dump(weather_dict, open('weather_dict.pkl','wb'))
</code></pre>

<h2 id="把数据按区域切分">把数据按区域切分</h2>

<p>我们把数据按照 12 个区进行切分，更细致的切分可以让天气数据更精确。同时在测试阶段，一个区一个统一的文件也会方便很多。</p>

<pre><code class="language-python">for region in weather_dict.keys():
    subset = df[df.name == region].copy()
    filename = weather_dict[region][1].lower().replace(' ', '') + '.csv'
    subset.to_csv('../data/nyiso/all/' + filename, index=False)
</code></pre>

<p>其中的一个文件大概长这样</p>

<table>
<thead>
<tr>
<th></th>
<th>timestamp</th>
<th>name</th>
<th>ptid</th>
<th>load</th>
</tr>
</thead>

<tbody>
<tr>
<td>0</td>
<td>2012-01-01 00:00:00</td>
<td>CAPITL</td>
<td>61757</td>
<td>1084.4</td>
</tr>

<tr>
<td>1</td>
<td>2012-01-01 00:05:00</td>
<td>CAPITL</td>
<td>61757</td>
<td>1055.3</td>
</tr>

<tr>
<td>2</td>
<td>2012-01-01 00:10:00</td>
<td>CAPITL</td>
<td>61757</td>
<td>1056.6</td>
</tr>

<tr>
<td>3</td>
<td>2012-01-01 00:15:00</td>
<td>CAPITL</td>
<td>61757</td>
<td>1050.8</td>
</tr>

<tr>
<td>4</td>
<td>2012-01-01 00:20:00</td>
<td>CAPITL</td>
<td>61757</td>
<td>1050.8</td>
</tr>
</tbody>
</table>

<h1 id="输出2012年的数据用于测试">输出2012年的数据用于测试</h1>

<pre><code class="language-python">print &quot;output 2012 data for test...&quot;
capital = pd.read_csv(&quot;../data/nyiso/all/capital.csv&quot;)
#capital[capital.timestamp &lt; pd.to_datetime('2013-01-01')].to_csv('load2012.csv', index=False)
capital[capital.timestamp &lt; '2013-01-01'].to_csv('load2012.csv', index=False)
csvs = []
for file in os.listdir(&quot;../data/wunderground/kalb&quot;):
    if file.startswith(&quot;2012&quot;):
        csvs.append(file)
print csvs
fout=open(&quot;weather2012.csv&quot;,&quot;a&quot;)

# 写入整个文件:
for line in open(&quot;../data/wunderground/kalb/&quot;+csvs[0]):
    fout.write(line)
# 跳过头部:
for file in csvs[1:]:
    f = open(&quot;../data/wunderground/kalb/&quot;+file)
    f.next()
    for line in f:
         fout.write(line)
    f.close()
fout.close()
</code></pre>

<pre><code>output 2012 data for test...
</code></pre>

<h2 id="下载nyiso的预测结果">下载NYISO的预测结果</h2>

<p>NYISO会公布一个 &ldquo;day-ahead&rdquo; 预测数据（每次提前一天他们都会预测下一条的用电需求状况）。 如果咱们能够比公司做的预测系统效果还要好，那妥妥的表示咱们的模型有比较好的效果。 我们先把它在 2014-2016 年的预测结果下载下来，以便最后比对。</p>

<p>网址如下: <a href="http://www.nyiso.com/public/markets_operations/market_data/custom_report/index.jsp?report=load_forecast">http://www.nyiso.com/public/markets_operations/market_data/custom_report/index.jsp?report=load_forecast</a></p>

<pre><code class="language-python">nyiso_forecast = pd.read_csv('../data/nyiso_dayahead_forecasts/forecast_2014_2016.csv')
</code></pre>

<pre><code class="language-python">len(nyiso_forecast)
</code></pre>

<pre><code>211442
</code></pre>

<pre><code class="language-python">nyiso_forecast.columns = ['timestamp', 'zone', 'forecast', 'gmt']
</code></pre>

<p>OK，到这里，我们已经有实际的数据，而且是已经按照区域切分好了，还有 nyiso 公司的预测数据。</p>

<p>下面，我们就要准备一些特征了，首先，是天气特征。</p>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/99-%E5%85%B6%E5%AE%83%E9%A1%B9%E7%9B%AE/%E4%B8%83%E6%9C%88kaggle/05-%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B%E4%B8%8E%E5%88%86%E9%85%8D%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A1%88%E4%BE%8B/%E6%A1%88%E4%BE%8B2harvard-energy-prediction/part-4.3-prediction-gaussian-process-regression-dec10/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Part 4.3 Prediction-Gaussian Process Regression-DEC10</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/99-%E5%85%B6%E5%AE%83%E9%A1%B9%E7%9B%AE/%E4%B8%83%E6%9C%88kaggle/05-%E8%83%BD%E6%BA%90%E9%A2%84%E6%B5%8B%E4%B8%8E%E5%88%86%E9%85%8D%E7%B1%BB%E9%97%AE%E9%A2%98%E6%A1%88%E4%BE%8B/%E6%A1%88%E4%BE%8B2harvard-energy-prediction/part-4.44.5-prediction-random-forests-and-k-nearest-neighbours-dec10/">
            <span class="next-text nav-default">Part 4.4&amp;4.5 Prediction-Random Forests and K-Nearest Neighbours-DEC10</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
