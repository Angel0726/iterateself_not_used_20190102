<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01 回归的原理 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="需要补充的 这个还没有进行整理 第9章利用Caffe做回归 第9章实现了一个基于Caffe的用卷积神经网络做回归的例子，并介绍了如何制作 HDF5 格式数据" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/09-%E5%88%A9%E7%94%A8-caffe-%E5%81%9A%E5%9B%9E%E5%BD%92/01-%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8E%9F%E7%90%86/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="01 回归的原理" />
<meta property="og:description" content="需要补充的 这个还没有进行整理 第9章利用Caffe做回归 第9章实现了一个基于Caffe的用卷积神经网络做回归的例子，并介绍了如何制作 HDF5 格式数据" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/09-%E5%88%A9%E7%94%A8-caffe-%E5%81%9A%E5%9B%9E%E5%BD%92/01-%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8E%9F%E7%90%86/" /><meta property="article:published_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta itemprop="name" content="01 回归的原理">
<meta itemprop="description" content="需要补充的 这个还没有进行整理 第9章利用Caffe做回归 第9章实现了一个基于Caffe的用卷积神经网络做回归的例子，并介绍了如何制作 HDF5 格式数据">


<meta itemprop="datePublished" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="5856">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="01 回归的原理"/>
<meta name="twitter:description" content="需要补充的 这个还没有进行整理 第9章利用Caffe做回归 第9章实现了一个基于Caffe的用卷积神经网络做回归的例子，并介绍了如何制作 HDF5 格式数据"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">最新</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">最新</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01 回归的原理</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-08-29 </span>
        
        <span class="more-meta"> 5856 words </span>
        <span class="more-meta"> 12 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#需要补充的">需要补充的</a>
<ul>
<li>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#第9章利用caffe做回归">第9章利用Caffe做回归</a></li>
<li><a href="#闢na醱汸蝙钃山鼸-国">■闢na醱汸蝙钃山鼸；国</a></li>
<li><a href="#⑥聚曜國蟛韉囑sum鈐-觀誦鵬職繼觀-騙醒龍麵醺">■⑥聚曜國蟛韉囑sum鈐 觀誦鵬職繼觀 騙醒龍麵醺</a></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#相关资料">相关资料</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h1 id="需要补充的">需要补充的</h1>

<ul>
<li>这个还没有进行整理</li>
</ul>

<h5 id="第9章利用caffe做回归">第9章利用Caffe做回归</h5>

<p>第9章实现了一个基于Caffe的用卷积神经网络做回归的例子，并介绍了如何制作 HDF5 格式数据，如何用GPU批量对数据进行运算，以及如何实现可视化训练的模型。</p>

<p><span style="color:red;">想知道怎么制作 HDF5 格式的数据？以及怎么使用 GPU 批量对数据进行运算。</span></p>

<p>通过前面两章的例子，我们已经了解了用Caffe做分类的基本流程。在机器学习的应 用中，除了分类任务，回归(regression)任务也是很常见的，比如人脸关键点回归，物体 位置回归，甚至通过人脸预测年龄的回归等。本章将通过一个玩具小例子了解如何在Caffe 中做回归。</p>

<p>9.1回归的原理</p>

<p>经典的回归场景就是要让模型预测的实数值和标签的值尽量一致，因为没有了类别， 所以损失函数也变得不一样。本节一起来了解Caffe中用于计算损失函数的欧式距离和对 应的 EuclideanLossLayer 层。</p>

<p>9.1.1预测值和标签值的欧式距离</p>

<p>用于分类的经典的卷积神经网络结构,一般是前面部分是若干各种方式连接的卷积层， 最后接一两个全连接层，得到一个向量，然后经过Softmax层输出预测的分类概率。如果 把图像的矩阵也看成是一个向量，卷积神经网络中无论是卷积层还是全连接层，就是不断 地把一个向量变换成另一个向量。事实上对于单个的filter/feature channel，Caffe里最基础 的卷积实现就是向量和矩阵的乘法，可参考<a href="https://github.eom/Yangqing/caffe/wiki/">https://github.eom/Yangqing/caffe/wiki/</a> Convolution-in-Caffe:-a-memo o</p>

<p>最后输出就是一个把指定分类的类目数作为维度的概率向量。因为神经网络的风格算 是黑盒子学习，所以很直接的想法就是把经过Softmax层之前的向量的值直接拿来做回归， 最后优化的目标函数直接基于实数值的误差。</p>

<p>在第2.5.5节中，讲线性回归的时候已经讲过，可以用预测值和标签值的差的平方作为 损失函数。那么如果每个样本要回归的标签有多个呢？自然我们考虑把每个标签值和预测 值的差的平方累积起来：</p>

<p>1 W    n</p>

<p>Z=1</p>

<p>如果把多个标签合一起看成是一个向量的话，只需要神经网络输出的预测值也是一个 等维度的向量，则计算的损失函数其实就相当于这两个向量之间欧氏距离的平方，也可以 看作是差向量的L2范数(L2norm)。</p>

<p>9.1.2 EuclideanLoss 层</p>

<p>执行9.1.1节说的实数向量的回归要用到Caffe中的EuclideanLoss层，这个层可以把 某一个层输出，和设定好的多维度实数值标签作为输入，然后计算差向量的L2范数作为 loss。用法在形式上和SoftmaxWithLoss基本相似。</p>

<p>9.2预测随机噪声的频率</p>

<p>本节用一个预测随机噪声频率的玩具例子，来说明用Caffe做回归的基本流程。</p>

<p>9.2.1生成样本：随机噪声</p>

<p>首先需要生成如图9-1中所示的随机噪声图像。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-267.jpg" alt="img" /></p>

<p>OOO59_O.97_O.82.jpg</p>

<p>00000_0.34_0.92.jpg</p>

<p>00001_0.57_0.12.jpg</p>

<p>图9-1横纵轴频率随机的二值噪声图像</p>

<p>如图9-1所示，就是要产生随机噪声，同时也不是完全无规律的噪声，而是沿着横纵</p>

<p>两个方向有不同频率。比如左上角的图，是个低频噪声的例子，其中沿着横轴的频率比起</p>

<p>纵轴稍高一些，而左下角则是个高频噪声的例子。频率的高低用一个0〜1之间的数字表示,</p>

<p>0表示完全没有变化，1表示每个像素之间都是不相关的最高频率变化。如图9-1中，文件</p>

<p>名的第二和第三个字段分别就是定义的频率沿着横轴和纵轴的值。这个例子中使用了</p>

<p>100x100的灰度图像，用一种非常简单的思路产生不同频率噪声。首先用随机整数发生器</p>

<p>得到一个1〜100的随机数，分别作为原始噪声的横轴和纵轴长度。然后按照这个大小产生</p>

<p>一个0〜1之间均匀分布的随机浮点数矩阵作为原始图像。最后把这个随机噪声的原始图像</p>

<p>放大到100x100就得到了不同频率的噪声图像。根据这个思路产生图像的代码如下：</p>

<p>import os import sys import datetime import cv2</p>

<p>from multiprocessing import Process, cpu_count import numpy as np</p>

<p>import matplotlib.pyplot as pit</p>

<p>#定义长宽和样本数量</p>

<p>H_IMG, W_IMG =    100,    100</p>

<p>SAMPLE_SIZE =    70000</p>

<p>#最后岳存样本的文件夹名</p>

<p>SAMPLES_DIR = &lsquo;samples*</p>

<p>#产生—噪声并保存到samples文件夹</p>

<p>def make_noise(index):</p>

<p>#    _随机生成宽和高</p>

<p>h = np.random.randint(1, H_IMG) w = np.random.randint(1, W_IMG)</p>

<p>#生成原始噪声图像</p>

<p>noise = np.random.random( (h, w))</p>

<p>#用cubic插值放大让图像显得更平滑</p>

<p>noisy_img = cv2.resize(noise, (H_IMGZ W—IMG), interpolation。 cv2.INTER_CUBIC)</p>

<p>#    1始图像的宽高和要放大到的宽高的比值就是相对频率</p>

<p>fx = float(w)    / float(W—IMG)</p>

<p>fy = float(h)    / float(H_IMG)</p>

<p>#文件名包含3个字段，分别是序_号、横轴频率和纵轴频率</p>

<p>filename =    <em>{}/{：0&gt;5d}<em>{}</em>{}.jpg</em>.format(SAMPLES_DIR, index, fx,</p>

<p>fy)</p>

<p>pit. imsave (filename, noisy_img, cmap= * gray *)    /</p>

<p>def make_noises (iO, il):</p>

<p>#    _产生下标iO到il的噪声图像</p>

<p>np. random, seed(datetime.datetime.now() .microsecond) for i in xrange (iO, il):</p>

<p>make_noise (i)</p>

<p>print (* Noises from { } to { } are made ! * . format (i0 + l, il)) sys.stdout.flush()</p>

<p>def main ():</p>

<p>#建立保存图像的文件夹</p>

<p>cmd = &lsquo;mkdir -p {}*.format(SAMPLES_DIR) os.system(cmd)</p>

<p>#默认获取所有可用CPU核数作为多进程数量 n_procs = cpu_count()</p>

<p>print(*Making noises with {} processes &hellip; 1.format(n_procs))</p>

<p>#产生尽量均匀的任务列表</p>

<p>length = float (S7kMPLE_SIZE) /float (n_procs)</p>

<p>indices = [int (round (i * length)) for i in range (n^procs + 1)]</p>

<p>#定义每个进程</p>

<p>processes = [Process(target=make_noises, args=(indices[i]z indices [i+1])) for i in range(n_procs)]</p>

<p>for p in processes: p. start()</p>

<p>for p in processes: p. join()</p>

<p>print(&lsquo;Done!&rsquo;)</p>

<p>if <em>name</em> ==    *<em>main</em>&lsquo;:</p>

<p>main ()</p>

<p>运行这段代码就得到了一个叫做samples的文件夹，这里照搬MNIST的习惯，一共7 万个样本。</p>

<p>9.2.2制作多标签HDF5数据</p>

<p>对于多标签+回归的任务，最简单的生成数据的方式还是HDF5。对于9.2.1节中产生 的7万个样本，还是划分出5万作为训练集，1万作为验证集，1万作为测试集。首先产生 3个数据集的列表，代码如下：</p>

<p>import os</p>

<p>#取文件名不包含后缀部分，用下画线分隔后两个字段</p>

<p>filename2score = lambda x: x[:x.rfind(•.&lsquo;)].split (•_•) [-2:]</p>

<p>#列出samples下所有图片文件名 filenames = os.listdir(* samples *)</p>

<p>#创建训练集列表</p>

<p>with open(* train.txt&rsquo;,    * w *) as f_train_txt:</p>

<p>for filename in filenames[:50000]:</p>

<p>fx, f y = filename2score(filename)</p>

<p>line =    &lsquo;samples/{}    {}    {}\nformat(filename, fx,</p>

<p>fy)</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-272.jpg" alt="img" /></p>

<p>f_train_txt.write(line)</p>

<p>#创建验证集列表_</p>

<p>with open(* val.txt&rsquo;,    * w1) as f_val_txt:</p>

<p>for filename in filenames[50000:60000]:</p>

<p>fx, f y = filename2score(filename)</p>

<p>line =    * samples/{}    { }    {}\n1.format(filename, fx,</p>

<p>f_val_txt.write(line)</p>

<p>#创建测试集列表</p>

<p>with open(* test.txt&rsquo;,    * w *) as f_test_txt:</p>

<p>for filename in filenames[60000:]:</p>

<p>line =    * samples/{}\n *.format(filename)</p>

<p>f_test_txt.write(line)</p>

<p>注意，和训练集/验证集不同的是，测试集只有文件路径列表没有标签。执行后，就得 到了 train.txt, val.txt和test.txt包含了文件路径和对应的频率的值，格式如下：</p>

<p>samples/04375_0.31_0.35.jpg 0.31 0.35 samples/08750_0.22_0.85.jpg 0.22 0.85 samples/26250_0.58_0.36.jpg 0.58 0.36</p>

<p>基于这3个txt文件中的列表，接下来产生对应的HDF5文件。</p>

<p>import sys</p>

<p>import numpy as np</p>

<p>import matplotlib.pyplot as pit</p>

<p>import h5py</p>

<p>#图像大小</p>

<p>IMAGE_SIZE =    (100,    100)</p>

<p>#减遍值帮助收敛</p>

<p>MEAN_VALUE =    128</p>

<p>#获 1输入的图像和标签列表文件名</p>

<p>filename = sys.argv[1]</p>

<p>#获取文件名不包含后缀部分作为数据集名称</p>

<p>setname, ext = filename.split(<em>.</em>)</p>

<p>#读取所有行</p>

<p>with open (filename, * r *) as f: lines = f.readlines()</p>

<p>#乱序</p>

<p>np.random.shuffle(lines)</p>

<p>#样本数量</p>

<p>sample_size = len(lines)</p>

<p>#图像＞据格式，样本总量X通道数X高X宽</p>

<p>imgs = np.zeros((sample_size, 1,)    + IMAGE一SIZE, dtype=np.float32)</p>

<p>#频率标签格式，样本总量x _标签数</p>

<p>freqs = np.zeros((sample_size, 2), dtype=np.float32)</p>

<p>#生成h5文件名</p>

<p>h5一filename =    *{ } «h5 *.format(setname)</p>

<p># _将数据写入h5文件，图像对应的数据名称为data,频率标签对应的数据名称为freq</p>

<p>with h5py. File (h5_f ilename, * w *) as h:</p>

<p>for i, line in enumerate (lines):</p>

<p>image_name, fx, fy = line[:-1]•split ()</p>

<p>#因$直接用plt.imread()读取的图片是三通道，所以只取第一个通道 img = pit. imread (image_name) [:,    :,    0] . astype (np. f loat32)</p>

<p>img = img. reshape ( (1,    ) -i-img. shape)</p>

<p>img -= MEAN_VALUE imgs[i]    = img</p>

<p>freqs[i]    = [float(fx), float(fy)]</p>

<p>if (i+1)    %    1000    ==    0:</p>

<p>print(&lsquo;Processed { } images!&rsquo;.format(i+1)) h. create_dataset(* data <em>, data=imgs) h.create一dataset(&lsquo;freq</em>, data=freqs)</p>

<p>#生成h5文件列爰</p>

<p>with open (* {}_h5 . txt&rsquo; . format (setname) ,    &lsquo; w *) as f:</p>

<p>f.write(h5_filename)</p>

<p>将段代码保存为gen_hdf5.py,然后依次执行以下命令：</p>

<p>» python gen_hef5.py train.txt</p>

<p>&gt;&gt; python gen_hdf5.py val.txt</p>

<p>这样就得到了训练集和验证集的h5文件及对应的列表文件。</p>

<p>9.2.3网络结构和Solver定义</p>

<p>网络结构是试着在LeNet-5上加了 -层，然后改动一下卷积核大小和stride，让最后进 入全连接前的维度不会太高。另外为了方便回归到0〜1之间，最后一层的激活函数是 Sigmoid()，最后再和标签一起在EuclideanLoss层：</p>

<p>name : &ldquo;RegressionExample** layer {</p>

<p>name: &ldquo;data&rdquo; type: &ldquo;HDF5Data&rdquo; top: &ldquo;data&rdquo; top: &ldquo;freq&rdquo; include {</p>

<p>phase: TRAIN</p>

<p>}</p>

<p>hdf 5_data_parain {</p>

<p>source : &lsquo;*train_h5 . txtn batch_size:    50</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;data&rdquo; type: &ldquo;HDF5Data&rdquo; top: &ldquo;data&rdquo; top: &ldquo;freq&rdquo; include {</p>

<p>phase: TEST</p>

<p>}</p>

<p>hdf 5_data_param {</p>

<p>source: &ldquo;val_h5.txt&rdquo; batch_size:    50</p>

<p>}</p>

<p>layer {</p>

<p>name: nconvln type: &ldquo;Convolution&rdquo; bottom: &ldquo;data&rdquo; top:    &ldquo;convl&rdquo;</p>

<p>param {</p>

<p>stride: 2 weight_filler {</p>

<p>typp: &ldquo;gaussian” std: 0.01</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: ’’constant&rdquo; value:    0</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;relul*&rsquo; type: &ldquo;ReLU&rdquo; bottom: ’’convl&rdquo; top: &ldquo;convl&rdquo;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;pooll&rdquo; type: &ldquo;Pooling&rdquo; bottom: &ldquo;convl&rdquo; top: &ldquo;pooll&rdquo; pooling_param {</p>

<p>pool: MAX kernel_size:    3</p>

<p>stride: 2</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;conv2&rdquo; type:    &ldquo;Convolution&rdquo;</p>

<p>bottom: &ldquo;pooll&rdquo; top:    &ldquo;conv2&rdquo;</p>

<p>param {</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: nrelu2&rdquo; type:    &ldquo;ReLU&rdquo;</p>

<p>bottom:    &ldquo;conv2&rdquo;</p>

<p>top: nconv2&rdquo;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;pool2” type: &ldquo;Pooling&rdquo; bottom: &ldquo;conv2&rdquo; top: &ldquo;pool2n pooling_param {</p>

<p>pool: MAX kernel_size:    3</p>

<p>stride:    2</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: nconv3&rdquo; type:    &ldquo;Convolution**</p>

<p>bottom: &ldquo;pool2&rdquo; top: &ldquo;conv3&rdquo; param {</p>

<p>}</p>

<p>convolution_param { num_output:    128</p>

<p>pad: 1</p>

<p>kernel_size:    3</p>

<p>weight_filler {</p>

<p>type: &ldquo;gaussian&rdquo; std: 0.01</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: &ldquo;constant&rdquo; value:    0</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name:    ** relu3*&rsquo;</p>

<p>type: &ldquo;ReLUn bottom: nconv3&rdquo; top: &ldquo;conv3&rdquo;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;pool3&rdquo; type: &ldquo;Pooling*， bottom: &ldquo;conv3&rdquo; top: &ldquo;pool3&rdquo; pooling_param {</p>

<p>weight_filler {</p>

<p>type: &ldquo;gaussian&rsquo;’ std: 0.005</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: &ldquo;constant&rdquo; value:    0</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: nrelu4&rdquo; type: &ldquo;ReLU&rdquo; bottom: &ldquo;fc4&rdquo; top: &ldquo;fc4&rdquo;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;drop4&rdquo; type:    &ldquo; Dropout&rsquo;*</p>

<p>weight_filler {</p>

<p>type: &ldquo;gaussian&rdquo; std: 0.005</p>

<p>}</p>

<p>bias一filler {</p>

<p>type: &ldquo;constant&rdquo; value:    0</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;sigmoid5&rdquo; type: &ldquo;Sigmoid&rdquo; bottom: &ldquo;fc5&rdquo; top: &ldquo;pred&rdquo;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;loss&rdquo;</p>

<p>type: &ldquo;EuclideanLoss&rdquo;</p>

<p>bottom: &ldquo;pred&rdquo;</p>

<p>bottom: &ldquo;freq&rdquo;</p>

<p>top: &ldquo;loss&rdquo;</p>

<p>}</p>

<p>用Caffe的draw net.py得到的可视化结构如图9-2所示。</p>

<p>图9-2训练噪声图像频率打分的网络结构</p>

<p>相应的Solver定义如下：</p>

<p>net:    &ldquo;./train_val.prototxt&rdquo;</p>

<p>momentum: 0.9</p>

<p>weight_decay:    0.00001</p>

<p>snapshot_pref ix:    . /f req_regression&rdquo;</p>

<p>solver_mode: GPU</p>

<p>type: &ldquo;Nesterov&rdquo;</p>

<p>这回采用的梯度下降是Nesterov方法，文件里没有指定snapshot的周期，则默认训练 结束后自动保存一个参数和Solver状态的存档。</p>

<p>9.2.4训练网络</p>

<p>首先还是像之前Caffe的例子一样，运行下面命令：</p>

<p>&gt;&gt; /path/to/caffe/build/tools/caffe train -solver solver.prototxt</p>

<p>就可以训练网络了，没有指定GPU的情况下，默认使用序号为0的GPU。训练这个网络 也并不费时，收敛后得到freq_regression_iter_10000.caffemodel的模型参数。笔者的笔记本 电脑上训练的曲线如图9-3所示。</p>

<p>-3.5</p>

<p>,A    Loss vs. Iters</p>

<p>-3.0</p>

<p>O</p>

<p>«2.</p>

<p>{SSO-I0I60I</p>

<p>0</p>

<p>2000</p>

<p>4000    6000</p>

<p>Iterations</p>

<p>8000 10000</p>

<p>图9-3训练/验证的loss随迭代次数的变化</p>

<p>在图9-3中纵轴为了方便查看，用的是logl0(loSS)，可以清楚看到模型收敛了，并且 验证集的loss更低，可能是训练集中极端样本出现的可能性更高的原因。</p>

<p>因为回归通常比分类更难训练，所以用Caffe的时候很容易出现不收敛的问题，或者 收敛一个很大的loss上。这通常是两个原因引起的：第一，参数设置不合适，这吋可以尝</p>

<p>试减小参数初始化时的浮动大小，减小学习率或改变梯度下降的方法等；第二，查看一下 是否使用了 cuDNN,这是很多人使用Caffe时都遇到过的问题，通常的表现是GPU不训 练不收敛，换成CPU或者删除cuDNN就可以了。解决方法是升级cuDNN或者直接不使 用 cuDNN o</p>

<p>9.2.5批量装载图片并利用GPU预测</p>

<p>直接用train_val.prototxt测试的方法在第8章已经讲过，这里就不重复了。直接利用</p>

<p>Python脚本在图片文件上测试的方法在第8章也有提到，但讲的是每次运行一张图片。在</p>

<p>图片数据量大的情况下，如果又有GPU,其实可以利用更加经济的方式，就是把多张图片</p>

<p>同时装载到显存中，然后运行一次得到多张图片的结果，实现并行。首先需要改写</p>

<p>train val.prototxt生成一个专门用来部署的网络结构描述文件deploy.prototxt,网络结构部</p>

<p>分和train_val.prototxt 一样，只需要改动开头和结尾部分即可。</p>

<p>name:    &ldquo;RegressionExample&rdquo;</p>

<p>layer {</p>

<p>name: &ldquo;data&rdquo; type: &ldquo;Input&rdquo; top: &ldquo;data&rdquo; input_param {</p>

<table>
<thead>
<tr>
<th>shape:</th>
<th>{</th>
</tr>
</thead>

<tbody>
<tr>
<td>dim:</td>
<td>100</td>
</tr>

<tr>
<td>dim:</td>
<td>1</td>
</tr>

<tr>
<td>dim:</td>
<td>100</td>
</tr>

<tr>
<td>dim:</td>
<td>100</td>
</tr>
</tbody>
</table>

<p>}</p>

<p>}</p>

<p>} ， layer {</p>

<p>name: &ldquo;convl&rdquo;</p>

<p>&hellip;中间部分省略&hellip;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;sigmoid5&rdquo; type: &ldquo;Sigmoid&rdquo; bottom: ”fc5&rdquo; top: &ldquo;pred&rdquo;</p>

<p>}</p>

<p>注意，在deploy.prototxt的Input层中，第-个维度是100，这是要使用的每次装载的</p>

<p>图片数量，也就是每次GPU前向计算的batch大小。基于此，deploy.prototxt用来批量从</p>

<p>图片文件预测噪声频率的代码如下：</p>

<p>import sys</p>

<p>import numpy as np</p>

<p>sys.path.append(*/path/to/caffe/python1) import caffe</p>

<p>WEIGHTS_FILE =    * freq_regression_iter_10000.caffemodel1</p>

<p>DEPLOY_FILE =    1 deploy.prototxt&rsquo;</p>

<p>MEAN_VALUE =    128</p>

<p>#caffe.set_mode_cpu()</p>

<p>net = caffe.Net(DEPLOY_FILE, WEIGHTS_FILE, caffe.TEST)</p>

<p>#    Transformer是Caffe中1于对图片进行预处并转换成分通道形式的模块</p>

<p>#    用 deploy.prototxt 中的 shape 作为图像的 shape</p>

<p>transformer = caffe.io.Transformer({&lsquo;data *: net.blobs[&lsquo;data1].data.shape}) #转换高度x宽度x通道&ndash;&gt; 通道x高度x宽度 transformer.set_transpose(&lsquo;data&rsquo;,    (2,0,1))</p>

<p>#减去均值</p>

<p>transformer.set_mean(* data1, np.array([MEAN_VALUE]))</p>

<p>#缩放系数</p>

<p>transformer.set_raw_scale(&lsquo;data *,    255)</p>

<p>image_list = sys.argv[1]</p>

<p># 获取 batch size</p>

<p>batch_size = net.blobs[* data *].data.shape[0] with open (image_list, &lsquo; r *) as f:</p>

<p>i =    0    ~</p>

<p>filenames =    []</p>

<p>for line in f.readlines():</p>

<p>filename = line[:-1] filenames.append(filename)</p>

<p>#读取一张图片，默认读取图片为0〜1之间的浮点数矩阵</p>

<p>image = caffe.io.load_image(filename, False)</p>

<p>#按照transformer的设置&rdquo;转化为网络接受的格式并进行减均值等预处理 transformed_image    =    transformer.preprocess(&lsquo;data&rsquo;,</p>

<p>image)</p>

<p>freqs):</p>

<p>{:.2f} and</p>

<p>#按对应位置装载到data的blob里</p>

<p>net .blobs[* data *].data[i,    &hellip; ]    = transformed_image</p>

<p>i += 1</p>

<p>#装载数据够一个batch后，执行一次前向计算    &lt;</p>

<p>if i == batch_size:</p>

<p>output = net.forward() freqs = output[<em>pred</em>]</p>

<p>#从结果中读取该batch所有结果并显示</p>

<p>for filename, (fxz    fy)    in zip(filenames,</p>

<p>print(&lsquo;Predicted frequencies for {:.2f} is {}&lsquo;.format(filename, fx, fy))</p>

<p>#重新开始给batch计数 i = 0</p>

<p>filenames =    []</p>

<p>需要注意的是，在第8章中我们对图像的处理比较粗暴，直接用cv2读取了单通道图 像然后减去均值，原因是因为单通道的例子比较简单。不过更好的做法是用Caffe的10模 块(背后实现是scikit-image)读取图片，然后用Caffe的Transformer模块对图片进行减均 值、通道变换等预处理。将上面代码保存为predict.py,然后执行：</p>

<p>» python predict.py test.txt</p>

<p>输出结果如下：</p>

<table>
<thead>
<tr>
<th>Predicted0.31</th>
<th>frequencies</th>
<th>for</th>
<th>samples/04349_</th>
<th><em>0.77</em></th>
<th>_0.31 .jpg</th>
<th>is</th>
<th>0.76</th>
<th>and</th>
</tr>
</thead>

<tbody>
<tr>
<td>Predicted0.96</td>
<td>frequencies</td>
<td>for</td>
<td>samples/15275</td>
<td><em>0.33</em></td>
<td>0.98.jpg</td>
<td>is</td>
<td>0.32</td>
<td>and</td>
</tr>

<tr>
<td>Predicted</td>
<td>frequencies</td>
<td>for</td>
<td>samples/02137</td>
<td><em>0.53</em></td>
<td>0.68.jpg</td>
<td>is</td>
<td>0.54</td>
<td>and</td>
</tr>
</tbody>
</table>

<p>0.69</p>

<p>从结果来看，基本还是准确的。</p>

<p>9.2.6卷积核可视化</p>

<p>为什么卷积神经网络也能判断出频率大小呢？我们可以考虑把第一个卷积层的每个卷</p>

<p>积核可视化出来，代码如下：</p>

<p>import sys</p>

<p>import numpy as np</p>

<p>import matplotlib.pyplot as pit</p>

<p>import cv2</p>

<p>sys.path.append(&lsquo;/path/to/caffe/python*) import caffe</p>

<p>#卷积核大小为5x5，放大方便观察</p>

<p>ZOOM_IN_SIZE =    50</p>

<p>#每X积核放大后之间的间隔</p>

<p>PAD_SIZE =    4</p>

<p>WEIGHTS_FILE =    &lsquo;freq_regression_iter_10000.caffemodel*</p>

<p>DEPLOY一FILE =    &lsquo;deploy.prototxt *</p>

<p>net =~ caffe.Net(DEPLOY_FILEZ WEIGHTS_FILEZ caffe.TEST)</p>

<p>#通过param属性取得指定层的参数的值 kernels = net.params[1convl1][0].data #归一化到0〜1之间方便可视化</p>

<p>kernels -= kernels.min() kernels /- kernels.max()</p>

<p>#    进行缩放，由5x5―&gt;50x50</p>

<p>zoomed_in_kernels =    []</p>

<p>for kernel in kernels:</p>

<p>zoomed_in_kernels.append(cv2.resize(kernel[0] ,    (ZOOM_IN_SIZE,</p>

<p>ZOOM_IN_SIZE)~ interpolation=cv2.INTER_NEAREST))</p>

<p>half:pa5 = ,PAD_SIZE /    2</p>

<p>padded_size x= ZOOM_IN_SIZE+PAD_SIZE</p>

<p>#利用numpy的pad方沄直蚕在卷积核函像的两边各补上half_pad这么多像素的白边 padding =    ((0,    0), (half_pad, half_pad), (half_pad, half_pad))</p>

<p>padded_kernels = np.pad(zoomed_in_kernelsf padding, * constant *, constant一values=l)</p>

<p>#    一共96个卷积核，画成8x12的排列</p>

<p>padded_kernels = padded_kernels.reshape(8,    12, padded_size,</p>

<p>padded_size).transpose(0,    2,    1,    3)</p>

<p>kernels_img    =    padded_kernels.reshape((8*padded_size,</p>

<p>12*padded_size))[half_pad:-half_pad, half_pad: -half_pad]</p>

<p>#可视化生&amp;的图像，包含〒所有第一层<em>96个卷积核</em></p>

<p>pit.imshow(kernels_img, cmap=&lsquo;gray&rsquo;, interpolation:•nearest’) pit.axis (* off *) pit.show()</p>

<p>执行代码，可视化结果如图9-4所示。</p>

<p>可以看到第一层的卷积核成功学到了各种不同频率的成分，这也是例子中判断频率高 低的关键，高频的成分通过高频的卷积核响应向下一层传递，低频则通过变化缓慢的卷积 核响应传向下一层。</p>

<p>虽然模型是用噪声训练出来的，但也可以试试看用到普通图像上是否管用。如图9-5 所示，从左至右分别是青海湖边的油菜花、四川西部深山的树林和北京(雾霾中)的高楼， 图片下方是用模型预测得到的分数。</p>

<h5 id="闢na醱汸蝙钃山鼸-国">■闢na醱汸蝙钃山鼸；国</h5>

<p>■mn，繚钃扑b灯覉喊较 .■ J鬵鱷!■■鞔鼷PSHrai</p>

<p>似巧關翳BISHHP鎂</p>

<h5 id="⑥聚曜國蟛韉囑sum鈐-觀誦鵬職繼觀-騙醒龍麵醺">■⑥聚曜國蟛韉囑sum鈐 觀誦鵬職繼觀 騙醒龍麵醺</h5>

<p>图9-4第一层卷积核的可视化</p>

<p>横轴频率：0.65    横轴频率：0.77    横轴频率：0.19</p>

<p>纵轴频率：0.73    纵轴频率：0.68    纵轴频率：0.22</p>

<p>图9-5噪声训练的模型在正常图像上的预测分数</p>

<p>可以看到，定性来说大体趋势是正确的。</p>

<h2 id="相关资料">相关资料</h2>

<ul>
<li>《深度学习与计算机视觉》</li>
</ul>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/04-%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/01-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">01 卷积神经网络</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/01-c&#43;&#43;/c&#43;&#43;-%E9%A2%98%E7%9B%AE/01-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E9%97%AE%E9%A2%98/">
            <span class="next-text nav-default">01 基本概念问题</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
