<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01 距离和度量学习 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="第12章度量学习 第12章介绍了度量学习的基本概念,并从图片开始，一步步实现了基于Caffe的Siamese 网络，还实现了基于t-SNE的结果" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/12-%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/01-%E8%B7%9D%E7%A6%BB%E5%92%8C%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="01 距离和度量学习" />
<meta property="og:description" content="第12章度量学习 第12章介绍了度量学习的基本概念,并从图片开始，一步步实现了基于Caffe的Siamese 网络，还实现了基于t-SNE的结果" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/12-%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/01-%E8%B7%9D%E7%A6%BB%E5%92%8C%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0/" /><meta property="article:published_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta itemprop="name" content="01 距离和度量学习">
<meta itemprop="description" content="第12章度量学习 第12章介绍了度量学习的基本概念,并从图片开始，一步步实现了基于Caffe的Siamese 网络，还实现了基于t-SNE的结果">


<meta itemprop="datePublished" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="6409">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="01 距离和度量学习"/>
<meta name="twitter:description" content="第12章度量学习 第12章介绍了度量学习的基本概念,并从图片开始，一步步实现了基于Caffe的Siamese 网络，还实现了基于t-SNE的结果"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">最新</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">最新</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01 距离和度量学习</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-08-29 </span>
        
        <span class="more-meta"> 6409 words </span>
        <span class="more-meta"> 13 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#第12章度量学习">第12章度量学习</a>
<ul>
<li><a href="#dm-公式-12-1">dM    (公式 12-1)</a></li>
<li><a href="#平面上">平面上。</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#相关资料">相关资料</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h5 id="第12章度量学习">第12章度量学习</h5>

<p>第12章介绍了度量学习的基本概念,并从图片开始，一步步实现了基于Caffe的Siamese 网络，还实现了基于t-SNE的结果可视化。</p>

<p>本章介绍度量学习(Metric Learning)的基本概念，并通过MNIST训练Siamese网络 的例子来加深理解。</p>

<p>12.1距离和度量学习</p>

<p>在机器学习中，有一类算法如K近邻/K-means、SVM、相似比对/搜索相关的算法等， 非常依赖距离这个度量来对数据执行分类/聚类/搜索等任务。所以有一个方向专门研究如 何让一个算法更好地学习到一种度量，比如欧式距离，提升特定任务的算法性能，这就是 度量学习。</p>

<p>12.1.1欧氏距离和马氏距离</p>

<p>本节首先来考虑图12-1所示的例子。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-303.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-304.jpg" alt="img" /></p>

<p>图12-1中左下角是在二维空间中由一个分布产生的方块样本，这个分布的一条等高线 如虚线的椭圆框所示。图12-1中还有一个不属于该分布的圆圈样本，在做聚类一类的任务 时，通常会用欧式距离判断是否属于同一类，如果对于本例用欧式(Euclidean)距离则会 出现问题。如图12-1左上角图所示，从方块分布中抽出中央和右上角边缘的两个样本，和 圆圈样本单独画出来，可以看到圆圈样本更加靠近方块样本的中心，而那个离得远的方块 样本到中心样本的欧氏距离反而更远，这是因为产生样本的分布本身形状导致的。这种情 况下，马氏(Mahalanobis)距离则是更加合适的一种度量。马氏距离是由印度统计学家 Mahalanobis提出的一种用于表示数据的协方差距离的度量，定义如下：</p>

<h6 id="dm-公式-12-1">dM    (公式 12-1)</h6>

<p>其中X, 分别是两个空间中的坐标，z是产生方块的分布的协方差矩阵。在这种距离 的度量下，方块分布的等高线到分布中心的距离都是相等的，如图12-1右上角图所示。在 第2章讨论PCA的时候已经讲过，协方差矩阵包含着方差在不同轴上投影的信息，所以如 果把马氏距离看作是如下的形式的话：</p>

<p>dM {x,y) = yj(x- y)AAJ (x - y) = \A7x - A7y\    (公式 12-2)</p>

<p>其中dT=£Tt/T,对角矩阵的对角线分别为协方差矩阵本征值的倒数开方，t/T的行 向量就是协方差矩阵的本征向量。通过对原来的样本进行变换，就得到图12-1右下角 图，对于方块的分布而言，计算马氏距离就等效于在变换后的空间里计算欧式距离。</p>

<p>通过前面的讨论知道了马氏距离就是对一个可以用协方差矩阵描述的分布，计算等效 距离的一种方式，不过对于很多机器学习任务，得到描述某一类样本的分布的协方差矩阵 往往意义不大，或是有时候样本数量相对于维度都不足以得到一个有效的协方差矩阵。所 以在机器学习中，马氏距离的意义可以拓展一下，如果用：</p>

<p>d(x,y) = yj(x-y)M(x-y)    (公式 12-3)</p>

<p>来表示想要最终使用的度量，其中M可以是任意满足条件的半正定矩阵，那么如何找到一 个合适的Af就是最早的度量学习关心的问题。</p>

<p>12.1.2欧式距离和余弦距离</p>

<p>除了马氏距离，第2章中讲过用来计算相似性的余弦距离也是一种常用的度量方式， 如图12-2所示的样本。</p>

<p>a)    b)    c)</p>

<p>如图12-2a所示，两种样本在距离上展现出的区分度并不特别明显。但在以原点为中 心和坐标轴成的角度来看，区分反而显得更清晰，这种情况就可以考虑用余弦距离。第2 章讲过计算余弦距离的公式，通过公式可以知道，余弦距离其实本质上还是在计算角度之 间的差，因为直接计算余弦距离的运算量并不小，所以更常用的一种计算方式是用归一化 之后的坐标(或者特征)相减，降低计算量，公式如下：</p>

<p>=    (公式 12-4)</p>

<p>形象的理解如图12-2b和12-2c所示，假设图12-2b中的虚线圆弧是单位圆所在，那么 归一化就相当于把每个样本沿着半径投影到单位圆上，投影后的样本就是空心的方框和小 圆圈，如图12-2c所示。投影之后再计算欧式距离，这个距离就等于距离和半径比值。因 为单位圆半径是1,当两个样本距离较近时，这个值可以很好地近似样本的夹角，当两个 样本距离远时，虽不能很好近似，但也能大致反映出夹角大小。</p>

<p>12.1.3非线性度量学习和Siamese网络</p>

<p>12.1.1中计算马氏距离相当于是线性变换，不少很有代表性度量学习的方法都是基于 线性变换去做的，比如 Large Margin Nearest Neighbor, Information Theoretic Metric Learning 等。线性变换的优点是学习出来的metric不容易过拟合，求解很快，泛化性也相对好一些。 但是缺点也很明显，拟合能力往往不够，对输入样本特征的可分性要求也高。</p>

<p>在12.1.2节中计算余弦距离就已经不是线性变换了。所以广义来看，度量学习要解决 的就是找到一种好的度量方式，不管是非线性还是线性的。对于非线性的情况，概括为公 式如下：</p>

<p>^(^J)= |/(^)-/(J)|    (公式 12-5)</p>

<p>其中/是非线性变换。既然可以有非线性变换，那么神经网络当然也是一个选项。考 虑一个卷积神经网络用戶G(x)表示对输入进行的非线性变换。对于来自于同一类的样本， 让同类别的样本之间的距离经过G变换后距离更近，而不同类别之间的样本经过G变换后 距离更远。训练阶段可以考虑训练的时候每次都输入两个样本，用两个参数完全一样的网 络对这两个样本进行变换，最后设计一个loss函数来实现让相同样本对之间的距离更近， 不同样本对之间的距离更远，如图12-3所示。</p>

<p>&rsquo;    x2</p>

<p>第12章度量学习</p>

<p>这种网络结构被称为Siamese Architecture,是1993年LeCun在贝尔实验室时和同事 合作发表的文章《Signature Verification using a ’’Siamese’’ Time Delay Neural Network》中提 出的结构。Siamese的名字源于著名的连体双胞胎恩（Eng）和昌（Chang）。19世纪的时 候，这对连体双胞胎兄弟因为跟随马戏团在全世界巡演而名噪一时，因为二人的出生地是 泰国的暹罗（Siam）,所以被称为Siamese Twins，后来Siamese Twins就成了连体人的代 名词。2005年的时候LeCun用这种结构的卷积神经网络来训练人脸比对（Face Verification） 模型，获得了不错的结果，论文《Learning a Similarity Metric Discriminatively, with Application to Face Verification》发表在CVPR上，一举成为了用卷积神经网络做Metric Learning的基础方法。</p>

<p>12.1.4 Contrastive Loss：对比损失函数</p>

<p>基于LeCun的工作，Caffe对Siamese训练提供了很好的支持，Caffe中内置了用于训 练Siamese网络的Contrastive Loss层，这种loss的计算公式如下：</p>

<p>1 N    7</p>

<p>L（d,y） =-+（1 -y/）max（zwargz&gt;2-t//,0）    （公式 12-6）</p>

<p>27V ,=i</p>

<p>其中#是每个batch的大小，y是标签，1代表相同样本，0代表不同样本，margin是 人为设定的一个值，是每对样本的欧式距离。</p>

<p>=\at-b\    （公式 12-7）</p>

<p>其中〃和分别是要比较距离的两个样本最后计算出来的特征（一个向量）。利用 Contrastive Loss层的时候，需要3个输入：两个输入分别是一对样本对应的特征tz和6， 欧式距离在层内自动计算，另一个输入为是否相似的标签JV。</p>

<p>根据Contrastive Loss的定义，当两个样本一样的时候，y=\,优化的目标是让&rsquo;尽量 小，是让相同样本尽量靠近；当两个样本不同时，y=0,是让max（zzwrrgz&gt;?-6/,0）2尽量小，也 就是6/尽量大以接近让不同的样本尽量远离。</p>

<p>12.2 用 MNIST 训练 Siamese 网络</p>

<p>本节还是通过最简单的MNIST的例子,通过训练Siamese网络让相同数字变换后的距 离尽量靠近，不同数字变换后尽量远离。</p>

<p>12.2.1数据准备</p>

<p>Caffe中也有用MNIST训练Siamese的例子，不过和MNIST分类的例子一样，细节 全都隐藏在C++和shell代码里了，所以本节从头开始，方便读者举一反三。</p>

<p>第一步当然是准备MNIST的数据，可以参考第8章，下载MNIST压缩包并生成图片， 然后在当前文件夹下建立一个指向mnist文件夹的链接：</p>

<p>» In -s /path/to/mnist mnist</p>

<p>第2篇实例精讲</p>

<p>Caffe官方的例子使用的leveldb,本节中不打算介绍这种方式，而是用另一种思路， 利用之前用过的lmdb来实现Siamese训练。具体办法是：生成两个lmdb,其中数据的顺 序一一对应，如果是相同数字，则标签为1，否则标签为0。对训练时用到的pmtotxt也做 相应修改，用两个data layer分别读取两个数据，按照图12-3所示的思路经过CNN之后 最后再计算转换后特征的距离。</p>

<p>在Caffe和其他一些流行框架如Keras中，产生样本方式就是随机配对，这种情况下, 假设每类数字的样本数量相等，均为〃，则相同样本的占比是：</p>

<p>10xC(«，2)    10x«(«-l)    10    1</p>

<p>C(10n,2) ~ 10n(10w-l) ~T00_l0</p>

<p>对于n＞〉l的情况，近似就是0.1,这个比例对于MNIST这样简单的数据效果还不错，</p>

<p>本节也用这个简单的策略进行训练。不过需要提一句的是，在做一些其他的训练的时候，</p>

<p>相同样本和不同样本的比例往往是经验值，需要一定的尝试。用来生成MNIST文件列表</p>

<p>的脚本如下：</p>

<p>import os import random import re</p>

<p>#指定训练图片和验证图片的路径 train_dir = &lsquo;mnist/train1 val_dir = <em>mnist/val</em></p>

<p>#岳定样本对数目</p>

<p>n_train =    100000</p>

<p>n_val =    10000</p>

<p>从文件名中获取数字的正则表达式</p>

<p>pattern = re.compile(1\d+_(\d).jpg&rsquo;)</p>

<p>#生成训练集和b证集列表的文件_</p>

<p>for img_dir, n_pairs in zip([train_dir, val_dir], [n_train, n_val]): #-列出所w的文件名 imglist = os.listdir(img_dir)</p>

<p>#获得所有的样本数量</p>

<p>n_samples = len(imglist)</p>

<p>#_数据集名称</p>

<p>dataset = img_dir[img_dir.rfind(os.sep)+1:]</p>

<p>#同时打开两个文r牛分别写入应的文件列表</p>

<p>with open(1{}•txt&rsquo;.format(dataset),    *w *) as f, </p>

<p>open(1{}_p.txt&rsquo;.format(dataset),    1 w*) as f_p:</p>

<p>#按照指定的数目i机写入文件路径对 for i in range(n_pairs):</p>

<p>#随机选取第I个文件</p>

<p>filename = imglist[random.randint(0, n_samples-l)] digit = pattern.findall(filename)[0] filepath = os.sep.join([img_dirz filename])</p>

<p>#随机选取第二个文件</p>

<p>filename_p = imglist[random.randint(0, n_samples-l)] digit_p = pattern.findall(filename_p)[0] filepath_p = os.sep.join([img_dir, filename_p])</p>

<p>#如果两不文件是同一个数字则标签为f否则标签为0 label =    1 if digit == digit_p else 0</p>

<p>#分别写入两个文件</p>

<p>f.write(1{}    {}\n *.format(filepath, label))</p>

<p>f_p.write(1{}    {}\n&rsquo;.format(filepath_p, label))</p>

<p>执行脚本，得到train.txt、train_p.txt、val.txt、val_p.txt这4个文件。然后像在第8章 中一样生成4个lmdb：</p>

<p>»    /path/to/caffe/build/tools/convert_imageset . / train.txt train—</p>

<p>lmdb ——gray</p>

<p>&gt;&gt; /path/to/caffe/build/tools/convert_imageset ./ train_p.txt train— p_lmdb ——gray</p>

<p>»    /path/to/caffe/build/tools/convert_imageset    . / val.txt val_lmdb</p>

<p>——gray</p>

<p>&gt;&gt;    /path/to/caffe/buiId/tools/convert_imageset    . / va_l_p.txt val<em>p</em></p>

<p>lmdb ——gray</p>

<p>因为文件对本身就是随机挑选的，再加上每行的文件和标签要一一对应，所以不能再 使用-shuffle这个选项。另外需要注意的是，因为两个lmdb—一对应，所以在使用其他数 据的情况下，比如自己采集的人脸比对的数据，如果其中有任何文件图片是损坏的，贝IJ对 应的两个路径都不应该写到列表文件里，否则在生成lmdb的时候可能出现错位。</p>

<p>12.2.2参数共享训练</p>

<p>训练的 solver 就是/path/to/caffe/examples/siamese 下的 mnist_siamese_solver.prototxt, 只不过把网络结构文件指向我们自己定义的文件路径。网络结构定义和Caffe自带例子主 要的不同在data layer,基础网络结构就是LeNet-5,具体如下：</p>

<p>name:    *&rsquo; mn i s t _ s i ame s e_ t r a i n_ t e s t&rdquo;</p>

<p># 一共4个data layer,分别是训练的一对样本和验证的一对样本 layer {</p>

<p>name: &ldquo;mnist&rdquo; type:    &ldquo;Data&rdquo;</p>

<p>top:    &ldquo;data&rdquo;</p>

<p>top: &ldquo;label&rdquo; include {</p>

<p>phase: TRAIN</p>

<p>}</p>

<p>transform_param { mean_value:    128</p>

<p>scale:    0.00390625</p>

<p>}</p>

<p>data_param {</p>

<p>source:    ntrain_lmdbn</p>

<p>batch_size:    64</p>

<p>backend: LMDB</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: nmnist_p&rdquo; type: ’’Data” top: &ldquo;data_p&rdquo;</p>

<p># top: &ldquo;label&rdquo;可以省略，因为已经在mnist的data layer中读取过了 include {</p>

<p>phase: TRAIN</p>

<p>}</p>

<p>transform_param { mean_value:    128</p>

<p>scale:    0.00390625</p>

<p>}</p>

<p>data_param {</p>

<p>source: &ldquo;train_p_lmdb&rdquo; batch_size:    64</p>

<p>backend: LMDB</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;mnist&rdquo; type: &ldquo;Data&rdquo; top: &ldquo;data&rdquo; top: &ldquo;label&rdquo; include {</p>

<p>phase: TEST</p>

<p>}</p>

<p>transform_param { mean一value: 128 scale:    0.00390625</p>

<p>}</p>

<p>data_param {</p>

<p>source: &ldquo;val_lmdb&rdquo; batch_size:    100</p>

<p>backend: LMDB</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;mnist_p&rdquo; type: &ldquo;Data&rdquo; top: &ldquo;data_p&rdquo;</p>

<p>layer中读取过了</p>

<p># top: &ldquo;label&rdquo;可以省略，因为已经在mnist的data include { f</p>

<p>phase: TEST</p>

<p>}</p>

<p>transform一param { mean_value:    128</p>

<p>scale:    0.00390625</p>

<p>}</p>

<p>data_param {</p>

<p>source: &ldquo;val_p_lmdb&rdquo; batch_size:    100</p>

<p>backend: LMDB</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: ’’convl’* type: &ldquo;Convolution&rdquo; bottom:    &ldquo;data&rdquo;</p>

<p>top: &ldquo;convl&rdquo;</p>

<p>#参数共享的方式是指定参数的名字，用name指定 #在其他层中如果出现了同样的name,则共享参数 #本例中共享参数的是convl_p</p>

<p>param {</p>

<p>name: &ldquo;convl_w&rdquo; lr_mult:    1</p>

<p>}</p>

<p>param {</p>

<p>weight_filler {</p>

<p>type: &ldquo;xavier&rdquo;</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: &ldquo;constant&rdquo;</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: ’’pooll&rdquo;</p>

<p>&hellip;中间部分省略&hellip;</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;feat&rdquo;</p>

<p>type: &ldquo;InnerProduct&rdquo;</p>

<p>weight—filler {</p>

<p>type: &ldquo;xavier&rdquo;</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: ’’constant&rdquo;</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>#处理MNIST数据的网络到此结束 layer {</p>

<p>name: &lsquo;*convl_pn type: &ldquo;Convolution&rdquo; bottom: ndata_p&rdquo; top: &ldquo;convl_p&rdquo;</p>

<p>#参数共享</p>

<p>param {</p>

<p>name:    &ldquo;convl_w&rdquo;</p>

<p>lr_mult:    1</p>

<p>}</p>

<p>param {</p>

<p>name: &ldquo;convl_b&rdquo; lr_mult:    2</p>

<p>}</p>

<p>weight_filler {</p>

<p>type:    &ldquo;xavier&rdquo;</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: &ldquo;constant&rdquo;</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;pooll_p&rdquo;</p>

<p>&hellip;中间部分省略 }</p>

<p>layer {</p>

<p>name: &ldquo;feat_p&rdquo; type: &ldquo;InnerProduct&rdquo; bottom:    &ldquo;ip2_p&rdquo;</p>

<p>top: &ldquo;feat_p&rdquo; param {</p>

<p>weight_filler {</p>

<p>type: &ldquo;xavier&rdquo;</p>

<p>}</p>

<p>bias_filler {</p>

<p>type: ’’constant’’</p>

<p>}</p>

<p>}</p>

<p>}</p>

<p>layer {</p>

<p>name: &ldquo;loss&rdquo;</p>

<p>type: &ldquo;ContrastiveLoss&rdquo;</p>

<p>bottom: &ldquo;feat&rdquo;</p>

<p>bottom: &ldquo;feat_p&rdquo;</p>

<p>bottom: &ldquo;label&rdquo;</p>

<p>top: &ldquo;loss&rdquo;</p>

<p>contrastive_loss_param { margin:    1</p>

<p>}</p>

<p>}</p>

<p>需要注意的有两点：第一点，对应的data layer参数要完全一致，每对中只要一个 datalayer读取标签就可以了，另一个可以忽略读取标签；第二点，参数共享通过制定参数 名称实现，一定要保证名称相同。网络结构的可视化如图12-4所示。</p>

<p>图12-4用多个lmdb训练Siamese的网络结构可视化</p>

<p>完整的solver和网络结构定义可以在本书的github代码仓中查看。接下来训练的过程 与第8章类似。</p>

<p>» /path/to/caffe/build/tools/caffe train -solver mnist<em>siamese</em> solver.prototxt -log_dir . /</p>

<p>得到的训练曲线如图12-5所示。</p>

<p>图12-5用MNIST训练Siamese模型的收敛曲线</p>

<p>由图12-5可知后期显然过拟合了，最小的验证集loss是在迭代22000次附近。</p>

<p>12.2.3结果和可视化</p>

<p>本节选取20000次时保存的模型来试一试，部署的文件就是Caffe自带的</p>

<p>mnist_siamese.prototxt：这个文件和一般的LeNet-5区别不大，只是最后一层换成了一个二</p>

<p>维输出。Caffe自带的例子选择二维输出，一方面可能是因为MNIST确实比较简单，另一</p>

<p>方面也容易可视化，所以这里直接用下面脚本把所有test集中的样本最后的输出画在二维</p>

<h6 id="平面上">平面上。</h6>

<p>import os import sys</p>

<p>sys.path.append(*/opt/caffe/python&rsquo;) import re</p>

<p>import numpy as np</p>

<p>import matplotlib.pyplot as pit</p>

<p>import cv2</p>

<p>import caffe</p>

<p>WEIGHTS_FILE = *mnist_siamese_iter_20000.caffemodel&rsquo;</p>

<p>DEPLOY—FILE =    1mnist_siamese.prototxt&rsquo;</p>

<p>IMG_DIR = &lsquo;mnist/test&rsquo;</p>

<p>MEAN =    128</p>

<p>SCALE =    0.00390625</p>

<p>caffe.set_mode_gpu() caffe.set_device(0)</p>

<p>net = caffe.Net(DEPLOY_FILEZ WEIGHTS_FILE, caffe.TEST)</p>

<p>#匹配获取文件对应数字的正则表达式</p>

<p>pattern = re.compile(&rsquo;\d+_(\d).jpg*)</p>

<p>#获取mnist/test文件夹下所有图片 image_list = os.listdir(IMG_DIR) n_imgs = len(image_list)</p>

<p># 一次性读取用GPU并行处理</p>

<p>net.blobs[&lsquo;data&rsquo;].reshape(n_imgsz 1,    28,    28)</p>

<p>#按照顺序保存label的列表 labels =    []</p>

<p>for i, filename in enumerate(image_list):</p>

<p>digit = int(pattern.findall(filename)[0]) labels.append(digit)</p>

<p>#获取文件路径</p>

<p>filepath = os.sep•join([IMG_DIR, filename])</p>

<p>#读取单通道文件并减均值和乘系数_</p>

<p>image = cv2•imread(filepath, cv2•IMREAD_GRAYSCALE).astype(np.float)</p>

<p>-MEAN</p>

<p>image *= SCALE</p>

<p>net.blobs[1 data *] .data[i,    &hellip; ]    = image</p>

<p>labels = np.array(labels) output = net.forward() feat = output[&lsquo;feat *]</p>

<p>#定义每个数字的颜色，颜色定义从Caffe自带例子直接复制而来</p>

<p>colors = [，#ff0000\ ，#ffff0(r, *#00ff00\ ，糊ffff，， *#0000ff1,</p>

<p>^ffOOff&rsquo;z &lsquo;#990000*,    &lsquo;#999900&rsquo;,    &lsquo;#009900&rsquo;,    &lsquo;#009999&rsquo;]</p>

<p>legend = [ &lsquo;0\ &lsquo;I&rsquo;, &lsquo;2’， *3&rsquo;, &lsquo;4，， &lsquo;5&rsquo;, %•&rsquo; &lsquo; 7 &lsquo;, ; 1 8 \ 1 9&rsquo;]</p>

<p>#用二维散点图可视化 pit.figure(&lsquo;feat *) for i in range (10):</p>

<p>pit.plot(feat[labels==i,0].flatten(),</p>

<p>feat[labels==iz1].flatten(),</p>

<p>’ .*, c=colors[i])</p>

<p>pit.legend(legend) pit.show()</p>

<p>因为样本量较大，本段代码推荐在GPU上运行，运行后得到的结果可以清楚看到相同 的数字会“聚”在一起，如图12-6所示。</p>

<p>2.0</p>

<p>1.5</p>

<p>1.0</p>

<p>0.5</p>

<p>0.0</p>

<p>-0.5</p>

<p>-1.0</p>

<p>—1.5</p>

<p>-2.0</p>

<p>-2-10 1 2</p>

<p>图12-6对图片提取二维特征的可视化</p>

<p>12.2.4用t-SNE可视化高维特征</p>

<p>MNIST的例子非常简单，所以二维的特征就足够了。然而在实际的应用中，比如人脸 比对或场景搜索，特征的维数可能是上千维。这时候如果还要可视化，就需要借助降维手 段。第2章讲降维的时候提到过t-SNE，基本上算是高维度特征在低维度下可视化的最常 用方法了。这种算法的基本思想是，高维空间中样本距离的相对远近，在降维后的空间中 也要体现出来。不过本书不打算探讨该方法的细节，只是讲一下如何通过Python的skleam 工具包调用该算法进行可视化。因为我们的例子中没有专门训练一个高维度的特征，所以 用训练好的模型的倒数第二层全连接层ip2代替进行测试。接上段代码，可视化ip2输出 特征的代码如下：</p>

<p>from sklearn.manifold import TSNE</p>

<p>#起一个新的figure pit.figure(* ip21)</p>

<p>#通过blobs取得隐层的数据 ip2_feat = net.blobs[* ip2&rsquo;].data # n_components指定降维之后的维数，默认就是2 model = TSNE(n_components=2)</p>

<p>ip2_vis_feat = model.fit_transform(ip2_feat) for i in range(10):</p>

<p>pit.plot(ip2_vis_feat[labels==iz 0] .flatten(),</p>

<p>ip2_vis_feat[labels==i,1].flatten(),</p>

<p>* . 1, c=colors[i])</p>

<p>pit.legend(legend) pit.show()</p>

<p>如果是配置比较低的计算机，可以考虑只用一部分样本进行可视化。执行上面代码得 到的图像如图12-7所示。</p>

<p>10</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-310.jpg" alt="img" /></p>

<p>-2</p>

<p>-4</p>

<p>-6</p>

<p>一 8</p>

<p>-10    一5    0    5    10</p>

<p>图12-7 t-SNE在二维空间中可视化倒数第二层的10维特征</p>

<p>图12-7虽然效果不如最后的二维特征，但也能看出已经有了比较明显的区分性。可视 化的完整代码和预训练好的模型在本书的github代码仓中也可以找到。</p>

<h2 id="相关资料">相关资料</h2>

<ul>
<li>《深度学习与计算机视觉》</li>
</ul>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%90%86%E8%AE%BA/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/01-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%AE%80%E5%8F%B2/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">01 计算机视觉简史</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/10-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83/01-%E9%80%9A%E8%BF%87-python-%E9%87%87%E9%9B%86%E7%BE%8E%E9%A3%9F%E5%9B%BE%E7%89%87/">
            <span class="next-text nav-default">01 通过 Python 采集美食图片</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
