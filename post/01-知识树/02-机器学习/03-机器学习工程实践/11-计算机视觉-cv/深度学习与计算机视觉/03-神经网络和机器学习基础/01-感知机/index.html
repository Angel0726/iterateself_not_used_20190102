<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>01 感知机 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="第3章神经网络和机器学习基础 需要补充的 暂时没有进行整理，对于神经网络的基础已经整理了很多的，需要把哪些融合之后再把这个整理进去。 第1章已经从" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/03-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/01-%E6%84%9F%E7%9F%A5%E6%9C%BA/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="01 感知机" />
<meta property="og:description" content="第3章神经网络和机器学习基础 需要补充的 暂时没有进行整理，对于神经网络的基础已经整理了很多的，需要把哪些融合之后再把这个整理进去。 第1章已经从" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/03-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/01-%E6%84%9F%E7%9F%A5%E6%9C%BA/" /><meta property="article:published_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-08-29T00:00:00&#43;00:00"/>
<meta itemprop="name" content="01 感知机">
<meta itemprop="description" content="第3章神经网络和机器学习基础 需要补充的 暂时没有进行整理，对于神经网络的基础已经整理了很多的，需要把哪些融合之后再把这个整理进去。 第1章已经从">


<meta itemprop="datePublished" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-08-29T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="28243">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="01 感知机"/>
<meta name="twitter:description" content="第3章神经网络和机器学习基础 需要补充的 暂时没有进行整理，对于神经网络的基础已经整理了很多的，需要把哪些融合之后再把这个整理进去。 第1章已经从"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">最新</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">最新</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">01 感知机</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-08-29 </span>
        
        <span class="more-meta"> 28243 words </span>
        <span class="more-meta"> 57 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#第3章神经网络和机器学习基础">第3章神经网络和机器学习基础</a>
<ul>
<li><a href="#需要补充的">需要补充的</a>
<ul>
<li>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href="#z-z-公式-3-6">z z .    (公式 3-6)</a></li>
<li><a href="#自行学习">自行学习。</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><a href="#相关资料">相关资料</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h1 id="第3章神经网络和机器学习基础">第3章神经网络和机器学习基础</h1>

<h2 id="需要补充的">需要补充的</h2>

<ul>
<li><span style="color:red;">暂时没有进行整理，对于神经网络的基础已经整理了很多的，需要把哪些融合之后再把这个整理进去。</span></li>
</ul>

<p>第1章已经从历史和其他角度讲述了神经网络的前世今生。本章将深入细节，一探究 竟。本章将从神经网络讲起，然后引出一些机器学习的基础概念并进行简单讨论。</p>

<p>3.1感知机</p>

<p>深度学习始于神经网络，神经网络始于感知机。</p>

<p>3.1.1 基本概念</p>

<p>在第1章里已经提到过感知机。本节就详细聊聊 这个在人工神经网络中最基础的结构。感知机由Frank Rosenblatt在1957年第一次提出，结构如图3-1所示。</p>

<p>5?</p>

<p>图3-1感知机示意图</p>

<p>这种结构以一个向量作为输入，计算输入每一维 度的值的线性组合，也就是第2章讲过的线性变换， 然后和一个阈值进行比对，高于阈值则输出1，否则 输入_1。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-125.jpg" alt="img" /></p>

<p>1,    + w2x2 + •</p>

<p>-1, WjXj + w2x2 +</p>

<p>xnwn+b&gt;0 ■xnwn + Z? 0</p>

<p>（公式3-1）</p>

<p>简单来说就是加权求和，然后再和b进行比大小。</p>

<p>3.1.2感知机和线性二分类</p>

<p>从结构上讲，感知机和神经元的相似之处在于：第一，多个输入到一个节点；第二， 神经元总输入电位超过阈值电位后，将释放一个输出，这对应感知机以o为阈值对应1和 -1的不同输出。功能上就大不一样了，感知机这样一种简单的结构实质能解决的是在多维 空间中的线性分类问题，如图3-2所示的一个二维平面上的例子。</p>

<p>把这个平面上的不同样本二分类的一个感知机，分界线对应如图3-3中所示的虚线。</p>

<p>图3-2二维平面上线性可分样本</p>

<p>^!+2%2-1=0</p>

<p>图3-3二维平面上线性可分样本和一个线性分界</p>

<p>图3-3中，O表示/x心＞0的样本，也就是标签结果为1的，对应分类虚线上方的部 分；△表示/xlrv2）＜0的样本，结果标签为_1，对应分类虚线下方的部分。</p>

<p>3.1.3激活函数</p>

<p>那么Frank Rosenblatt的感知机和神经网络有什么联系呢？感知机事实上就是人工神 经网络的最小单元，这个结构里有两个最基本的成分：计算输入向量的一个线性变换；对 线性组合的结果进行阈值判断，实际上就是非线性变换。或者更简单来说，把阈值和线性 变换放一起，则是第2章提到的仿射变换，所以感知机本质上就是一个仿射变换接一个非 线性变换。把公式3-2简化一下，用x来表示向量（xbx2,    用w来表示对应系数的向</p>

<p>量，sgri表示大于0输出1，小等于0则输出-1的函数，得到公式3-3如下：</p>

<p>y    /（x） = sgn（＞v-x + Z?）    （公式 3-3）</p>

<p>其中wx表示两者的点积。更一般地，按照前面所说，把这个公式里的仿射变换+非 线性变换的特点提取出来，可以表示为公式3-4。</p>

<p>f{x）=g{w^x + b}    （公式 3-4）</p>

<p>g（*）表示一个非线性变换。在机器学习领域，这种非线性变换通常被称为激活函数。 激活函数可以是sgn函数，也可以是其他函数，比如可以是连续且光滑的tanh函数（如 图3-4a所示），或是sigmoid函数（如图3-4b所示），其实就是第2章提到过的logistic 函数在一维输入下的特例。这些正是经典全链接神经网络的常见基本单元。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-128.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-129.jpg" alt="img" /></p>

<p>图3-4 tanh函数和sigmoid函数</p>

<p>另外也可以是ReLU(Rectified Linear Unit)激活函数，这是2012年之后深度学习中被用 到最多的一个经典神经元结构(如图3-5所示)。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-130.jpg" alt="img" /></p>

<p>感知机是个如此简单的模型，说白了就是乘积一累加运算一判断大小，非常适合计算 机模拟，这也是为什么这个很早就提出来的简单结构如今会成为神经网络基础的重要原因。</p>

<p>3.2神经网络基础</p>

<p>本节将从直观形象的角度，用最简单的例子一步步了解一个神经网络是如何完成基本 分类的任务。</p>

<p>3.2.1从感知机到神经网络</p>

<p>了解了感知机，就可以开始探索最基本的神经网络了 经典的两层神经网络结构。</p>

<p>先来看一个如图3-6所示的最</p>

<p>输出</p>

<p>图3-6 —个简单的神经网络的例子</p>

<p>最原始的输入层(X1?X2)和3个不同感知机相连，这 3个感知机有3个输出，然后再和一个感知机相连，最 终输出在这样一个经典的网络结构中，输入后面的 一层叫隐藏层，因为通常在训练和使用的时候，其输出 对使用者来说是不可见的，然后是输出层。很容易发现 这样的网络结构有以下两个特点。</p>

<p>分层结构，如果把输入也当成一层，则每一层有一定数量的输出作为下一层的输入。 从这个角度来说，可以把神经网络看作是对一个向量进行分步变换，每一层的输入向量经 过这一层感知机变换之后，相当于变成了一个新的向量，并且新向量的维度等于这一层感 知机单元的数量，这样一层层变换直到形成最后的输出。如图3-6所示的网络结构，输入 层的向量传递到隐藏层之后，变成了一个三维向量，而这个三维向量到达输出层之后，最 终变成一维。如果从函数的角度来看，整个神经网络的作用就是一个向量x,经过了变换 之后成了一个向量y而已。</p>

<p>每一层的输出都和下一层所有的感知机输入相连，也就是通常所说的全连接（Fully Connected）。所以在这种经典的结构中，对于一个《层（包含输入层和输出层）的网络， 权值的数目和神经元数目的关系如下：</p>

<p>（公式3-5）</p>

<p>/=0</p>

<p>其中W代表权值的总数，八代表第f层的感知机数量。可以看到，当网络层数不多的 时候，随着感知机单元数量的增加，权值数目是平方增加的趋势。最近几年ImageNet竞赛 的网络有去掉全连接层的趋势，也是因为全连接层的单元数未必很多但是参数却很多，常 常会占据一个模型中的大部分参数。</p>

<p>3.2.2最简单的神经网络二分类例子</p>

<p>了解了神经网络的两个特点，那么这样一种分层的、全连接的结构和单个的感知机分 类比起来强大在哪里呢？先来看图3-7中所示的一个平面上二分类的小例子。</p>

<p>这里面产生的样本是由曲线</p>

<p>=＞〔27^+|)</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-132.jpg" alt="img" /></p>

<p>作为分界线，以上的样本标签为1,以下的样本标为0。因为产生样本的分界线是弯曲的， 所以对只能做线性二分类的单个感知机来说，显然无能为力。那么轮到神经网络出场了， 我们建立一个非常/简单的用于二分类的两层的神经网络，结构如图3-8所示。</p>

<p>/°o</p>

<p>o o /</p>

<p>输出</p>

<p>输入 隐藏层 输出层 图3-8用于二分类图3-7所示样本的神经网络结构</p>

<p>A    A A</p>

<p>△ △</p>

<p>△    △    A</p>

<p>△ A</p>

<p>0.2    0.4    0.6    0.8    L0</p>

<p>图3-7二维平面上线性不可分样本的例子</p>

<p>其中隐藏层的激活函数采用Sigmoid,输出激活函数采用的是第2章介绍过的Softmax 函数。经过训练后，这样一个网络能得到如图3-9所示的结果。</p>

<p>图3-9中，虚线以上部分（浅色）是训练好的模型分类为1的区域，虚线以下的部分 （深色）是模型分类为0的区域。可以看到，这么一个简单的神经网络成功找到了一个类 似折线的二分类边界，将数据分开了。再仔细看一下图3-9还会发现，这个边界像是由两 条不同方向的直线“拼”起来的，只是交界部分的直线不那么直了。在远离交界的部分还</p>

<p>是能清晰看出直线边界的，如图3-9中的两条虚线所示，后面会讲到这是为什么。</p>

<p>下面来详细分析一下这个网络到底做了什么。输入层就不用介绍了。从隐藏层看起，</p>

<p>也就是两个用Sigmoid作为激活函数的感知机，在这样一个神经网络中，隐藏层是可以分 类弯曲边界的关键，这在第2章已经提到过，所以如果是线性不可分的样本，经过仿射变 换后，仍然是不可分的。这个时候，就要依靠非线性变换了，也就是Sigmoid激活函数起 的作用。我们把隐藏层第一个感知机hl的输出作为新的横轴，第二个感知机h2的输出作 为新的纵轴输出，把每一个样本在经过非线性变换后，在新的坐标平面的位置画出来。同 时也把图3-9中区分空间区域的网格线画出来，如图3-10所示。</p>

<table>
<thead>
<tr>
<th>V    &lsquo;</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>0    o</td>
<td></td>
<td></td>
</tr>

<tr>
<td>，0</td>
<td>O</td>
<td>o</td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td>\    o O</td>
<td></td>
<td>&ldquo;</td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td>，、、    o</td>
<td></td>
<td></td>
</tr>

<tr>
<td>么    </td>
<td>3 o °</td>
<td>/</td>
</tr>

<tr>
<td></td>
<td>O O    z</td>
<td>△厶</td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td>A A</td>
<td></td>
<td></td>
</tr>

<tr>
<td>A    O</td>
<td>o</td>
<td></td>
</tr>

<tr>
<td>A</td>
<td>:施</td>
<td>A</td>
</tr>

<tr>
<td>厶</td>
<td>厶</td>
<td></td>
</tr>

<tr>
<td>厶</td>
<td>•.么，..</td>
<td>A</td>
</tr>

<tr>
<td>A A</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<p>o.o驗縫識通鋼</p>

<p>0.0    0.2    0.4    0.6    0.8    1.0</p>

<p>图3-9样本和二分类模型的分类边界</p>

<p>图3-10输入样本经过隐藏层非线性变换后在新的 二维空间中的坐标</p>

<p>可以看到，在新的坐标平面内原来的平 面被严重扭曲，而扭曲之后的空间里样本是 线性可分的。注意到两个区域的分界线在这 个平面内就是一条直线，这就是隐藏层的重 要作用。事实上，如果连接一个sgn作为激 活函数的感知机，这个分类问题就解决了。</p>

<p>但是就如在第2章提到的，在分类问题中，</p>

<p>直接度量类别标签不如转换成一个分类概 率。所以这里采用的是两个单独的输出接 Softmax作为整层的“激活函数”，把输出 层经过Softmax变换后的两个输出值也按照</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-135.jpg" alt="img" /></p>

<p>上面办法画出二维坐标，如图3-11所示。图3—n Softmax层输出的结果表示在二维平面中</p>

<p>所以Softmax层的作用也一目了然。先通过一次变换让样本对应的值都大于0，方便 归一化。并且因为^的特性，让样本的区分度尽量高，这一点和SVM异曲同工。然后归 一化让两个输出的概率和为1，最后输出的标签就是按照概率比大小了。</p>

<p>现在回过头来再稍微深入分析一下，为什么隐藏层的非线性变换能够让一个弯曲边界 的样本分开并且成为线性可分的呢？来做这么一件事：以隐藏层的每个感知机的输出值作 为z轴，以原始的;^2平面作为另外两个轴，在三维空间中画出样本的分部，可以得到如 图3-12所示的两个感知机输出样本在xi~x2-z的三维空间中的分布。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-136.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-137.jpg" alt="img" /></p>

<p>图3-12将隐藏层的输出作为z轴画出的样本在三维空间中的分布</p>

<p>其中图3-12的左图对应hl的输出，右图对应h2的输出。两个三维图分别代表把两个 感知机的输出值作为z轴，在三维空间中的样本坐标分布。可以看到，第一个隐藏单元hl 的值相当于把平面上位于左上角半边的样本“抬升”了，而第二个隐藏单元h2的值 “抬升” 了位于右上半边部分的样本。到这里其实就很清楚了，接下来只需要一个简单的 线性相加就可以让中间部分标签为0的样本“抬升”到最高的区域。这样一个简单的截面 就可以将两种样本划分开了。这也是为什么在图3-9中可以看到分界线像是两条直线拼起 来的一个折线段，因为边界就是两个感</p>

<p>知机的分类直线组合起来的。在图3-9 中，虚线所在的部分分别对应了两个 隐藏单元分类的线性边界。用更加简 单的示意图表示就是类似图3-13所示 的情况。</p>

<p>图3-13感知机线性组合后形成非线性边界的示意图</p>

<p>单个感知机的非线性变换只能对+/_样本划分出一条线性边界。可是线性组合后就可以 给++和非的样本划分出一个折线的边界。这种对区域的划分和表示其实是神经网络中的</p>

<p>一个重要性质，叫做分布式表征(distributed representation),第4章会详细讲解。总之， 空间被进一步划分了，当然最后具体的边界则由数学优化来确定。事实上第三层输出层做 的就是类似的事情，我们把Softmax输出的值也用类似的方式分别作为z轴画在图3-14所 示的三维空间中。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-139.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-140.jpg" alt="img" /></p>

<p>图3-14将Softmax输出作为z轴，样本在二维空间中的分布</p>

<p>一目了然，从视觉上确实是区分度更高了，并且每个点在z轴所在位置相当于属于当 前类别的概率。这个小例子分别基于MXNet和Caffe的具体实现将在第7章中讲解。</p>

<p>3.2.3隐层神经元数量的作用</p>

<p>前面的例子帮助我们理解了非线性变换的作用。那么神经元数量又起什么作用呢？下 面再来看一个比三角函数分界稍微复杂一点的二分类例子，如图3-15所示。</p>

<p>显然对于这种圆形的分界线，两个线性分界线的组合就力所不及了。我们尝试增加一 个隐藏层的单元，然后训练，结果如图3-16所示。</p>

<p>1.0</p>

<table>
<thead>
<tr>
<th>0 8处</th>
<th>0^</th>
<th>U°o °o</th>
<th>O</th>
</tr>
</thead>

<tbody>
<tr>
<td>OOP</td>
<td>厶</td>
<td></td>
<td></td>
</tr>

<tr>
<td>3</td>
<td>△</td>
<td>△</td>
<td>&mdash;&mdash;-J</td>
</tr>

<tr>
<td></td>
<td>A</td>
<td></td>
<td>O</td>
</tr>

<tr>
<td>0O</td>
<td>厶</td>
<td>O</td>
<td>°oo</td>
</tr>

<tr>
<td>r\,</td>
<td>° oo</td>
<td>O1 0 .</td>
<td>O</td>
</tr>
</tbody>
</table>

<p>0.0    0.2    0.4    06    0.8    1.0</p>

<p>0.0    0.2    0.4    0.6    0.8    1.0</p>

<p>图3-15两个隐层单元网络不可分的样本在二维平面的分布    图3-16用三个隐层单元后得到的分类结果</p>

<p>通过标出的代表每个隐藏单元的线性分类边界的虚线，勉强还是能够看出是三条直线 的分界线拼成的。和前面例子一样，把隐藏层的分布也画出来，如图3-17所示。能发现在 隐藏层变换后的三维空间里样本已经是线性可分的了，和上一个例子的区别只是维度发生 了变化。</p>

<p>接下来再看看图3-18中Softmax层中的一个输出在输入样本的二维平面上的响应。</p>

<p>图3-17图3-16的样本在隐层对应的 三维空间中的分布</p>

<p>图3-18将Softmax输出作为z轴，样本 在三维空间中的分介</p>

<p>同样是通过非线性变换把一部分样本“抬升”，和其他样本形成了区分。所以总结一 下，从分类边界的角度来看，神经元数目对应着用于“拼接”出分类边界的线段数量，神 经元越多，就能“拼接”出越复杂的边界。而从维度的角度来看，神经元数目对应着非线 性变换后空间的维度，一般来说维度越高，变换后的样本越容易被线性分开。</p>

<p>3.2.4更加复杂的样本和更复杂的神经网络</p>

<p>接着3.2.3节所讲，更进一步，如果样本分布是如图3-19所示。</p>

<p>或者再复杂一些，如图3-20所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-144.jpg" alt="img" /></p>

<table>
<thead>
<tr>
<th>O</th>
<th>oA</th>
</tr>
</thead>

<tbody>
<tr>
<td>△</td>
<td>O A ° O</td>
</tr>

<tr>
<td>O</td>
<td>A °A</td>
</tr>

<tr>
<td>△</td>
<td>o △ o △</td>
</tr>

<tr>
<td>O</td>
<td>△</td>
</tr>
</tbody>
</table>

<p>图3-20二维平面上更复杂的样本分布</p>

<p>图3-19二维平面上一个类似螺旋状的样本分布</p>

<p>甚至是高维空间里的复杂分布呢？道理也一样，增加隐藏层单元数或是层数把样本投 射到更容易线性分类的更高维度空间。或者从另一个角度可以理解为对空间进行足够精细 的非线性扭曲，然后进行线性分类。</p>

<p>所以定性来看4随着感知机单元数量的增加，神经网络的分类和拟合能力是越来越强 的。而这种能力本质上来源于两个方面：第一是非线性变换，作用是让空间扭曲，样本可 以被线性划分或者更容易在变换后的空间里线性组合得到目标值；第二是维度，维度的增 加极大地增强了样本的线性可分的程度，这一点其实和SVM是很像。另一方面维度的增 加也可以让简单的非线性变换组合出复杂的非线性变换，来适应样本的分布，比如3.2.3 节中的例子。</p>

<p>第1章提到过，一个简简单单的两层神经网络（线性输入-Sigmoid隐层-线性输出）， 只要给够隐藏层神经元数目，是可以以任意精度逼近任意有界连续函数的。证明这里就不 讲了。不过通过前面的分析和第2章关于非线性变换的内容定性来理解，其实就是通过更 多的单元，一点一点拼出一个更加细腻的抬升/下降的边界，然后通过改变参数控制非线性 的程度，也就是抬升/下降的程度。只要神经元的数量足够多，对于任意的有界连续函数， 通过神经元的组合，都可以一点一点地拼凑出想要的形状。</p>

<p>^&gt;TIPS1: TensorFlow Playground, TensorFlow 的游乐场</p>

<p>本节举的例子是最简单的非线性例子。读者自己也可以试试各种分布的样本在 神经网络中的分类边界是如何构成的。TensorFlow已经提供了这样的网址，供 大家自己动手搭建和训练一个神经网络用于分类一些二维空间中的样本，同时 还能查看训练过程中每层空间的变化。网址为<a href="http://playground.tensorflow.org/。">http://playground.tensorflow.org/。</a></p>

<p>^TIPS2:神经网络和神经</p>

<p>还是要提一句的是，虽然神经网络的名字里有“神经”两个字，然而通过3.2 节的讨论可以知道，如果感知机对神经元的模仿还有那么点意思的话，人工神 经网络和真正的神经网络就没有什么关系了，所以有不少研究者更愿意称神经 网络为多层感知机(Multi-Layer Perceptron，MLP )。</p>

<p>3.3后向传播算法</p>

<p>第1章曾经提到过，后向传播算法是David Rumelhart于1986年提出后得到了广泛 应用。不过事实上1974年的时候，Harvard的博士生Paul Werbos在他的博士毕业论文中 已经提出过后向传播算法，可惜并没有造成影响。本节一起了解一下这个随着神经网络的 崛起而名声大噪的方法。</p>

<p>3.3.1求神经网络参数的梯度</p>

<p>通过3.1和3.2两节的讲解，对于一个典型的全连接神经网络，其实就是一层层的仿射 变换+非线性变换的疊加，所以可以将其看作是一个复合函数。比如一个《层的网络，可 以将其表示成如下的复合函数：</p>

<h6 id="z-z-公式-3-6">z z .    (公式 3-6)</h6>

<p>=Sn (/。(心-批-”…^久乂^如’/卜))))…)))</p>

<p>其中表示仿射变换，g表示激活函数，下标表示层数。注意如果这里x表示的是 个向量的话，w是个矩阵，*是个向量。第2章已经讲过，一般的机器学习问题，都可以 通过损失函数Z转换成一个优化问题。将损失函数作为要最小化的目标，数据作为给定的 输入，参数作为可变量进行优化，也就是要优化的变量是公式3-6中的IV，Zi和0。优化问 题的常用方法第2章已经讲过了，所以现在的问题是要求神经网络中每个参数的梯度。</p>

<p>第2章末尾讲过，复合函数求导可以用链式法则。而通过公式3-6,神经网络恰好就 是一个参数量庞大的复合函数。算上损失函数A也不过是又多“复合” 了一些，所以求导 的链式法则当然也适用。其实这就是后向传播算法的最基本思想：通过链式法则求出所有 参数对损失函数的梯度。</p>

<p>3.3.2 计算图(Computational Graph)</p>

<p>计算图是自动求导方法中的一个基础概念，用在深度学习中主要是用来表达输入输出 以及中间变量(也就是隐藏神经元)之间的计算关系。如图3-21所示，左边的图是一个简 单的计算图的例子。</p>

<p>这么一个简单的图中，每个节点代表一个变量。每条边代表变量间的关系，具体就是</p>

<p>图3-21中的公式，先计算然后计算所以计算图很自然地将变量之间的依赖 关系包含了进来。另外需要注意的是，计算图中是不规定计算关系粒度的，所以我们可以 自己定义计算关系(operation)，比如直接定义这样左边的4个节点的计算图 就化成了右边3个节点的形式。例子中这么做虽然没什么意义，但这种灵活的表达方式是 有很多意义的，比如Theano的文档中的一个简单的例子，如图3-22所示。</p>

<p>图3-21计算图的例子</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-146.jpg" alt="img" /></p>

<p>先看左边的图，这个例子中先计算了    然后计算了 (假设6类0),最后d</p>

<p>再作为输入进一步计算根据小学知识，先乘以一个数然后除以同一个数，结果当 然还是该数本身。所以d=ab/b=a，左边的图可以化简成右边的图。</p>

<p>简单了解了计算图的基本概念，接下来进入正题，利用计算图通过后向传播来计算梯 度。这里还是用图3-21中所示的简单例子，计算过程如图3-23所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-147.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-148.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-149.jpg" alt="img" /></p>

<p>=2 c    =2 c</p>

<p>=2(a+b)    =2{a+b)</p>

<p>图3-23计算图上的后向传播算法例子</p>

<p>如图3-23所示，第一步：在有些教材或是习惯中，从输出节点出发，这一步不用算也 知道初/初=1。第二步：计算下一层，也就是6/的父节点的偏微分初= 第三步: 再下一层，首先来计算3c/&amp;z = l。至此将和dc/如相乘，就得到了输出节点J对输 入节点6Z的偏微分为= = + 也就是我们要求的梯度。注意在计算这一步的 时候，36//如=2c是在第二步计算中已经保存起来的值，所以在这一步中就避免了重复计 算，这是后向传播算法的精髓思想之一。算完了节点6Z,节点也类似可以算出 dd/da = 2c = 2(a + b)，并且在计算时同样利用前面已经保存的= ，避免了重复计 算。注意在这个例子中，我们发现计算图的每一条边，也表示两个量之间的偏微分的值。</p>

<p>3.3.3利用后向传播算法计算一个神经网络参数的梯度</p>

<p>3.2.2节中讲到了计算图中，计算关系可以自己定义粒度，其实变量也是一样的。所以 考虑3.3.1节中讲到的情况，变量可以是向量、矩阵或者高维张量（tensor）。在变量和计 算关系都可以灵活定义的前提下，神经网络在计算图中的表示就容易多了，下面来看图3-24 中所示的例子。</p>

<p>图3-24计算图节点的合并，感知机中的后向传播</p>

<p>图3-24中左边的是一个感知机的例子，输入是一个二维向量化七），要优化的参数是 和仏计算被分解为最基本的乘法和加法操作，最后一步是一个ReLU非线性变 换。根据图3-24中的关系，可以对每条边都计算出梯度的表达式，梯度传递的路径和每次 要计算的梯度用虚线表示在图3-24中。做后向传播的时候只需要和图3-23中一样，沿着y 出发把所有虚线连接的路径上的梯度乘起来，直到叶节点就可以了。通过这个例子注意到一 件事，那就是后向传播算法的计算量是和一个计算图中，需要后向传播的边的总数成正比的。</p>

<p>接下来尝试把计算关系、节点形式和维度都变化一下，如图3-24中的右图所示。对位 相乘实际上就是点积，根据第2章讲到的线性代数知识，扩展到多维就是向量和矩阵的乘 法，在图3-24中用dot表示。我们来考虑将3-24中左边的图和计算关系拓展成一个典型的 神经网络中的一层：W是个矩阵，x、A、p、＜和^都是向量，其中假设j的维度是w，x 的维度是〃。根据第2章末尾讲到的链式求导的知识，只要从开始向后传导相关的雅可 比矩阵就可以实现后向传播了。所以和图3-24的左图是一回事，只不过更加简洁地表达了 则根据计算关系可以知</p>

<p>计算和多维度的情况。另外需要注意的是，在这样一个汁算图中, 道，J/0、人（6）和人⑻都是的对角矩阵，如下：</p>

<p>〉0?1:0 0 0    t2&gt;0?l:0</p>

<p>0</p>

<p>0</p>

<p>t &gt;0?1:0</p>

<p>m</p>

<p>0 0</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-151.jpg" alt="img" /></p>

<p>db&rsquo;</p>

<p>0</p>

<p>dt2</p>

<p>db2</p>

<p>人（P）</p>

<table>
<thead>
<tr>
<th>0_3z,0</th>
<th>0 ••0 •如2</th>
<th>dtmdbm J• 0• 0</th>
<th></th>
<th>0_10</th>
<th>0 ••0 •1 ••</th>
<th>• 1-o&rsquo;• 0</th>
</tr>
</thead>

<tbody>
<tr>
<td>：</td>
<td>••</td>
<td></td>
<td></td>
<td>0</td>
<td>0 •</td>
<td>• 1</td>
</tr>

<tr>
<td></td>
<td></td>
<td>dt</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td>0</td>
<td>0 •</td>
<td>m</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<p>对于如果计算的时候把FF按行展开成一个向量，则是一个m^mn的矩 阵，其中除了对角线上的每个lx〃的子矩阵，其他元素都是0,广义上相当于一个分块对 角矩阵。</p>

<table>
<thead>
<tr>
<th></th>
<th>dp&rsquo;nw    nw.</th>
<th>0</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td>0</td>
<td>dp2dw2,i</td>
</tr>

<tr>
<td></td>
<td>0</td>
<td>0</td>
</tr>

<tr>
<td></td>
<td>x。0    x,</td>
<td>0 …&hellip;…</td>
</tr>

<tr>
<td></td>
<td>0</td>
<td>0 …</td>
</tr>
</tbody>
</table>

<p>如2</p>

<p>0</p>

<p>0</p>

<p>dpm …dp。</p>

<p>dwm，n</p>

<p>xi</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-152.jpg" alt="img" /></p>

<p>所以总的来说，对于一个典型全连接层，其实只是在输出对应的各个维度上分别求了梯度。 最后加深一下印象，下面给出一个对实数值^进行回归的神经网络例子，如图3-25所示。</p>

<p>图3-25后向传播计算一个神经网络参数的梯度</p>

<p>如图3-25所示为一个双层的全连接神经网络，输出是一个一维变量y,实测数据以/</p>

<p>丨 2</p>

<p>表示，采用5^-/）作为损失函数。要计算梯度的参数是FFp Zh，恥和如，也就是仿射</p>

<p>变换的参数。整个梯度的计算过程是：首先进行前向计算，由输入*开始向前传播，将所 有节点的值计算出来：然后执行后向传播算法，由损失函数£开始，计算梯度并向后（x 所在方向）传播，其中3£/办=    其他边对应的梯度计算和图3-24中的例子相似，唯</p>

<p>一的区别是最后一层的输出是单输出（一维）。当然这个例子只是用来表示神经网络计算 图的一种，特别是为了方便说明后向传播的概念。就像前面说的，计算图的粒度和计算关 系都是可以自己定义的，只要方便计算或者实现即可。</p>

<p>^TIPS1:更多关于后向传播算法</p>

<p>如果有读过一些比较早的机器学习和神经网络教材的读者可能会发现，这里说的 后向传播和老教材中不太一样。这是因为许多老教材中，比如Tom Mitchell的《机 器学习》，一讲到后向传播，往往是和权值更新打包一起讲，而且在那个时候梯度 下降的方法也比较单纯、原始，还没有用到像现在这么多一阶梯度下降的变种。 而随着深度学习的发展，如今更新权值的思路其实变得更简单粗暴了。概括一 下就是，把原来打包式的做法拆开成了两步：即求梯度和梯度下降。所以现在 再提到后向传播，一般只是指第一步，即求梯度。</p>

<p>^TIPS2:深度学习中的张量</p>

<p>本节已经提到了张量，在实际的深度学习应用中，比如卷积层，样本的mini-batch 等（后面会讲到），很多地方都会接触到张量。张量甚至成了一些框架中的基 本元素，比如Theano，甚至TensorFlow的命名就是张量。</p>

<p>不过要说明的是，深度学习中当提到张量时，和物理或是几何中的张量关系不 大，可以简单认为就是在不同维度上存数据的一种形式。无论对张量的梯度计 算是如何实现的，都可以等效于将张量展开成一个向量，计算完梯度之后，再 按照原来张量中元素对应的顺序“折叠”回一个张量。</p>

<p>3.3.4梯度消失</p>

<p>后向传播算法虽然很有效率地解决了梯度计算的问题，但是并没有完美解决神经网络, 尤其是多层神经网络训练的问题。在第1章的神经网络兴衰史里也提到了，当时面临的难 题是梯度消失和梯度爆炸问题，也正是本节要讲的主题。</p>

<p>梯度消失是传统神经网络训练中非常致命的一个问题，其本质是由于链式法则的乘法 特性导致的。比如来考虑深度学习之前在神经网络中最流行激活函数之一 Sigmoid,其表 达式和导数如下：</p>

<p>(7( X</p>

<p>(J [X</p>

<p>l + e_x</p>

<p>e&rsquo;x</p>

<p>(公式3-7)</p>

<p>(1</p>

<p>把这个函数的导数画出来，如图3-26 所示。</p>

<p>图3-26 Sigmoid函数的导数</p>

<p>对于Sigmoid,导数的最大值在输入 为0处，值为0.25。考虑一个激活函数都 是Sigmoid的多层神经网络，则梯度向后 传导时，每经过一个Sigmoid层就需要乘 以一个小于0.25的梯度。而每乘一个梯度，</p>

<p>则梯度的值又变得更小一些。况且在优化 的过程中，每个激活层输入都在0附近的 概率非常非常低。也就是说随着层数的加 深，梯度的衰减会非常大，迅速接近0，</p>

<p>这就是梯度消失问题。</p>

<p>梯度消失问题是传统多层神经网络难以训练的最大难题。根据上一段对问题的描述可 以知道，这个问题在训练深层网络中的体现是：离输出层越近的参数，梯度越大，成了主 要在进行学习的参数；而远离输出层的参数则只能在接近0的梯度则以一个非常小的速率 进行学习。这种情况相当于一个恶性循环，因为靠近输出层的节点的值都是由前面那些学 习速率很慢的层执行前向运算得来。而前面层因为学习速率慢，所以参数未必学到了什么 特征，所以这些后面层的输入随机性会比较强，这样相当于在一个有随机性的数据上进行 学习，即使学习速率再快，最后也未必能真的学到有用的特征。这一过程又会让前面层的 参数更难学到有效的值。所以将Sigmoid这一类函数作为激活函数的传统神经网络，随着 层数的加深，效果反而会下降。</p>

<p>因为导致梯$消失的根本原因是小于0的梯度连续做乘法。现在看来解决的思路主要 有两种：第一种是第1章里提到过的逐层无监督预训练+后向传播微调。这个办法其实严 格来说并不是针对梯度消失问题，只是预先找到一个很好的初始化位置，降低上一段说的 靠近输入层一直在“瞎学”的风险。加上这个方法训练起来也比较麻烦，如今几乎没人用 了，更为主流的解决办法是，第二种方法，ReLU等可以避免梯度衰减的激活函数。不过 需要注意的是，即使有了 ReLU,在非常深的网络中仍然会存在梯度传播困难的问题，因 为小于1相乘的衰减并不是梯度减弱的唯一因素，后面内容中还会继续探讨。</p>

<p>3.3.5修正线性单元(ReLU)</p>

<p>ReLU (Rectified Linear Unit)在3.1.3节中也提过了，这里再展开讲讲，如图3-27a</p>

<p>所示。</p>

<p>ReLU中，小于0的部分直接置0,大于0的部分即为输入。这样即实现了非线性变换, 同时大于0的部分梯度为1。这样对于需要从输入一直传递的信息，激活函数的梯度总是 1,即使连续相乘也不会变小，解决了梯度消失的问题。第1章也提到过，2012年Alex Krizhevsky提出的Alexnet里，ReLU是帮助训练快速收敛的一个有力手段。</p>

<p>根据ReLU的定义，信息只能在ReLU的输入大于0的区域进行传播(前向和后向)， 这带来了另外一个优点就是稀疏性。稀疏性不仅对网络的性能提高有帮助，而且从神经科 学的角度，神经元的激活率是非常低的，这也是一种仿生的模拟。不过这种特性也带来一</p>

<p>个问题，就是在输入小于0的区域，即使有个很大的梯度传播过来也会戛然而止，也就是 “挂了”，所以这个问题被称做Dying ReLU。针对这个问题Andrew Ng组提出了 Leaky</p>

<p>ReLU,如图3-27b所示，将ReLU小于0的部分改成一个斜率小于0大于-1的线性函数 y=axf对于Leaky ReLU, a是一个非常小的值，比如论文中给出的是a=0.01。这个名字非 常形象，感觉就像是二极管中的漏电流(leak current),不知是不是作者对电子的课程印 象深刻。总之，Leaky ReLU就是用一个非常小的系数让信息和梯度的传播不至于中断。同 时系数很小还一定程度上继承了 ReLU带来的稀疏性优点。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-155.jpg" alt="img" /></p>

<p>c)</p>

<p>图 3-27 ReLU、(Randomized) Leaky ReLU、Parametric ReLU 和 Softplus 示意图</p>

<p>在 Leaky ReLU 的基础上，有人在 Kaggle 的 NDSB (National Data/Science Bowl)竞赛 中，把求平均提高泛化能力的思想加入进来，发明了随机版本的Leaky ReLU。这个方法具 体来说就是在训练的过程中《按照高斯分布随机取值，测试/验证的时候取均值。直观理解 也参照图3-27b所示。</p>

<p>既然小于0区域的斜率可以取值，那么为什么不把这个值作为一个参数呢？于是 MSRA的He Kaiming提出了参数化ReLU (Parametric ReLU)，让a称为一个可优化的参 数，如图3-27b所示。</p>

<p>不管是ReLU还是PReLU,都是有棱有角的，实际应用中还有一个平滑版本的ReLU, 叫做Softplus,公式如下：</p>

<p>/(x) = ln(l + ex)    (公式 3-8)</p>

<p>Softplus的曲线如图3-27c所示，其中虚线是用来对照的ReLU。Softplus其实就是 Sigmoid的原函数，用来做激活函数是Bengio的组于2000年NIPS的文章里提出的。除了 图3-27中画出来的这些，ReLU 一族或是类似ReLU的激活函数还有Noisy ReLU、Shifted ReLU、Exponential LU和Concatenated ReLU等，在此就不展开说了，有兴趣的读者可以</p>

<h6 id="自行学习">自行学习。</h6>

<p>本质上来说，ReLU解决梯度消失的原则是靠梯度等于或接近1,从而避免连续相乘的 结果衰减，而ReLU—族或类似的办法也都是基于这一原则的变种。</p>

<p>3.3.6梯度爆炸</p>

<p>梯度的不断衰减是因为连续乘法导致的，那么如果在梯度的连续乘法过程中总是遇上 很大的(绝对)值呢？比如考虑一个全连接网络，随着算法的进行，参数进入了某一个区</p>

<p>域，导致一条路径上的多个节点计算出的值都很 大。在每次计算仿射变换对应的梯度时，都会得 到很大的值，所以在后向传播算法中梯度可能 会因为连续乘法出现非常大的值。一旦这个值 使得权重的更新步长过大，就像第2章讲学习率 时举的学习率过大的例子(如图2-51a)…样，</p>

<p>很可能会让算法不收敛，这个问题被称为梯度爆 炸问题。下面举个比较形象的例子，来看图3-28。</p>

<p>如图3-28所示为一个二维的例子。可以看到 函数的曲面有一个类似“断崖”的区域，当优化 的参数值在某一步恰好到了 “断崖”时，会获得</p>

<p>图“断崖”和梯度操性</p>

<p>一个极大的梯度，而如果还是将这个梯度乘以学习率作为迭代步长的话，下一次迭代的步 长会非常大。如图3-28中的实线箭头所示，从而“飞”出了合理的区域，这就是梯度爆炸。 根据描述和图3-28中的例子，解决梯度爆炸的方法也很直观，只要把沿梯度方向前进的步 长限制在某个值内就可以避免过大的步长了。根据这个思路，一个常用的办法是如果计算 出来梯度的范数(norm)大于某个阈值，则对梯度以这个范数为基准做归一化，让新的梯 度的范数等于这个值。举个例子，还是以二维情况来讲，如果算出来在“断崖”处的梯度 为(60, 80)，而梯度的范数的阈值限制在5，则有：</p>

<p>60</p>

<p>x5,</p>

<p>80</p>

<p>x5</p>

<p>(0.6x5,0.8x5) = (3,4)</p>

<p>a/602 +802    7602 +802</p>

<p>这种将梯度的#大值限制住的办法，通常被称为梯度裁剪(gradient clipping)</p>

<p>3.3.7 梯度检查(gradient check)</p>

<p>因为梯度的计算常常不稳定，而且后向传播算法本身依赖于梯度表达式，所以并不是 一个容易实现和调试的算法。因此人们想到了用数值计算的梯度和计算图计算的梯度进行 对比，来检查梯度的计算是否出现了错误，俗称梯度检查(gradient check)。计算的方法 也很直接，对于一个维度而言：</p>

<p>• 102 •</p>

<p>—-—I= lim— &mdash;&mdash; ~ — &mdash;&mdash; (公式3-9)</p>

<p>Ad    2e    2 A</p>

<p>也就是说用一个非常小的A通过数值的方法实现对梯度的近似。A的取值应该尽量小， 但是又不能太小，否则有可能因为浮点数精度引入计算误差，通常这个值在le-4〜le-6 之间。</p>

<p>有了数值计算的梯度值，就需要和表达式算出的梯度值进行对比，对比的思路也比较 简单，就是比较梯度差异相对梯度的值，一般用如下公式：</p>

<p>relative error =</p>

<p>I八-八I</p>

<p>臟(八，八)</p>

<p>(公式3-10)</p>

<p>其中是解析(analytical)的梯度值，是数值计算(numerical)的梯度值，这个</p>

<p>相对误差作为判断梯度是否出现错误的一个参考。按照斯坦福大学的课程《用于视觉识别 的卷积神经网络》(CS231n)的建议，单精度情况下，这个值大于le-2则说明梯度很可 能错了，小于le-7则说明没什么问题，在这两个值之间则视损失函数的平滑度决定。</p>

<p>3.3.8从信息传播的角度看后向传播算法</p>

<p>通过前面的讨论可以知道，无论是梯度消失还是梯度爆炸，其根源都是链式求导法则 的连续相乘的特性。从这个角度来看，梯度消失和梯度爆炸其实都是一个问题，就是梯度 累积相乘带来的不稳定性。那么是否解决了梯度消失和梯度爆炸问题，深层网络的训练就 解决了呢？其实梯度的消失和爆炸只是梯度传播过程中不稳定性体现的两个方面，其他一 些因素也影响了深层网络的训练。</p>

<p>从信息论的角度来看，数据经过处理的步骤越多，则丢失的信息可能也会越多，这叫 做数据处理不等式(Data Processing Inequality, DPI)，表达如下:</p>

<p>X^Y^Z</p>

<p>（公式3-11）</p>

<p>其中x—y—z是一个马尔科夫链。/是互信息，表示一个随机变量包含另一个随机变 量信息量的度量，这里可以简单认为是信息相关性的一种度量。第2y章里讲到过的KLL散 度就是可以描述互信息的一种表达。当然这些都是定义，在这里可以认为就是hr—Z信 息传递的路径，而代表着信息传播的过程中，只有可能丢失，而不可能增加。 而这种信息的丢失，或者说信息在传播过程中的误差，体现在神经网络中就是后向传播算 法随着传播带来的信息丢失。具体来说要计算梯度都需要输入数据，而数据的分布所携带 的信息在计算后向传播的过程中会一层层丢失，这种信息丢失的多少也是影响算法优化性 能的一个重要原因。</p>

<p>除了 DPI,梯度计算本身的性质也会导致信息随层数增加而丢失，具体来说就是梯度 所代表的线性近似。先来看图3-29。</p>

<p>从函数展开的角度，梯度下降的本质就是对函数做了 一阶线性近似，然后再进行迭代。如图3-29所示，画出了 一个非线性曲线的一段，及其某一点梯度所代表的线性近 似。可以看到，离求梯度的点越近，这种近似越好，相反 则误差越大。在每次迭代时，线性近似的误差会按照后向 传播的方向从输出一层层传递到输入层，而且随着迭代的 次数增加，误差越来越大。对于ReLU等单元，这种误差 同样存在，虽然大部分区域都是可以被线性近似完美拟合，</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-158.jpg" alt="img" /></p>

<p>但是输入为0处，也就是梯度变化的过渡区域是无法被线 性近似的。只要迭代时经过了过渡区域，误差就会产生。</p>

<p>而层数越深，则在后向传播计算后迭代时经过过渡区域的可能性就越高。</p>

<p>针对信息传播的误差问题，也有很多办法，比如增加辅助损失函数(auxiliary loss), 让梯度在传播的路径变得短一些，这在2014年ILSVRC的冠军网络结构GoogLeNet中就 有所体现，使用了两个路径更短的辅助损失函数来促进收敛。直观来看这个方法是帮助靠</p>

<p>近输入的低层的特征有更强的区分性，而从信息传播角度则是减少了传播路径的长度，减 小信息传播中的丢失。</p>

<p>在2016年的ECCV上，北京大学的林宙辰教授的小组提出了接力后向传播算法，其 基本思想是每次后向传播只传播一个较短的长度，然后利用辅助损失函数像接力一样，把 没有传播到的层再继续利用后向传播算法接着计算。该方法在应用到2015年ILSVRC的 场景分类竞赛(Scene Classification Challenge)中取得了第一名的好成绩。</p>

<p>3.4随机梯度下降和批量梯度下降</p>

<p>有了数据，有了神经网络模型，又有了后向传播算法计算梯度，第2章也讲过了各种 一阶优化算法，感觉万事俱备了。是否直接把所有数据往模型里一放进行训练就可以了呢？ 实际情况并没有这么简单，本节来讨论下训练神经网络，尤其是深度网络中的一些数据层 面的具体做法。</p>

<p>3.4.1全量数据(full-batch)梯度下降</p>

<p>全量数据梯度下降是最直接的做法，每次计算梯度的时候把所有训练数据都考虑进来。 具体来说就是，假设一共有个7V个样本的话，计算损失函数的时候，对所有的7V个样本都 求一遍损失函数的值，然后求平均：</p>

<p>1 N</p>

<p>.    (公式 3-12)</p>

<p>/-    Jy i=</p>

<p>这个方法虽然简单、直接，并且能最好地将数据分布的信息代入到梯度计算中，同时 还方便并行计算的实现。但是在大数据时代，数据量少则几万，上不封顶，使用全量数据 的梯度下降就显得很不现实。</p>

<p>3.4.2随机梯度下降(SGD)和小批量数据(mini-batch)</p>

<p>和全量数据梯度下降相对的办法是随机梯度下降(Stochastic Gradient Descent, SGD)。 具体的做法是每次从训练样本中随机抽取一个样本用来计算损失函数，将相应计算出的梯 度作为当前一步梯度下降的依据。因为每次梯度下降只抽出一个样木进行计算，所以SGD 的第一个优点就是快。比如一个有10000个样本的数据，如果用全量数据计算梯度，10000 个样本都算一遍，也就下降一步。而用SGD的话，10000个样本都过一遍，就下降了 10000 步！这在计算效率上的差异是显而易见的。</p>

<p>虽然SGD在计算效率上有巨大优势，不过上面说的是理想情况，根据描述SGD还有 另一个特点是随机性。因为数据是从全量中进行的采样，所以仍然是包含数据分布的信息, 可以知道SGD在梯度下降过程中的随机性非常大。随机性像噪声一样带来不确定，但是在 深度学习的应用中是一种优点，因为深度学习中面临的基本都是非凸优化问题。第2章讲 过克服非凸问题的一些方法，比如加入冲量。SGD则相当于另一种思路，通过随机性的引</p>

<p>入，实现了梯度下降时的启发式搜索。下面来考虑一个形象的例子，如图3-30所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-159.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-160.jpg" alt="img" /></p>

<p>a)    b)</p>

<p>d)</p>

<p>图3-30全量梯度下降和SGD对应的损失函数曲面</p>

<p>图3-30a是在考虑到大量数据时，损失函数曲面的图，可以看到数据量大的时候，随 机性非常小可以忽略，曲面有一个非常稳定的极小值。而图3-30b、c、d图是考虑3个随 机样本对应的损失函数曲面。因为数据都是从同一个分布中而来，所以曲面的大体形状和 图3-30a相似。而随机性则让曲面在局部和3-30a产生了很多差异，这种差异的好处是在 大量数据的曲面中，极小值的位置在单个随机样本对应的曲面中未必是极小值。这样一来， 在SGD中，梯度有一定概率是朝着“逃出”极小值的方向，从而避免陷入极值，同时梯度 下降的大方向仍然保持正确。总之综合两点考虑，SGD比起全量数据梯度下降还是有很大 优势，但是在实际应用中，尤其是类别很多的分类问题中，SGD的随机性也有可能导致算 法不收敛，所以更为常用的是一个折中的办法，就是小批量数据(mini-batch)。</p>

<p>小批量数据的思路其实还是一样，全量数据太多，纯SGD每次用一个样本不太稳定， 所以每次计算梯度随机选取一定数量的部分样本。这样计算量仍然远小于全量数据，同时 一定量的采样既能保持一定的随机性，又能控制随机的程度不会过大导致算法不收敛。此 外SGD每次只有一个样本，无法在数据层面并行计算，而mini-batch则可以并行。既然是 批量的数据，每个批次的样本量的选择也成了重要的超参数。尽管有研究(LeonBotton，</p>

<p>《Large-Scale Machine Learning with Stochastic Gradient Descent》)表明 SGD，也就是样本</p>

<p>量为1是最快的，但实际使用中的问题让样本数量的选择成了一个经验活。比如Github上 有个热度挺高的库叫做caffenet-benchmark,里面通过实验评估了各种超参数对imagenet 训练结果的影响。在这个库的评估里，训练imagenet-2012数据最优的样本数量是64。最 后要说的是，mini-batch严格来说和SGD不是一回事，不过随着时间的推移，现在在深度 学习中一提到SGD,其实多数指的都是mini-batch。</p>

<p>在各种深度学习框架中，经常看到的两个概念一个是迭代次数(iterations)还有一个 是训练了多少代(epoches)。迭代次数就是指更新了多少次参数的值，而代数就是值遍历 了多少次所有的训练样本。</p>

<p>皂TIPS:深度学习中的极小值</p>

<p>第2章已经提到过，高维度中，极小值并不是最大的问题，鞍点反而会更加令人 头疼。事实上，在神经网络尤其是深度学习中，即使存在极小值并且算法最后收 敛到了极小值，也未必是个大问题。根据Bengio教授的一些研究，在高维度和 深层网络下，局部最小值往往和全局最小值非常接近，所以效果上也未必有什么 大差别。而 LeCun (《The Loss Surfaces of Multilayer Networks》)、斯坦福大学 以及 Google 的一些最新研究(《Qualitatively Characterizing Neural Network Optimization Problems》，《Identifying and attacking the saddle point problem in high-dimensional non-convex optimization》)则发现，尽管深度学习中损失A数 的曲面严格来说是非凸的，但是大致形状也是凸的。总之极小值在深度学习中越 来越不是问题了。</p>

<p>3.4.3数据均衡和数据增加(data augmentation)</p>

<p>现在考虑一个二分类问题，比如区分一张图片里的是一只猫还是一条狗。因为某种原 因，数据搜集的时候只找到了 2000张猫的图片和50000张狗的图片作为训练数据。如果直 接把这52000张图片放在一起，然后用mini-batch的方法进行训练，则会出现一个问题， 就是数据的不均衡。比如每次迭代的样本数量为100个，那么平均下来每次样本中猫的数 量通常只有3、4个。这样的结果是计算损失函数的时候，狗的图片比重太大，所以相当于 是针对狗的图片进行了充分的训练。猫的图片带来的损失的影响很低，所以猫的特征就并 不容易被学习到，这会影响分类器最终的性能。</p>

<p>很自然地，我们希望训练数据总体上是均衡的，所以对数量不平均的数据，在训练前 一个必要的步骤就是做数据均衡。最直接的想法就是把猫的图片复制24遍，这样猫的样本 也是50000张和狗的样本打平了。这样做是有效果的，不过在实际应用中更常用的手段是 做数据增加。</p>

<p>在机器学习中，数据通常都是来源于一个分布。比如猫的图片，无论图片中的猫是什 么颜色，什么姿势，眼睛是瞪着还是眯着，都能看出是一只猫。而所有的猫的图片，都可 以看作是来自于一个分布。所以在做数据平衡的时候可以考虑模拟这个分布来产生一些和 已有数据不完全一样的数据。具体到猫的图片的例子，就是可以考虑把图像旋转一个角度, 左右镜像对称，明暗度做一些改变，或者是裁剪等，如图3-31所示。</p>

<p>明暗</p>

<p>长宽比</p>

<p>旋转    裁剪</p>

<p>图3-31猫图片数据增加的例子</p>

<p>做了这些改变之后，仍能一眼看出这是只猫，可以认为图片仍是来自“猫”这个分布。 数据增加不仅可以用来解决样本数量不平衡的问题，还可以带来其他的好处。比如想象一 下2000张猫的训练数据全是向左看的猫,那么训练出的模型遇到一只向右看的猫就未必能 判断得很准。所以数据增加的时候可以随机加入水平翻转，让向右看的猫也出现在训练样 本之中，增强模型对从未见过的数据的判断能力，这也是数据增加带来的好处。所以在实 际应用中，即使是数量多的-一类的图片也可以用数据增加的手段来获取更多的训练样本，</p>

<p>来增强模型对于未见过的数据的分类能力。比如猫和狗的例子中，可以通过数据增加把猫 和狗的图片都增加到10万张再进行训练。甚至可以在每次训练迭代之前实时在原始图片基 础上随机加上一些变化，相当于拥有了无限的数据增加的样本。现在很多深度学习框架中 都已经出现了这样的预处理结构。</p>

<p>0&gt;TIPS:类均衡采样(Class-aware Sampling)</p>

<p>尽管数据做了均衡后可以保证总体数量上的均衡，但是单纯随机采样的 mini-batch中，样本的分布却还是随机浮动的，尤其是当分类类别大于批量采样 的数目时，有时候一个类出现一个以上的样本，而有的类却一个都不出现，这 些情况的出现对于收敛并不是一个好的因素。所以一个思路是，除了总体上样 本数量的均衡，在梯度下降的每个迭代批次进行采样的时候，要尽量让样本在 类别和数量上都更加均匀。类均衡采样(Li Shen, 《Relay Backpropagation for Effective Learning of Deep Convolutional Neural Networks》)就是这个思路下的 一个方法。</p>

<p>这个方法首先将所有的类别列出来，并随机打乱顺序。每次采样的时候按照采 样数量在打乱顺序后的类列表上依次采样，如果采样到列表末尾，则重新打乱 顺序继续采样。这样保证了每个批次数据中，类别的均匀性。然后在每个类别 内再用同样的策略进行随机的样本采样，这样不需要做数据增加就实现了均匀 采样，而且均匀度比平衡样本数量后直接随机采样更高，训练时的整体收敛性 也更好。</p>

<p>3.5数据、训练策略和规范化</p>

<p>从本节开始的内容其实不限于神经网络，而是机器学习中普遍的问题，当然，神经网 络是机器学习算法中的一种。当我们衡量一个机器学习算法是否好的时候，最直接的方法 是衡量算法预测和测量数据的误差。比如对于训练数据，损失函数就是衡量这种误差的方 法。训练一个神经网络时，损失函数降到一个非常小的值，我们说网络很好地收敛了。然 而当网络训练好以后，是否能对训练数据以外的数据也做出很好的预测呢？其实这才是 更看重的指标，这种对训练数据以外数据做出准确预测的能力称为泛化(generalization) 能力。</p>

<p>3.5.1欠拟合和过拟合</p>

<p>欠拟合和过拟合是机器学习中常见也非常简单的两个概念，下面来看图3-32所示的例子。</p>

<p>图3-32 —维拟合的例子</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-166.jpg" alt="img" /></p>

<p>图3-32中所示的3个图中都画出了同样的数据点，这些点都是由一个“倒U”形状的 曲线加上叠加一个高斯分布的噪声产生的。虽然看上去不是很整齐，但还是能一眼看出来 是一个“倒U”的形状。其中红色的圆点是用来训练数据，而蓝色的三角形点则是训练中 未曾出现的数据，不过就像前面提到的，红色和蓝色的点都是由“倒U”曲线加上噪声产 生的样本，所以它们是来自同一个分布，在机器学习中，这种分布通常称为数据产生分布 (data-generating distribution),事实上在前面内容里曾提过这个概念。训练数据和测试数 据来源于同一分布，是机器学习中的一个基本假设。这是一个很直观很显然的事情，比如 我们训练了一个机器学习算法，根据体温、心率和血压用来判断一个人是否很平静，这个 模型无论判断人有多准确，都难以直接用到一只猫身上，因为猫的各项指标来自于完全不 同的分布。或者再白话些就是我们从一件事情中学到的经验未必能放到另一件事情上。总</p>

<p>之，在数据同分布的假设下，从训练数据中学习到的特性，才能有效预测没有见过但是和 训练数据来源于同一分布的数据，这个过程就是泛化。</p>

<p>在这个假设下，图3-32a中尝试用一个线性的模型去拟合红色的圆点数据，结果可想 而知，不仅红色的训练数据难以拟合，蓝色的测试数据也根本对不上。其根本原因是因为 线性拟合的模型过于简单，表达能力不足以学习到数据点的特性，这种情况称为欠拟合。</p>

<p>图3-32b中使用了一个复杂得多的模型，比如可以是一个包含很多高次项的多项式，或 者是一个隐藏层单元很多的双层神经网络。这样的模型有了非常强的表达/拟合能力，所有的 红色圆点都被很好地拟合。不过从图3-32中来看，拟合得有些过分好了，因为数据点是有明 显的中间高的趋势，同时也有噪声附加在这个趋势上。而图3-32b中的曲线连噪声一起学习到 了，虽然训练数据误差接近于0,但是对于没见过的蓝色三角形数据点，就完全不靠谱了。这 种情况相当于“记住”每个训练数据的位置，而丧失了对新数据的泛化能力，称为过拟合。</p>

<p>图3-32中用一个比线性模型复杂，又不会表达能力过分的模型，可以是一个二次函数， 也可以是一个比3-32b模型简单得多的神经网络。总之是一个恰到好处的模型，成功学习 到了数据的趋势。这种才是我们想要的情况，也就是能够成功泛化的模型。</p>

<p>模型的拟合能力通常被称为capacity, 一般情况下，如果欠拟合解决办法是通过增加 模型复杂度来增强拟合能力，比如对于神经网络，增加层数或者神经元数量。而过拟合则 不是那么轻易解决的事情，需要在模型复杂度和训练精度之间寻找一个平衡。如果欠拟合 解决办法是增加模型的复杂度以达到更强的学习能力，比如对于神经^网络，增加层数或者 神经元数量。而过拟合则不是能那么轻易解决的事情，因为一般来说减小误差的趋势往往 是通过更复杂的模型实现的，这个趋势容易导致过拟合，需要在模型复杂度和训练精度之 间寻找一个平衡。</p>

<p>3.5.2训练误差和测试误差</p>

<p>前面也提到了数据通常分为两部分，一部分是训练数据，用来让模型做后向传播学习 参数，模型在训练数据上预测值和数据值的误差衡量被称为训练误差(training error)或者 经验误差(empirical error)；另一部分是测试数据，相应的误差衡量被称为测试误差(test error)或者泛化误差(generalization error)。一般来说训练误差是否变小代表着学习的过</p>

<p>程是否收敛，而测试误差是否足够小则和模型对于未见过的样本预测能力的好坏直接相关, 通常来说，测试误差总是大于训练误差，不过这两者随着模型能力的变化趋势并不相同。 想象一下如果可以看到两种误差随着能</p>

<p>力的变化趋势的话，当模型的能力不够 时，训练误差和测试误差都会随着模型能 力的增加而降低，这对应着欠拟合。当模 型的能力恰到好处的时候，测试误差达到 最小。随着模型能力的继续增加，模型开 始在能够学习训练数据分布的基础上，进 而开始学习到每一个训练数据，这就是过 拟合，所以测试误差会越变越大。这个趋 势如图3-33所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-167.jpg" alt="img" /></p>

<p>需要说明的是，这个趋势曲线中的测试误差和训练误差的差异(generalization gap)随 着模型能力的增长是不断变大的。当模型能力超过了最佳的点时，这个差异的增长速度就 会超过训练误差的下降速度，这就是为什么测试误差会越来越大。</p>

<p>通常来说我们会更希望测试误差和训练误差的差异更小，因为这代表着更好的泛化能 力。由于数据都是来源于某种分布，如果从抽样的观点来看待训练数据，根据最基本的统 计知识，数据量越大，抽样误差越小。也就是说随着数据的增加模型对真实分布描述的误 差就越小，泛化性能就会越好。不过就算数据量可以无限增加，也不能完全解决误差的问 题，因为在数据中还隐含了一个假设，就是我们讨论的都是带有随机性的数据。这些随机 性有可能是误差，有可能是一些难以观测到的变量。为了更好理解数据量和误差的关系， 下面来看个例子，如图3-34所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-168.jpg" alt="img" /></p>

<p>图3-34完美模型的误差随数据量的变化</p>

<p>图3-34a是当数据不多的时候，我们得到了一个如实线所示的最优模型，中间的黑色 虚线代表真实数据下能得到的最优模型。按照前面的论述，数据量少的时候，对真实分布 的描述可能会有较大误差，所以中间的实线和虚线完全没有重合。</p>

<p>自然而然地，我们希望有更多的数据，比如图3-34b所示的情况，最优模型的泛化能 力就会好一些，但＞训练数据的增加对模型的能力提出了更高的要求。•般来说，这个时 候的最优模型会比数据少的时候复杂一些，但是在训练数据上的误差会上升，而对真实数 据的误差会下降，并且下降程度会超过训练误差的上升程度，也就是说前面提到的训练误 差和测试误差的差异缩小了。可以看到中间的实线和虚线的差异变小了。</p>

<p>再来考虑最极端的情况，假设我们能够获取任意多的数据，或者说多到对真实分布的 描述误差可以忽略，如图3-34c所示。这种情况下，可以认为得到了完美的模型，训练误 差和测试误差的差异就可以忽略了，它们都会趋向同一个值，称做贝叶斯误差(Bayes error) o</p>

<p>^TIPS:非参数模型</p>

<p>因为本书主题是深度学习，所以截止到这里只讲了参数模型，也就是神经网络。 参数模型可以理解为参数数量给定的模型。比如神经网络，定好了结构的话，参 数数量是确定不变的，学习过程只要根据训练数据和损失函数优化参数的值就可 以了。因为参数和形式的确定，所以给定一个参数模型，模型的能力也是确定的。 非参模型则是和训练数据更紧密相关，参数数量会随着数据的不同而变化，最简 单的例子比如各种插值法，还有SVM和高斯过程等。非参数模型相对于模型能 力的控制更容易一些，比如SVM，核函数半径如果很短，则能够获得很强的分 类能力，训练误差可以很低，甚至每一个样本都成为支持向量，从而过拟合；而 长一些的核函数半径则能降低过拟合的风险。不过非参数模型大都是基于前面提</p>

<p>到的局部泛化的思想，而神经网络则是希望能从数据中学习到特征 (representation)。</p>

<p>3.5.3奥卡姆剃刀没有免费午餐</p>

<p>奥卡姆剃刀(Occam&rsquo;s razor)和没有免费午餐(No Free Lunch Theorems, NFL)是两 个不同的理论，放在一节是因为这两个理论都有些哲学和逻辑的意思，并且名字都有些怪。</p>

<p>先来说说奥卡姆剃刀。14世纪的时候，有个哲学家William of Ockham,他在自己写的 -本讲道理的书里阐述了一■个观点：Non sunt multiplicanda entia sine necessitate。翻译过来 就是“如无必要，勿增实体。”这句听上去很有道理的观点在400年后被苏格兰的玄学和 哲学家William Hamilton爵士正式命名为Occam’s razor。无论从原话还是名字来看，都透 着一种简单至上的思想。具体到机器学习中，这个哲学观点代表的意思是：在所有能够很 好解释训练数据的模型中，选择最简单的那个。那么怎样才能算是很好解释训练数据呢？ 理想情况就是图3-33中虚线右边的部分，最简单的那个就是虚线对应的那一点，通常就是 一个最优(optimal capacity)的模型。在很多传统机器学习算法中，奥卡姆剃刀并不是一 句大道理，而是有统计学习理论的支撑。不过在神经网络，尤其是具体到深度学习中的理 论支撑并不明确，本书也并不涉及这部分内容，有兴趣的读者可以自背研究学习。</p>

<p>接下来再谈谈什么是没有免费的午餐。前面两节已经反复说过，&amp;器学习根本来说就 是从已有数据中学习，然后泛化到未见过的数据。特别地，对于分类问题，就是通过学习 已经带有标签的数据，来预测未见过的数据的类别。前面还提到数据的同分布假设非常重 要，因为同分布才是泛化的前提，那么是否可以有算法从各种所有可能出现的分布中都进 行学习，并且有效泛化呢？答案是否定的，美国数学和计算机科学家David Wolpert和 William Macready在20世紀末指出并证明：如果考虑所有可能的数据分布，不管什么算法， 分类误差的期望值都是一样的。也就是说天上不会掉下一个像免费午餐一样的算法，比其 他算法都好，考虑所有可能的分布的话，什么算法水平都-•样，甚至是一个随机的分类算 法。定性来理解如图3-35所示。</p>

<p>图3-35没有对任何分布都有效的分类算法(NFL)</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-171.jpg" alt="img" /></p>

<p>图3-35中黑色实线是分类边界，a、b和c图对应3种不同分类器和各自分类效果最好 时的样本例子，图3-35a里分类效果好的线性分类边界，到了 b和c图中则不灵。同样道 理看似过拟合的图3-35c中的分类器，其实对图3-35c的分布有很好的效果，但在a和b 图中则并不好。所以全局来说并不存在某种算法比另一种算法更好，只有针对特定问题， 特定的数据分布时，找到一个好的算法才有意义。</p>

<p>其实上面说了这么多就两件事：泛化很重要；数据很重要。</p>

<p>3.5.4数据集划分和提前停止</p>

<p>通过前面3节的讨论，我们知道数据主要分为训练数据和测试数据。在实际的训练中， 还会使用到一个数据集，叫做验证集。验证集通常被用在训练过程中，但并不作为用于更 新网络权重的训练数据的一部分。主要作用是在训练过程中评估模型的准确度和损失函数 值，作为一个指标选择模型的超参数，比如网络层数、隐藏单元数量，或是激活函数的类 型等。同时验证集也用来观察训练是否已经过拟合，因为验证集并不作为更新网络权重的 数据，所以能体现出网络的泛化能力。在神经网络中，随着训练的进行，在训练集和验证 集上的损失函数值常呈现如图3-36所示的趋势。</p>

<p>图3-36和图3-33的趋势非常相似，只不过 ，</p>

<p>3-36训练过程中损失函数在验证集和 训练集上的趋势</p>

<p>横坐标换成了迭代次数。定性理解这个趋势，在</p>

<p>训练的开始阶段，模型什么都尚未学到，所以无</p>

<p>论是训练集还是验证集误差都很高。随着训练的|</p>

<p>不断迭代，在训练集上的误差会越来越小，这是f 数</p>

<p>学习到数据特征的阶段，模型仍然欠拟合，所以i 在训练过程中，训练集和验证集上的误差都下降 了。然后就是过拟合阶段，训练集的误差不断下 降，但是泛化能力则变差，于是验证集上的误差 p 变高了。所以当验证集上值最小时，就是参数最 优的时候。 7</p>

<p>一个非常简单fcj策略是每当验证集上的损失函数值达到一个比之前更小的值，就把这 个值记录下来作为最小值，然后继续训练，直到在发现某i个最小值之后一个给定的迭代 次数内，如果没有发现新的更小的值，则认为已经过拟合了。于是之前验证集上最小值对 应的模型就是最优的模型，这个简单粗暴的策略叫做提前停止(early-stopping)。提前停 止虽然简单，但是有个潜在的风险就是用来判断是否已经过拟合的次数并不容易确定。这 个次数无论是个常数还是一个比例，如果太长，会浪费计算资源，如果太短，则有可能在 验证集误差还有可能继续下降(比如鞍点或者缓慢离开极小值时)的时候就提前结束。</p>

<p>虽然验证集只是在训练中使用，但是和测试集有个共性就是都不参加到参数的梯度下 降训练中。如表3-1总结了这3种数据集的特点。</p>

<p>表3-1训练集、验证集和测试集</p>

<table>
<thead>
<tr>
<th>作    用</th>
<th>训练集</th>
<th>验证集</th>
<th>测试集</th>
</tr>
</thead>

<tbody>
<tr>
<td>训练模型</td>
<td>调节超参数 避免过拟合</td>
<td>评估模型性能</td>
<td></td>
</tr>

<tr>
<td>使用阶段</td>
<td>训练</td>
<td>训练，一定间隔</td>
<td>测试</td>
</tr>

<tr>
<td>梯度下降中使用</td>
<td>是</td>
<td>否</td>
<td>否</td>
</tr>

<tr>
<td>模型性能参考</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
</tbody>
</table>

<p>当然，如果数据非常匮乏的情况下，有个策略是将验证集和测试集合二为一，则比没 有强。</p>

<p>3.5.5病态问题和约束</p>

<p>通过改变模型的拟合能力来避免过拟合并不是一件容易的事情，更常用的办法是使用 规范化对模型的参数进行一定的约束。下面来考虑一个非常简单的例子，求下面方程的解:</p>

<p>2x-y+2=0</p>

<p>这是一个二元一次方程，有无数个解，都在如图3-37a所示的这条直线上。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-173.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-174.jpg" alt="img" /></p>

<p>图3-37病态方程求解和规范化    (</p>

<p>这是一个典型的病态(ill-posed)方程，有无数个解可以满足方程，可以通过x和y 带入等式左边求出0,但是通过等式来推导;v和y的值却是不可行的。病态方程除了有不 可逆的性质，在数值计算上也不受欢迎。比如取x=109, y=2xl09+2,那么如果％和^的系 数发生了很小的变化，则这个变化会被放大很多到等式的右边，在数值计算中，这常常是 不稳定的。</p>

<p>针对病态方程，一个常见的办法是加入一个约束项，缩小*和y的取值范围，比如令 x2+/=0.8,如图3-37b所示，则相当于约束x和^在半径为2/人圆上，于是相切点(-0.8,0.4) 成了一个稳定的解。此外还可以令约束为|x|+[y|=l，则交点也只有一个，就是(-1,0),也是 一个稳定的唯一解。</p>

<p>3.5.6 L2 规范化(L2 Regularization)</p>

<p>虽然上面讨论的是一个非常简单的解方程的例子，但是和机器学习的问题有许多相似 性。基于参数的机器学习模型某种程度上就是一个不可逆的问题，对于同一个损失函数值， 可以对应很多种不同的参数。甚至在高维度下，极小值和最小值都很接近，所以即使是很 好优化过的模型，也会对应许多不同的参数组合，而这些组合未必是数值稳定的。而且因 为参数的范围更自由，可以得到很小的训练误差，往往都不具有很好的泛化性能。这时候 也可考虑加入一个约束项，这种方法叫做规范化(regularization)。具体来说就是在损失 函数里加上一项，最常用的一种是L2规范化：</p>

<p>£(<9) = £(6>) + ^^2    (公式 3-13)</p>

<p>i</p>

<p>其实就是L2范数，也就是欧氏距离的平方乘上一个系数。在神经网络中，L2规范化 通常只应用于仿射变换中的线性变换部分，也就是IVX+6的IV。根据公式形式，这样一项 加上之后，权重的绝对值大小就会整体倾向于减小，尤其是不会出现特别大的值。所以L2 规范化还有个名字叫做权重衰减(weight decay),也有一种理解这种衰减是对权值的一种 惩罚，所以有时候会看到文章或者书里管这一项叫做惩罚(penalty)项。</p>

<p>下面通过一个简单的例子来形象理解一下L2规范化的作用。考虑一个只有两个参数 ^和^的模型，其损失函数曲面如图3-38所示。</p>

<p>图3-38 L2规范化对目标函数曲面的影响</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-176.jpg" alt="img" /></p>

<p>a)    b)</p>

<p>图3-38a是一个目标函数，可以看到，最小值所在是一条线，整个曲面像一条山岭倒 过来一样。这样的曲面对应无数个参数组合，单纯用梯度下降法是难以得到确定解的，可 以看作是一个典型的病态问题。但是加上一项0.1x(Wl2+w22)，贝lj曲面变成了如图3-38b所 示的样子。最小值所在从倒过来的“岭”变成了一个“谷”。需要注意的是“谷”所在的 位置并不是规范@的中心(0,0)，而是根据规范化系数的大小和原来损失函数曲面共同决定。 当规范化系数a—-时，原来的损失函数可以忽略，则“谷”的位置趋近于(0,0);当a-0 时，“谷”的位置趋近于原损失函数曲面中“岭”所在的位置。总之加入这一项之后，梯 度下降法就能够解决了。并且通过这个例子可以看出，L2规范项还起到了帮助收敛的作用。 统计学里这个方法常用来处理多重共线性下的最小二乘法问题，并且有个形象的名字叫做 岭回归(ridge regression) o</p>

<p>3.5.7 L1 规范化(L1 Regularization)</p>

<p>除了 L2规范化，L1规范化也是最常见的规范化方法之一，形式如下：</p>

<p>L(0) = L(0) + a^\0i\    (公式 3-14)</p>

<p>i</p>

<p>其实在图3-37c所示的例子中已经见过，和L2的区别主要是L2项的等高线不同，二 维情况的等高线画在了图3-37c中，是个旋转45°的正方形。这个性质让L1规范化后的 参数更趋向于某些维度为0,也就是稀疏性。关于这个性质的形象理解还是来看个经典的 二维情况下的例子，如图3-39所示。</p>

<p>图3-39中虚线代表的是原损失函数的等高线，实现代表的是规范化项的等高线，左边 a图是L2的情况，右边b图是L1的情况。当整体函数达到最小值的时候，如a图中红点 所示的位置。所以能够很清楚地看出，L2项让整体参数都有变小的趋势。而L1则会让</p>

<p>参数的方向朝着某个轴靠近，比如图3-39b中，因为原始损失函数等高线的形状，无论L1 项的系数怎么变，最终最小值一定是在横轴上。这样的约束可以让有效特征的数量变少， 从而获得稀疏性。因为这个性质，L1规范化经常被用在降噪和图像重建中。在统计学里</p>

<p>L1 规范化也有另外一个名字叫 LASSO，即 Least Absolute Shrinkage and Selection Operator,</p>

<p>是对LI规范化的一个简短概括。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-177.jpg" alt="img" /></p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-178.jpg" alt="img" /></p>

<p>图3-39 L2规范化和L1规范化的区别</p>

<p>3.5.8 集成(Ensemble)和随机失活(Dropout)</p>

<p>3.5.7节介绍的是最常见的两种规范化方法，其实广义来说，任何尝试减小算法泛化误 差的改动方法都可以叫规范化，本节介绍的两个方法就是两种比较有代表性的。</p>

<p>首先通过一个例子来了解集成(ensemble)的基本概念，考虑一个平面上的二分类问 题，如图3-40所示。</p>

<p>图3-40集成(ensemble)的示意例子</p>

<p>图3-40中的数据均是测试数据，a、b和c图分别是3个不同模型在测试数据上的分类 结果。需要注意的是，一般在做集成的时候，相同模型结构的3组不同参数是比较常见的 情况。但是并不限定于此，也就是说集成的模型可以是不同的模型结构甚至完全不同的算 法。每个模型错误分类的样本都用圆圈标了出来，可以看到每个模型大体都是准确的，但 是a、b和c图中都会有分类错误的情况发生。定性来看因为每个模型是不同的，所以错误 的情况通常也不一样，所以大部分的情况还是正确分类的。基于这个思路，可以考虑综合 考虑3个不同模型的结果，因为错误分类毕竟是少数，所以最终结果的可靠性就会好很多。 所以把这3个模型的结果综合考虑，如图3-40d所示，图3-40d的左图中画出了 3个模型 的分类边界，对结果我们采取多数投票(majority vote),也就是3个模型分类结果中多数 的结果作为最终结果，如图3-40d右图所示，结果就很好了。除了多数投票，在实际应用 中常见的办法还有取均值或者中值，总之基本思想都是一样。俗话说得好“三个臭皮匠， 赛过诸葛亮”。</p>

<p>集成法是通过多个模型的结果综合考虑给出最终的结果，虽然准确率和稳定性都会提 高，但是训练多个模型的计算成本也是非常高的，如果训练10个左右的模型，则计算成本 高了一个量级。所以集成法通常在ILSVRC和Kaggle这样的竞赛中更常见，实际应用中使 用更多的则是一个和集成法类似但又不尽相同的方法，在第1章也提到过，Alex Krizhevsky 在ILSVRC 2012中就用到过这种方法：随机失活法(dropout)。</p>

<p>Dropout的底层思想其实也是把多个模型的结果放到一起，只不过实现方式是在一个 模型的内部，而不是真正去训练多个模型。Dropout的示意如图3-41所示。</p>

<p><img src="file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-180.jpg" alt="img" /></p>

<p>图3-41随机失活(dropout)示意</p>

<p>图3-41中左边展示的是一个非常简单的神经网络结构。我们选取隐藏层，在每次的梯 度迭代中，让隐藏层的每个单元以一定的概率不被激活。比如图3-41右边的图，是0.5 为失活概率情况下的一个例子，&amp;和//3不被激活时，实际上相当于一个包含两个隐层单元 的新网络。在该次梯度迭代结束后，下次迭代中再继续这个过程。通常在应用中，如果w 个隐藏单元的网络对于问题是最优的，则实际训练用的网络中单元数〃应该是的取 整。注意到在这个过程中存在一个问题，对包含《个单元的一层以失活概率进行dropout 的时候，有/的概率全部单元都没有激活，这样一来输入输出之间的通路就断了。比如 图3-41的例子中，有1/16的概率会没有通路。不过好在实际应用中，A7通常都很大，所以 这个概率会非常非常小，不会形成实际困难。</p>

<p>定性来理解一下，dropout实现的相当于每次迭代都在一个随机挑选特征的子空间进 行。举个不严谨的例子，比如想判断一个动物是不是猫，第一次迭代的时候通过重量、毛 色和体型；第二次迭代通过重量、眼睛形状和奔跑速度；第三次迭代通过体型、尾巴长度、 叫声和食物类型……当然区别在于神经网络中的特征都是学出来的。这样做的好处不仅实 现了集成的思想，还把每个特征之间的关联性降低，增强了泛化能力。</p>

<p>在实现dropout的时候，因为训练时候对单元按照一定概率随机置零，所以训练结束</p>

<p>后到了预测阶段需要对参数的值乘上1卞，才能保证结果正确。这个步骤也可以在训练时 对输入除以1-P来等效实现。也有人在预测阶段使用dropout,方法很直接，就是打开 dropout,运行n次网络，得到〃个不同的结果，然后像集成法一样，选取一个最终结果。 Dropout虽然避免了训练多个模型，可并不意味着训练时和单独训练一个模型一样快，通 常还是要慢一些。另外什么样的失活概率p是最好的，通常也是个经验值。</p>

<p>3.6监督学习、非监督学习、半监督学习和强化学习</p>

<p>机器学习中通常根据数据是否有标签可以分为监督学习(supervised learning)、非监 督学习(unsupervised learning)和半监督学习(semi-supervised learning)。如果需要算法 与环境交互获得数据则是强化学习(reinforcement learning)。本书中针对的计算机视觉应 用将以监督学习为主，不过本节还是来简单全面地了解一下这3种类型的机器学习。</p>

<p>3.6.1 监督学习、非监督学习和半监督学习</p>

<p>截至目前本书中讲过的大部分内容都是监督学习。监督学习的意就是用来训练网络 的数据，我们已经知道其对应的输出，这个输出可以是一个类别标签/也可以是一个或者 多个值。模型经过训练后，遇到新来的数据，可以预测对应的标签或者值。监督学习是最 常见的应用，已知标签的分类和回归问题都属于监督学习。非监督学习则是并不知道数据 的标签，而是根据数据本身的特性，从数据中根据某种度量学习出一些特性。比如想象一 个人从来没见过猫和狗，如果给他看了大量的猫和狗，虽然他还是没有猫和狗的概念，但 是他是能够观察出每个物种的共性和两个物种间的区别的，并对这两种动物予以区分。举 个简单的例子理解一下，如图3-42所示。</p>

<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>

<p>a)    b)</p>

<p>图3-42监督学习和无监督学习示意</p>

<p>图3-42a是监督学习的样本，可以看到样本根据类别不同而表示成不同的形状，算法 学习的时候根据标签对空间区域进行划分。图3-42b是没有标签的样本，虽然没有标签但 是也能很明显看出有3个集中的“簇”，每个“簇”中的样本互相靠得更近一些。这种情 况下对样本的划分通常被称为聚类(clustering),常见的方法有k-means,混合高斯模型</p>

<p>(GMM, Gaussian Mixture Model)等。广义来说，只要是无须人工标注就能从数据中提 取出特征，都算是无监督学习。从这个角度，第2章提到过的PCA也可以算在无监督学习 的范畴里。无监督学习通常被认为能够更好地从数据本身分布中挖掘出特征，并且对于数 量不是很大的数据集还能防止过拟合。第1章提到过的2006年Hinton的深度学习开山级 文章《A Fast Learning Algorithm for Deep Belief Nets》里，就是用无监督学习对每一层进行 预训练，然后再用监督学习进行训练。</p>

<p>监督学习和非监督学习都是比较极致的情况，要么数据都有标签，要么一个标签都没 有。在实际应用中，还有比较常见的情况是部分数据有标签，部分没有，把这两种数据都 利用起来称为半监督学习(semi-supervised learning)。</p>

<p>在大数据的趋势下，还有一个越来越流行的概念叫做弱监督学习(weakly supervised learning),是指用弱一些的标注来帮助训练一个更强条件下的算法。比如图片分类，有标 注的数据虽然好，但是耗费人力去标注，获取成本高。但是没有标注的数据，或是一些不 严格标注的数据，比如用户传图片时贴的标签，相对获取成本就低很多。后者就是一种弱 监督的数据，可能包含噪声，多重标注，或是信息缺失等问题。但使用得当的话，结合前 者能带来更大的数据量和更好的泛化。</p>

<p>3.6.2 强化学习(reinforcement learning)</p>

<p>(深度)强化学习在机器学习中是一个比较另类的分支，随着AlphaGo战胜李世石， 强化学习开始跃入大众视野并一下子吸引了很多人的兴趣。强化学习的思想借鉴了很多动 物和环境交互学习的行为。强化学习中算法本身有一个状态(state),算法借助一个代理</p>

<p>(agent)和环境^environment)交互，交互的结果以奖惩(reward)的形式返回并作用于 算法本身，如图343所示。</p>

<p>图3-43强化学习示意图</p>

<p>代理通过当前的状态产生一个行动，这个行为和环境交互后会让代理处于一个新的状 态，并且同时反馈给代理一个奖惩的分数。这个分数相当于对行为的一种评价，和我们为 算法设置的目的有关。如果定义好的行为得到正分数，不好的行为得到负分，则反馈作用 于算法改进后，在通过代理产生下一个可能让奖惩分数提高的行为。这个过程一直持续， 算法就会在这个不断试探的过程中越变越好。举个例子，比如用强化学习训练一辆小车不 会撞墙或者障碍物，小车就是代理，小车所在的有障碍物的房间的地面就是环境。小车的 状态就是当前的位置，以及当前位置能获得的信息，比如传感器得到的距离信息，或者摄 像头看到的画面。根据当前状态和算法策略，每次小车做出任何一个方向前进的行为后， 如果没有撞墙，则得到一个小的奖励分数，如果撞到了墙，则得到一个较大的惩罚负分。 这样就实现了学习的过程。</p>

<p>因为强化学习的行为都会对应一个奖惩，所以常常有人拿强化学习和监督学习进行比 较。的确强化学习的这种特性在某种程度上相当于从环境中获得了对数据的标注，但这两 种类型的算法还是有很大不同的。首先强化学习的目标和监督学习不一样，强化学习看重 的是行为序列下的长期收益，而监督学习往往关注的是和标签或已知输出的误差。强化学 习的奖惩概念是没有正确或错误之分的，而监督学习标签就是正确的。强化学习是一个学 习+决策的过程，并且有和环境交互的能力，这都是监督学习不具备的。</p>

<p>目前强化学习主要用于机器人、游戏等和环境交互比较多的领域。除了第1章提到的 DeepMind,现在专注强化学习的技术重镇还有号称“钢铁侠原型”的Elon Musk创立的 OpenAI,加州大学伯克利分校等。</p>

<h2 id="相关资料">相关资料</h2>

<ul>
<li>《深度学习与计算机视觉》</li>
</ul>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/03-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/01-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B/01-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/01-c&#43;&#43;/c&#43;&#43;-%E9%A2%98%E7%9B%AE/01-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E9%97%AE%E9%A2%98/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">01 基本概念问题</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/11-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89-cv/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/02-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%92%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E4%B8%AD%E7%9A%84%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/01-%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E5%92%8C%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2/">
            <span class="next-text nav-default">01 线性变换和非线性变换</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
