<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>11 基于 MXNet 实现 LeNet-5 网络 - 迭代自己</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="iterateself" />
  <meta name="description" content="需要补充的 这个还没有进行整理。要进行整理。 8.3基于MXNet的实现 本节基于和8.2节一样的网络结构和数据源，在MXNet上实现手写数字识别" />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.47.1" />


<link rel="canonical" href="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89cv/11-%E9%9D%99%E6%80%81%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F/01-%E7%89%A9%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%8E%E6%A3%80%E6%B5%8B/10-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/11-%E5%9F%BA%E4%BA%8E-mxnet-%E5%AE%9E%E7%8E%B0-lenet-5-%E7%BD%91%E7%BB%9C/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">




<meta property="og:title" content="11 基于 MXNet 实现 LeNet-5 网络" />
<meta property="og:description" content="需要补充的 这个还没有进行整理。要进行整理。 8.3基于MXNet的实现 本节基于和8.2节一样的网络结构和数据源，在MXNet上实现手写数字识别" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://iterate.site/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89cv/11-%E9%9D%99%E6%80%81%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F/01-%E7%89%A9%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%8E%E6%A3%80%E6%B5%8B/10-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/11-%E5%9F%BA%E4%BA%8E-mxnet-%E5%AE%9E%E7%8E%B0-lenet-5-%E7%BD%91%E7%BB%9C/" /><meta property="article:published_time" content="2018-09-01T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-09-01T00:00:00&#43;00:00"/>
<meta itemprop="name" content="11 基于 MXNet 实现 LeNet-5 网络">
<meta itemprop="description" content="需要补充的 这个还没有进行整理。要进行整理。 8.3基于MXNet的实现 本节基于和8.2节一样的网络结构和数据源，在MXNet上实现手写数字识别">


<meta itemprop="datePublished" content="2018-09-01T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-09-01T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="3374">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="11 基于 MXNet 实现 LeNet-5 网络"/>
<meta name="twitter:description" content="需要补充的 这个还没有进行整理。要进行整理。 8.3基于MXNet的实现 本节基于和8.2节一样的网络结构和数据源，在MXNet上实现手写数字识别"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">迭代自己</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">主页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a><a href="/catalog/">
        <li class="mobile-menu-item">完整目录</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">迭代自己</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">主页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/catalog/">完整目录</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">11 基于 MXNet 实现 LeNet-5 网络</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-09-01 </span>
        
        <span class="more-meta"> 3374 words </span>
        <span class="more-meta"> 7 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#需要补充的">需要补充的</a>
<ul>
<li><a href="#相关资料">相关资料</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>

    
    

    
    <div class="post-content">
      

<h1 id="需要补充的">需要补充的</h1>

<ul>
<li>这个还没有进行整理。要进行整理。</li>
</ul>

<p>8.3基于MXNet的实现</p>

<p>本节基于和8.2节一样的网络结构和数据源，在MXNet上实现手写数字识别，进而了 解用MXNet进行图片分类任务的基本步骤。</p>

<p>8.3.1 制作 Image Record io 数据</p>

<p>和Caffe中用LMDB保存大量数据相对应，MXNet中对于大量数据10的实现采用的 是Image Recordio,这是DMLC自己研发的一种高效且易于分布式访问的数据存储方式， 和LMDB —样也是基于内存映射(Memory Map)。因为在硬盘上的存储编码可以是JPG 等压缩格式，所以空间占用上和Caffe中用LMDB类存储cv::Mat的方式比起来优势很大， 并且转换时的速度也不慢，这一点又胜过Caffe中直接读取图片的ImageDataLayer。和Caffe 类似，要制作这种格式，第一步也是要制作一个文件路径和标签的列表，格式如下：</p>

<p>0    5    mnist/train/000000_5.jpg</p>

<p>1    0    mnist/train/000001_0.jpg</p>

<p>2    4    mnist/train/000002_4.jpg</p>

<p>3    1    mnist/train/000003_l.jpg</p>

<p>每一行都是用制表符分隔开的3个字段，第一个字段是一个整数编号，第二个字段是 标签，第三个字段是文件名或者文件路径。注意虽然例子中的编号是按顺序的，其实不重 要。从产生的MNIST图片生成列表的代码如下：</p>

<p>import os</p>

<p>import sys</p>

<p>#第一个参数是输入路径</p>

<p>input_path = sys.argv[l].rstrip(os.sep)</p>

<p>#第£个参数是输出路径’ output_path = sys.argv[2]</p>

<p>#列出Sj入文件夹下所有文件名 filenames = os . listdir(input_path) with open (output_path, * w&rsquo;) as f:</p>

<p>for i, filename in enumerate(filenames):</p>

<p>filepath = os.sep.j oin([input<em>pathz filename]) label = filename[:filename.rfind(<em>.</em>)].split(*</em>*)[1]</p>

<p>#格式化为序号\t标签\t文件路径</p>

<p>line =    ’{}\t{}\t{}\n*.format(i, label, filepath)</p>

<p>f.write(line)</p>

<p>把这段代码保存为gen mxnet imglist.py,然后依次执行下面命令：</p>

<p>» python gen_mxnet_imglist.py mnist/train train.1st</p>

<p>&gt;&gt; python gen_mxnet_imglist.py mnist/val val.lst</p>

<p>» python gen_mxnet_imglist.py mnist/test test.1st</p>

<p>接下来第二步就可以利用MXNet的官方工具mxnet/bin/im2rec进行数据转换了，执行 下面命令：</p>

<p>» /path/to/mxnet/bin/im2rec train.1st . / train.rec color=0</p>

<p>» /path/to/mxnet/bin/im2rec val.lst . / val.rec color=0</p>

<p>» /path/to/mxnet/bin/im2rec test.1st . / test.rec color=0</p>

<p>需要提一下的是，列表文件中，第二个字段可以是多个标签的，如果是这种情况，就 需要在执行im2rec时指定label_width参数为标签的个数。更多参数的含义可以参考 <a href="http://mxnet/">http://mxnet</a>. io/zh/api/python/io. html。</p>

<p>截止作者完稿时，在最新正在开发的0.9版的MXNet中推出了 image模块，提供了 Python实现的更灵活的接口 Imagelter,有兴趣的读者可以到MXNet的github主页进行</p>

<p>了解。</p>

<p>8.3.2 用 Module 模块训练 LeNet-5</p>

<p>第7章中已经大概了解了 MXNet中接口最简单的Model模块的使角，本节将进一步 了解更灵活的Module模块。按照Caffe中LeNet-5版本的结构，定义网络并用Module模 块封装的代码如下：</p>

<p>import mxnet as mx</p>

<p>#定义数据Symbol</p>

<p>data = mx.symbol.Variable(* data1)</p>

<p>#第一层卷积和池化</p>

<p>convl = mx.symbol.Convolution(data=dataz kernel=(5, 5), num_filter=20) pooll = mx.symbol.Pooling(data=convl, pool_type=&ldquo;max&rdquo;,</p>

<p>kernel=(2,    2), stride=(2, 2))</p>

<p>#第二层卷积和池化</p>

<p>conv2 = mx.symbol.Convolution(data=pooll, kernel=(5, 5), num_filter=50) pool2 = mx.symbol.Pooling(data=convl, pool_type=&ldquo;max&rdquo;,</p>

<p>kernel=(2, 2), stride=(2,    2))</p>

<p>#第一层全连接，输入到全连接前先将二维数据展开</p>

<p>flatten = mx.symbol.Flatten(data=pool2)</p>

<p>fcl = mx.symbol.FullyConnected(data=flatten, num_hidden=500) relul = mx.symbol.Activation(data=fcl, act_type=&ldquo;relu&rdquo;)</p>

<p>#第二层全连接</p>

<p>f c2 = mx.symbol.FullyConnected(data=relul, num_hidden=l0)</p>

<p># Softmax+loss</p>

<p>lenet5 = mx.symbol.SoftmaxOutput(data=fc2, name=1softmax *)</p>

<p>#用Module封装，这次使用GPU来进行训练</p>

<p>mod = mx.mod.Module(lenet5, context=mx.gpu(0))</p>

<p>有了模型，接下来定义数据。在MXNet中，数据迭代器比Caffe的Data Layer强大不 少，提供了更丰富的数据扰动方式，这里用随机裁剪和随机旋转。需要注意的是，MXNet 内置的随机裁剪是正方形裁剪，随机旋转是原大小旋转，也就是说会出现没有图像的区域， 我们用黑色进行了填充，相应代码如下：</p>

<p>train_dataiter = mx.io.ImageRecordlter(</p>

<p>~ #训练数据源</p>

<p>path_imgrec=&ldquo;../data/train.rec”，</p>

<p>#数维度</p>

<p>data_shape=(1,    28,    28),</p>

<p>#批_的样本数量</p>

<p>batch_size=50,</p>

<p>#减i均值，因为是单通道，所以定义红色通道均值即可 mean_r=128,</p>

<p>#减均值后归一化到［0.5,    0.5)之间</p>

<p>scale=0.00390625,</p>

<p>#数据增加-随机裁剪</p>

<p>rand_crop=True,</p>

<p>#裁 &amp;的最小边长</p>

<p>min_crop_size=24,</p>

<p>#暴剪的*大边长</p>

<p>max_crop_size=28,</p>

<p># i据增沅-随机旋转，范围为-15°〜15°之间 max_rotate_angle=15z</p>

<p>林i转后的圣白部分值填充为◦，也就是黑色 fill_value=0</p>

<p>)</p>

<p>val_dataiter = mx.io.ImageRecordlter( path_imgrec=&ldquo;../data/val.rec&rdquo;, data_shape=(1,    28,    28),</p>

<p>batch_size=100,</p>

<p>mean_r=128, scale=0.00390625,</p>

<p>)</p>

<p>模型和数据两大要素已备齐，下面可以开始训练模型了。</p>

<p>import logging</p>

<p>#把log输出至G文件</p>

<p>logging.getLogger().setLevel(logging.DEBUG)</p>

<p>fh = logging.FileHandler(* train_mnist_lenet.log *)</p>

<p>logging.getLogger().addHandler(fh)</p>

<p>#用来随着训练进程改变学习率</p>

<p>#    MXNet默认的学习率策略较少，这里用FactorSecheduler，</p>

<p>#相当于Caf fe中lr_policy的step，如果希望实现其他类型</p>

<p>#需要自己到lr_scheduler. py中添加代码</p>

<p>*wd&rsquo;:    0.0005,</p>

<p>1lr_scheduler1: lr_scheduler</p>

<p>}</p>

<p>#    checkpoint是个回调函数，用来保存模型，period是每多少个epoch保存一次 checkpoint = mx.callback.do_checkpoint(&lsquo;mnist_lenet&rsquo;, period=5)</p>

<p>#和8.31中例子保持一致训练到3.6万次，也就是36个epoch</p>

<p>mod.fit(train_dataiter,</p>

<p>eval_data=val_dataiter, optirnizer_params=optimizer_params, num_epoch=3 6,</p>

<p>epoch_end_callback=checkpoint)</p>

<p>把上面所有代码合在一起，保存在train_lenet5.py中，然后执行：</p>

<p>» python train_lenet5.py</p>

<p>这样就开始训练了，训练完毕会输出一个mnist_lenet-symbol.json文件，这个是模型结 构的描述文件，按照设定，每迭代5代保存一次的模型参数存档，命名形式为mnist_lenet-[i)l| 练的代数].pamms。当然还有输出的log,例子如下，主要包含训练的精度、验证集的精度、 学习率的变化和保存模型的信息。</p>

<p>Epoch[0] Train-accuracy=O.710640</p>

<p>Epoch[0] Time cost=3.347</p>

<p>Epoch[0] Validation-accuracy=0.955000</p>

<p>Update[1001]: Change learning rate to 9.50000e-03</p>

<p>Epoch[1] Train-accuracy=0.925640</p>

<p>Epoch[1] Time cost=3.453</p>

<p>&hellip;中间部分省略&hellip;</p>

<p>Update[4001] : Change learning rate to 8.14506e-03</p>

<p>Epoch[4] Train-accuracy=0.959400</p>

<p>Epoch[4] Time cost=3.451</p>

<p>Saved checkpoint to nmnist_lenet-0005.params&rdquo;</p>

<p>Epoch[4] Validation-accuracy=0.982800</p>

<p>Update[5001] : Change learning rate to 7.73781e-03</p>

<p>MXNet中没有Caffe里专门画训练曲线的工具，不过在自带例子中有个 mxnet/example/kaggle-ndsbl/training_curves.py 对只输出准确率的训练 log 文件都管用：</p>

<p>» python /path/to/mxnet/example/kaggle-ndsbl/training_curves.py &ndash;log-file=train_mnist_lenet.log    }</p>

<p>运行程序得到如图8-5所示的可视化结果。</p>

<p>.8</p>

<p>0    5    10    15    20    25    30    35</p>

<p>Epoch</p>

<p>图8-5 MXNet训练集和验证集准确率随训练变化</p>

<p>8.3.3测试和评估</p>

<p>1.测试模型准确率</p>

<p>MXNet在测试集上评估非常简单，把训练好的模型读取到一个Module中，把测试数</p>

<p>据装载到一个ImageRecordlter中，然后调用Module的score ()函数就可以了。</p>

<p>import mxnet as mx #测试数据的迭代器方法和验证数据一致 test_dataiter = mx.io.ImageRecordlter(</p>

<p>path_imgrec=n../data/test.rec&rdquo;, data_shape=(1,    28,    28),</p>

<p>batch_size=100 r mean_r=128,</p>

<p>scale=0.00390625,</p>

<p>)</p>

<p>#从前缀为nrniSt_lenet的存档中读取第35代的存档</p>

<p>#    for_training 要指定为 False</p>

<p>mod = mx.mod.Module.load(*mnist_lenet&rsquo;,    35, context=mx.gpu(0))</p>

<p>V    f I</p>

<p>#如果是想接着之前的结果继续训练把begin_epoch设置为35即可 mod.fit(&hellip;,</p>

<p>begin_epoch=35)</p>

<p>V    V •</p>

<p>#    load只管读取模型文件(.j son)和参数(.params)</p>

<p>#要想用起来还需要bind—遍</p>

<p>mod.bind(</p>

<p>data_shapes=test_dataiter.provide_data, label_shapes=test_dataiter.provide_label, for_training=False)</p>

<p>#定义一个评估模型的metric，这里使用准确率(acc: accuracy) metric = mx .metric.create(&lsquo;acc1)</p>

<p>#调用score ()函数，结果更新在metric里 mod.score(test_dataiter, metric)</p>

<p>#准确率的metric里保存准确率和对应值</p>

<p>for name, val in metric.get_name_value():</p>

<p>print^( * {} = { : . 2f} % * . format (name, val* 100) &gt;</p>

<p>把上面代码保存并执行，就能得到在测试集上的评估结果，如笔者训练的模型结果输 出如下：</p>

<p>accuracy=99.09%</p>

<p>2.评估模型性能</p>

<p>这里用一个比较粗略的方法来评估前向计算性能，就是用python的time模块，迭代</p>

<p>一定次数计算总时间，然后求得每次前向计算的消耗时间。</p>

<p>import time import mxnet as mx</p>

<p>#和Caffe中的用例保持一致，用64作为batch size benchmark—dataiter = mx.io.ImageRecordlter(</p>

<p>path_imgrec=&ldquo;../data/test.rec&rdquo;, data_shape=(1,    28,    28),</p>

<p>batch_size=64,</p>

<p>mean_r=128, scale=0.00390625,</p>

<p>)</p>

<p>#测试GPU下的执行效率</p>

<p>mod = mx.mod.Module.load(&lsquo;mnist_lenet1,    35, context=mx.gpu(0))</p>

<p>mod.bind(</p>

<p>data_shapes=benchmark_dataiter.provide_data, label_shapes=benchmark_dataiter.provide_label, for_training=False)</p>

<p>#获取测试开始时的时间</p>

<p>start = time.time()</p>

<p>#迭代并计次</p>

<p>for i, batch in enumerate(benchmark_dataiter): mod.forward(batch)</p>

<p>#获取消耗的总时间并输出</p>

<p>time_elapsed = time.time()    - start</p>

<p>msg =    &lsquo; { } batches iterated!\nAverage forward time per batch:</p>

<p>{:.6f} ms *</p>

<p>print(msg.format(i+1, 1000*time_elapsed/float(i)))</p>

<p>在笔者的笔记本电脑上得到如下结果：</p>

<p>157 batches iterated!</p>

<p>Average forward, time per batch:    0.754967 ms</p>

<p>和Caffe的结果差不多，但是笔者用的毕竟是带桌面的笔记本电脑，结果可能不具参</p>

<p>考性。</p>

<p>8.3.4识别手写数字</p>

<p>用训练好的MXNet模型预测图片略微有些复杂，因为mxnet的Module模块中，没</p>

<p>有直接接受NDArray作为输入的方法，需要把输入做成一个带名字的值的形式，具体代</p>

<p>码如下：    &lt;</p>

<p>import sys import os import cv2</p>

<p># 从 Python 的 collections 库中导入 namedtuple from collections import namedtuple</p>

<p>#建立一个namedtuple，Batch为名称，只有一个字段，字段名字是data</p>

<p>Batch = namedtuple(&lsquo;Batch <em>,    [&lsquo;data</em>])</p>

<p>import numpy as np import mxnet as mx</p>

<p>#输入路径，在例子中是包含所有测试文件图片的nmist/test input_path = sys.argv[l].rstrip(os.sep)</p>

<p>mod = mx.mod.Module. load (*mnist_lenet&rsquo; ,    35, context=mx.gpu (2))</p>

<p>#没有数据迭代器的情况下，手动指定输入_的维度</p>

<p>mod.bind(</p>

<p>data_shapes=[(* data *,    (1,    1,    28,    28))],</p>

<p>for_training=False)</p>

<p>filenames = os.listdir(input_path) for filename in filenames:</p>

<p>filepath = os.sep.j oin([input_path, filename])</p>

<p>#读取灰度图片</p>

<p>img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)</p>

<p>#数据预处理，减均值和缩放</p>

<p>img = (img. astype(np.float)-128)    ★    0.00390625</p>

<p># reshape成mod接受的形状</p>

<p>img = img.reshape((1,    1)+img.shape)</p>

<p>#用Batch封装后传入做前向运算</p>

<p>mod.forward(Batch([mx.nd.array(img)]))</p>

<p>#得到二维的概率</p>

<p>prob = mod.get_outputs()[0].asnumpyO</p>

<p>#变成一维数组</p>

<p>prob = np.squeeze(prob)</p>

<p>#获取预测的标签</p>

<p>pred_label = np.argmax(prob)</p>

<p>print(* Predicted digit for {} is {}&lsquo;.format(filepath pred_label))</p>

<p>把这段代码同样保存为recognize_digit.py,并执行下面命令：</p>

<p>» python recognize_digit.py mnist/test</p>

<p>得到如下输出，对于前几行而言，结果和8.3.3基于Caffe的结果一致。</p>

<table>
<thead>
<tr>
<th>PredictedPredicted</th>
<th>digitdigit</th>
<th>for mnist/test/000000 7.jpg</th>
<th>isis</th>
<th>72</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>for</td>
<td>mnist/test/000001_</td>
<td>_2.jpg</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000002</td>
<td>_l.jpg</td>
<td>is</td>
<td>1</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000003_</td>
<td>_0.jpg</td>
<td>is</td>
<td>0</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000004</td>
<td>_4.jpg</td>
<td>is</td>
<td>4</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000005</td>
<td>_l.jpg</td>
<td>is</td>
<td>1</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000006_</td>
<td>_4.jpg</td>
<td>is</td>
<td>4</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000007_</td>
<td>_9.jpg</td>
<td>is</td>
<td>9</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000008</td>
<td>_5.jpg</td>
<td>is</td>
<td>5</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000009</td>
<td>_9.jpg</td>
<td>is</td>
<td>9</td>
</tr>

<tr>
<td>Predicted</td>
<td>digit</td>
<td>for</td>
<td>mnist/test/000010</td>
<td>_0.jpg</td>
<td>is</td>
<td>0</td>
</tr>
</tbody>
</table>

<h2 id="相关资料">相关资料</h2>

<ul>
<li>《深度学习与计算机视觉》</li>
</ul>

    </div>

    
    

    
    

    <footer class="post-footer">
      

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89cv/11-%E9%9D%99%E6%80%81%E5%9B%BE%E5%83%8F%E9%A2%86%E5%9F%9F/01-%E7%89%A9%E4%BD%93%E8%AF%86%E5%88%AB%E4%B8%8E%E6%A3%80%E6%B5%8B/10-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/10-%E5%9F%BA%E4%BA%8E-caffe-%E5%AE%9E%E7%8E%B0-lenet-5-%E7%BD%91%E7%BB%9C/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">10 基于 Caffe 实现 LeNet-5 网络</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/01-%E7%9F%A5%E8%AF%86%E6%A0%91/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/02-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/03-caffe/caffe/">
            <span class="next-text nav-default">Caffe</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="iteratelyd@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="http://github.com/iterateself" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/thebegin/activities" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/68028070/" class="iconfont icon-douban" title="douban"></a>
  <a href="http://iterate.site/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>

  <span class="copyright-year">
    &copy; 
    2018
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">iterateself</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>








</body>
</html>
