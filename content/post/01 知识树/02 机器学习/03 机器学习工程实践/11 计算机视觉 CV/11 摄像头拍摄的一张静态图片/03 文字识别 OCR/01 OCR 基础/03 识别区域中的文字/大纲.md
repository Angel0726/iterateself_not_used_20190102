---
title: 大纲
toc: true
date: 2018-09-02
---
# 识别区域中的文字



## 主要内容

classification models ：

不需要对文字预先分割(end-to-end)：<span style="color:red;">什么是不需要对文字预先分割？是指只要把文字那块的图片输入就行了吗？不需要再对每个字进行划分吗？此处不需要文字分割的意思是不需要去除背景并分割定位单个字符是吗？</span>

- multi-digit number classification
- RNN/LSTM/GRU+CTC
- attention-mechanism


这个是大神：
文字识别近两年没有太大进展，有两种方法，一种是CNN+RNN+CTC，白翔老师团队的CRNN写的比较清楚，还有一种是CNN+RNN基于Attention的方法。



说一下自己做了两年的topic吧（单指识别）。

自己刚刚开始上手的framework是: CNN + LSTM + CTC。这个framework加上residue network + stn可以把通用的数据集刷的非常高。

之后开始研究attention based的框架，这个框架比较灵活，可挖的坑也比较多，目前遇到的主要问题是数据集。现有的数据集的不够支撑更加复杂的模型。

你好，attention和ctc两种方式效果对比咋样？attention的效果要比ctc好，attention可以引入language model。

resnet用的是哪种？另外stn是什么方法有资料么？[facebook/fb.resnet.torch](https://link.zhihu.com/?target=https%3A//github.com/facebook/fb.resnet.torch), stn: Spatial Transformer Network

我跑了resnet的，感觉效果还没普通cnn的好。。奇怪了，另外，attention的paper有推荐的吗？




ctc也可以引入语言模型。attention速度比ctc慢很多，识别率主要在cnn那一块，这个其实ctc和attention是共有的。attention自带一定的语义信息，ctc基本只有局部的响应了，不过ctc解码的时候还是可以另外附加language model的，attention也可以额外附加language model。

我指的语言模型是在训练的时候加入一起训练然后implicit的encode在模型中，对于decode过程中引入语言模型个人不是非常喜欢这种做法，当然如果是刷竞赛的指标，是可以作为后处理过程引入。attention的速度之所以慢，是因为attention在每一个timestep需要对每一个feature进行score，计算量比ctc要大很多。因为ctc loss中引入了blank label，所以形成的局部的响应。Attention的语义信息主要encode在了lstm的hidden state中。

## 相关资料

- [OCR文字识别用的是什么算法？](https://www.zhihu.com/question/20191727)
- Ian goodfellow 的 multi-digit number classification：[Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks](https://arxiv.org/abs/1312.6082)


## 需要消化的



## 需要补充的
