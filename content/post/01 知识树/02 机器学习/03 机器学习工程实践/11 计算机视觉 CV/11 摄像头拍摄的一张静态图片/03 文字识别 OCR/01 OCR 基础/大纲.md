---
title: 大纲
toc: true
date: 2018-09-02
---
# OCR 基础



## 主要内容

一般的 OCR 包含两步：

- detection -> 找到包含文字的区域(proposal)
- classification -> 识别区域中的文字

detection就是为了从给定的区域中找到存在文字的区域和不存在文字的区域（背景），faster-rcnn的分类是关于该区域是否是存在文字，并且将存在文字的这部分区域框起来给出坐标。为后续对框出来的区域进行文字的识别做准备

## 需要消化的



## 需要补充的

- 普通的机器学习有没有使用的？
- 还是介绍了很多好的方法的，不知道现在普遍使用的是什么？
- 这些对于中文和特殊符号的适用情况怎么样？
- 有相关的项目吗？
- 有相关的数据集吗？
- 这种情况如果需要打标要怎么进行，有打标工具吗？
- 想更深入的理解这些方法。
- 找到包含文字的区域这个有对应的数据集进行训练吗？
- 有没有比较过attention和ctc两种方法的正确率？我的经验是 ctc 在正常的 horizontal text 上效果稍好。ctc正确率稍高，但是限制较多，感觉attention还有研究价值

- 以上这些算法的时间复杂度、以及对计算资源的要求高吗？如果腾讯微信or新浪微博or国家有关部门处于安全/敏感内容的考虑，需要对这些社交应用发出的图片进行文字识别，有没有可能性？成本有多大？<span style="color:red;">嗯，是呀，还有这种应用</span>


- 请教下在手写体汉字样本（票据类）较少的情况下，如何提升识别的准确率呢？我看目前用的是lstm+ctc。 自己脑洞不够大:想到可不可以模型融合；结合yolo2或faster rcnn。她的回答是：直接lstm+ctc?

- rnn/lstm/gru encoder-decoder model 这个不是用来翻译以及生成歌词、诗句啥的吗。。还能用来识别数字?是的。

- 对于圆形印章盖住了的字，要怎么分割识别？一般可以用字符间距作为先验条件截取分割字符，如果粘连形变比较严重的话，我觉得传统方法就比较难处理了。

- 请问10000个以上汉字类别也可以搭建cnn分类器吗？我试过3k汉字，1w以上就没有收敛过。。。

- 需要进行语义纠错吗？语义纠错有哪些论文？


- 开源的 开源OCR引擎Tesseract 要用吗？


- 百度OCR大致用的啥思路你知道吗？ [OCR文字识别-百度大脑](https://link.zhihu.com/?target=http%3A//ai.baidu.com/tech/ocr/general) 百度ocr的基本思路是crnn吗？现在应该都不是了


- 有什么调参技巧么？我用crnn+resnet得到的结果一直不是很好
- 您好 我在用attention模型的时候发现效果不如ctc， 经常漏掉一些字符和多出一些字符， 能给一些提示吗？我用的是LuongAttention。 一开始是输入batchsizex32x400x1的图片 然后经过若干层cnn变成batchsizex99x256的特征， 将此特征输入一个双向gru，得到99个hidden output， 再将这99个hidden output 输入一个带attention机制的解码gru（一层单向）我可能说的不清楚 传到这了 ctc+attention 共用cnn和双向gru节点 ，然后两个loss一起训练 https://gist.github.com/ray075hl/09ac0b6a186344c924d055054ca95d2f  他回复说：试着加大一下cnn的深度

hi 楼主 我想问一下 为什么 我用ctc 和 attention 一起训练， ctc能够得到正确的结果，这是不是说 其实cnn+rnn产生的特征已经能够正确表征字符了， 这样加深cnn是不是没什么用？（个人理解，我已经加深了cnn，在等结果）

应该只能说是你产生的feature能够正确地被ctc decode。有做过ctc和attention单独分开训练的实验吗？

嗯 我现在用很深的densenet在试。 单独的也做过实验， ctc能够很好的定位对齐， 而attention似乎在定位对齐有一些不准，特别是在比较模糊的情形下， ctc完胜， 我都怀疑是我代码写的不对了 O(∩_∩)O哈哈~

在图片较为清晰的情形下 attetnion 一行十几个字也能识别对 。

在模糊的情况下是有这样的现象的

attention对噪声比较敏感 ctc更鲁棒一些 可以这么说吗？ 请问 有没有什么方法可以处理这种情况呢？

cnn加深之后 虽然还是有定位错误 但效果较之前确实变好了很多很多


ICCV2017有个paper：[Towards Accurate Text Recognition in Natural Images](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1709.02054)。然后最根本的应该还是对原始图片进行增强（去噪，去模糊等）要来的更加直接点吧。






- 你训练的时候用多种字体试试，我用了几百种字体，基本各种打印体识别效果都挺好的。我同事识别驾驶证上的那个车辆识别代号，一开始网上找了这种专用字体发现识别率不高，后来添加了其他多种字体，识别率提高了不少



- 想问下各位大佬用crnn+ctc的方法的训练集样本数得在多少？我用5000个样本，精度一直接近0
- 大佬，最近在做车牌识别，有一个问题很不解。ctc loss是用于不定长序列识别，可以不用对齐，那车牌这种定长序列为什么也可以用ctc呢？使用ctc的时候可以指定模型识别序列的长度吗（比如指定车牌识别的长度为7）？指定长度后精度会有提升吗
- 答主您好，可以请教您一下目前对于文本识别比较主流的网络架构是什么样的呢？
还是那种cnn提特征，放入 bilstm 进行 encode，最后用有 attention 机制的 decoder 或者是 ctc 来进行识别预测吗？特别是对中文的数据集有什么好的改进意见吗？





第一个答主已经说得很详细了，补充一点分类器方面的材料，汉字识别以前主要采用最近邻分类器（KNN）和修正二次判别函数(MQDF)，主要是针对扫描文档OCR和手写汉字OCR。当然现在深度学习发展迅猛，卷积神经网络（CNN）已经开始大行其道，具体可以看看百度深度学习研究院的技术报告。

作者：张阳
链接：https://www.zhihu.com/question/20191727/answer/58870255
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。




单字符用CNN,整行或者单词用CNN+LSTM+CTC，都有开源实现




给你提供一个现成的框架，也是分那几步走了，效果不错 [LEADTOOLS Professional OCR Module](https://link.zhihu.com/?target=http%3A//leadtools.gcpowertools.com.cn/products/professional-ocr/)
