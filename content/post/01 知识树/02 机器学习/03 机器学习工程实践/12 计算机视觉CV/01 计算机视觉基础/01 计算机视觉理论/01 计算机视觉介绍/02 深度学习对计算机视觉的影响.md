

# 深度学习对计算机视觉的影响

2012年，计算机视觉的新起点。


在深度学习出现之前，计算机视觉就像是设计精妙的火箭，缺少一个强大的助推器。<span style="color:red;">嗯，好像是这样。</span>


ILSVRC举办的前两年，各种手工设计特征+编码+SVM框架下的算法就霸占了前几名。ILSVRC的分类错误率的标准是让算法选出最有可能的5个预测，如果有一个是正确的则算通过，如果都没有预测对则算错误。2010 年 ILSVRC 的冠军是 NEC 的余凯带领的研究组，错误率达到了 28% 。2011年施乐欧洲研究中心的小组将这个成绩提高到了 25.7%。

终于，到了 2012 年，这年辛顿的小组也参加了竞赛，主力选手是辛顿的一名研究生阿历克斯•克里泽夫斯基(Alex Krizhevsky)。阿历克斯是一名学术和工程都非常厉害的学生，在这一年的竞赛上，他提出了一个5卷积层+2全连接层的卷积神经网络 AlexNet，并利用 CUDA 给出了实现，这个算法一下将前5类错误率从 25.7% 降到了 15.3%，在之前的 ImageNet竞赛中，哪怕有一个百分点的提升，都是很不错的成绩，而深度学习第一次正式 应用在图像分类竞赛就取得了 10 个百分点的改进，并且完胜第二名(26.2%)。这在当时对传统计算机视觉分类算法的冲击是不言而喻的。简单来说当时的改进主要有以下3点。<span style="color:red;">厉害了，竟然能用 CUDA 给出实现。</span>

- 更深的网络结构。
- 校正线性单元(Rectified Linear Unit, ReLU)，Dropout等方法的应用。<span style="color:red;">2012 年就有 Dropout了？看来我落后了非常多</span>
- GPU训练网络。<span style="color:red;">之前不是使用 GPU 进行训练的吗？</span>


尽管在当年许多传统计算机视觉的学者仍然对AlexNet抱有种种质疑，如算法难以解释，参数过多（实际上比许多基于SVM的办法还少）等，但自从 2012 年后，ImageNet 的参赛者几乎全体转向了基于卷积神经网络的深度学习算法，或者可以说计算机视觉领域 全体转向了深度学习。基于深度学习的检测和识别、基于深度学习的图像分割、基于深度 学习的立体视觉等如雨后春笋般一夜之间全冒了出来。深度学习，尤其是卷积神经网络就 像一把万能的大杀器，在计算机视觉的各个领域开始发挥了作用。




## 相关资料

- 《深度学习与计算机视觉》
