---
title: 01 人工智能的新焦点-深度学习
toc: true
date: 2018-08-29
---


# 第1章引 言

What magical trick makes us intelligent? The trick is that there is no trick. The power of intelligence stems from our vast diversity, not from any single, perfect principle （是什么魔法让我们拥有智能？其实并没有魔法。智能的力量来源于多样性，而非任何一个完美的原理）。- Marvin Minsky

<span style="color:red;">上面这句真的是这样吗？智能来自多样性吗？真的吗？</span>








1.3基于深度学习的计算机视觉

深度学习成了现今大部分计算机视觉领域的标配，计算机视觉上的成功又进一步促进 了深度学习。

1.3.1从ImageNet竞赛到AlphaGo战胜李世石——计算机视觉超越人类

前面已经介绍过ImageNet图像分类竞赛和AlexNet的一骑绝尘。本节来看看接下来几 年发生了什么。

2013年，马修•塞勒(Matthew Zeiler)以初创公司Clarifi创始人，以及纽约大学计 算机系的博士生的两个身份参加了 ImageNet比赛，并分别取得了第一名和第三名，这一年 他把ImageNet的前5分类错误率降低到了 11.7%o从这一年开始几乎所有的参赛者都开始 使用卷积神经网络，少数没有使用深度神经网络的参赛者都处于垫底位置。

2014年，Google开始在ImageNet发力。当时在Google担任软件工程师的克里斯蒂 安•赛格蒂(Christian Szegedy)提出了一种Inception的结构，并基于这种结构搭建了一 个22层的卷积神经网络GoogLeNet,达到了 6.66%错误率的成绩。和2013年相比，这一 年基于卷积神经网络的成绩普遍提升，前5名都达到了小于10%的成绩。另外值得一提的 是，GoogLeNet从网络、形态上讲，已经脱离了 AlexNet和LeNet的卷积叠加+全连接的框 架。这一年，所有的参赛者都使用了深度神经网络。

^Tips：关于GoogLeNet的细节，第4章节会有详细介绍。

2015年，在建立更深网络的大趋势下，微软亚洲研究院(Microsoft Research Asia, MSRA)的何恺明提出了深度残差网络(Deep Residual Networks)，把网络层数做到了 152 层，并在ImageNet的分类比赛中取得了 3.57%的错误率。在当年，这个成绩的意义除了第 一名，更重要的是超过了接收过训练的人在ImageNet数据集上对图片进行分类的成绩

(5.1%)。虽然这个结果并不能说明深度学习算法已经真的超过了人类，但是在深度学习 介入ImageNet的分类竞赛前，算法只能做到28%的错误率，而在引入深度学习后，三年 内就填补了最先进算法到人类分类水平的23%左右的空白，深度学习已经充分展现了威力。 2016年，前5名分类的错误率被进一步降低到了 2.99%。冠军是我国公安部三所的搜

神(Trimps-Soushen)代表队。2016年的ImageNet竞赛基本上是中国公司代表队的全面开 花。在各个不同类别比赛的最终排行榜上都能看到中国公司和机构的名字，出现最多的是 海康威视、公安部三所搜神和汤晓鸥老师的商汤科技。这是个可喜可贺的情况，说明中国 在深度学习的应用上已经走在了世界的前列。不过从另一方面来讲，2016年很多国外传统 强队根本没有参赛，并且也没有什么特别亮眼的新方法被提出，这届竞赛有些更像是模型 组合及调参大赛，也不是一件特别鼓舞人心的事情。

每一门学科技术的发展都是螺旋式上升，深度学习被大炒几年后是否也会像股票和三 线城市的房价一样回调停滞？总之，作为一门威力强大但是却没有被透彻研究的技术，深 度学习还有很多可以探索的领域，其发展也许还任重道远。如图1-7是从2011年到2016 年ImageNet竞赛中物体分类最好成绩的趋势。



图1-7 2011〜2016年ImageNet图像分类竞赛前5错误率最好成绩

深度学习在图片分类上的成功是被关注讨论最多的，事实上在其他领域深度学习算法 在指标上也在渐渐赶超人类。如人脸识别领域的一个公认数据集LFW(Labeled Faces in the Wild)上，人类识别的准确率是97.53%,而如今基于深度学习的人脸识别已经可以达到 99.5%的水平。

2016年初万众瞩目的围棋人机大战中，AlphaGo突破了人类智慧的最后堡垒。虽然 AlphaGo不算是计算机视觉的应用，但是深度卷积神经网络却在其中扮演了重要角色。棋 盘的特征是以19X19的图像形式表示的，通道数是人为规定的颜色、轮次等其他特征，然 后放到基于深度卷积神经网络的估值和策略网络中进行训练。

事实上在许多特定任务上，基于深度学习的算法超越人类水平都不是什么新鲜事，未 来还会看到更多的例子。

1.3.2 GPU和并行技术——深度学习和计算视觉发展的加速器

前面提到过，深度学习的概念早就有了，早期制约其发展的因素是方方面面的，其中 一个很重要的方面就是计算能力的限制。相对其他许多传统的机器学习方法，深度神经网 络本身就是一个消耗计算量的大户。另一方面，由于多层神经网络本身极强的表达能力， 对数据量也提出了很高的要求。如图1-8所示，一

个普遍被接受的观点是，深度学习在数据量较少时，



图1-8深度学习和传统机器学习算法对 数据的依赖关系

和传统算法差别不大，甚至有时候传统算法更胜一 筹。而当数据量持续增加的情况下，传统的算法往 往会出现性能上的“饱和”，而深度学习则会随着 数据的增加持续提高性能。所以大数据和深度神经 网络的碰撞才擦出了今天深度学习的火花，而大数 据之大更加大了对计算能力的需求。在GPU被广泛 应用到深度学习训练之前，计算能力的低下限制了 对算法的探索和实验，以及在海量数据上进行训练 的可行性。

从20世纪80年代开始人们就开始使用专门的运算单元负责对三维模型形成的图像进 行渲染。不过直到1999年NVIDIA发布GeForce 256时，才正式提出了 GPU的概念。早 期的GPU中，显卡的作用主要是渲染，但因为天然就很强的并行处理能力和少逻辑重计算 的属性，从2000年开始就有不少科研人员开始尝试用GPU来加速通用高密度、大吞吐量 的计算任务。2001 年，通用图形处理器(General-Purpose computing on GPU，GPGPU)的 概念被正式提出。2002年，多伦多大学的James Fung发布了 OpenVIDIA,利用GPU实现 了一些计算机视觉库的加速，这是第一次正式将GPU用到了渲染以外的用途上。到了 2006 年，NVIDIA推出了利用GPU进行通用计算的平台CUDA,让开发者不用再和着色器/ OpenGL打交道，而更专注于计算逻辑的实现。这时，GPU无论是在带宽还是浮点运算能 力上都已经接近同时期CPU能力的10倍，而CUDA的推出一下降低了 GPGPU编程的门 槛，于是CUDA很快就流行开并成为了 GPU通用计算的主流框架。后来深度学习诞生了， 鉴于科研界对GPU计算的一贯偏爱，自然开始有人利用GPU进行深度网络的训练。之后 的事情前面也讲到了，GPU助Alex—战成名，同时也成为了训练深度神经网络的标配。

除了 NVIDIA, ATI (后被AMD收购)也是另一大GPU厂商。事实上ATI在GPU通

用计算领域的探索比NVIDIA还早，但也许是因为投入程度不够,或是其他原因，被NVIDIA 占尽先机，尤其是后来在深度学习领域。

说完了 GPU领域的风云变幻，接下来看一些实际的问题：如何选购一块做深度学习的 GPU? 一提到用于深度学习的GPU,很多人立刻会想到NVIDIA的Tesla系列。实际上根 据使用场景和预算的不同，选择是可以很多样化的。NVIDIA主要有3个系列的显卡： GeForce、Quadro和Tesla。GeForce面向游戏，Quadro面向3D设计、专业图像和CAD等， 而Tesla则是面向科学计算。所以这里主要讨论一下GeForce和Tesla的区别。

GeForce系列显卡面向游戏，所以性能要求是最高的，而精度上的限制就低很多，另 外稳定性比Tesla也差很多。毕竟玩游戏的时候如果程序崩了也就丢个存档，但服务器要 是崩了没准能“挂掉” 一个公司。当然从实际角度看最大的两个优点是：既可以进行深度 学习又可以玩游戏；便宜。

Tesla从诞生之初就是瞄准高精度科学运算。所以Tesla严格意义上来说不是块显卡， 而是计算加速卡。对于不带视频输出的Tesla卡而言，玩游戏是指望不上的。由于Tesla开 始面向的主要是高性能计算，尤其是科学计算，在许多科学计算领域，如大气等物理过程 的模拟中对精度的要求非常高，所以Tesla的设计上双精度浮点数的能力比起GeForce系 列强很多。如GTX Titan和K40两块卡，GTX Titan的单精度浮点数运算能力是K40的1.5 倍，但是双精度浮点数运算能力却只有K40的不到15%。不过从深度学习的角度来看，双 精度显得不是那么必要，如经典的AlexNet就是两块GTX 580训练出来的。所以，2016 年开始，NVIDIA也在Tesla系列里推出了 M系列加速卡，专门针对深度学习进行了优化， 并且牺牲双精度运算能力而大幅提升了单精度运算的性能。前面也提到了，除了精度，Tesla 主要面向工作站和服务器，所以稳定性特别好，同时也会有很多针对服务器的优化，如高 端的Tesla卡上的GPUDirect技术可以支持远程直接内存访问(Remote Direct Memory Access, RDM A)用来提升节点间数据交互的效率。当然，Tesla系列有一个最大的特点就 是贵。

综上所述，如果是在大规模集群上进行深度学习研发和部署，Tesla系列是首选，尤其 是M和P子系列是不二之选。单机上开发的话，“土豪”或者追求稳定性高的人就选择 Tesla。而最有性价比且能兼顾日常使用的选择则是GeForce。

1.3.3基于卷积神经网络的计算机视觉应用

和计算机关联最紧密的深度学习技术是卷积神经网络。本节来列举一些卷积神经网络 发挥重要作用的计算机视觉的方向。

图像分类顾名思义，图像分类就是对于输入的已知图像，由算法提取特征并最终分 到已知的一个类别里，或者说判断图像中是否包含一个已知类别中的物体，如图1-9所示。

前面花了不少篇幅讲述ILSVRC从2010年到2016年的风云变幻，而图像分类是深度 学习在计算机视觉领域大放异彩的第一个方向。不管是最开始的MNIST,还是后来的 ImageNet,基于深度学习的图像分类在特定任务上早就超过了人的平均水平。

ATips•.第10章会一步步实现一个利用卷积神经网络进行图像分类的例子。



图1-9图像分类示意图

物体检测物体检测和图像分类差不多，也是计算机视觉里最基础的两个方向。它和 图像分类的侧重点不同，物体检测要稍微复杂一些，关心的是什么东西出现在了什么地方, 是一种更强的信息。如图1-10中，经过物体检测，我们得到的信息不仅是照片中包含马和 摄影师，还得到了每一样检测到的类别的位置信息，以方框的形式展现出来。



图1-10物体检测示意图

和图像分类相比，物体检测传达的信息更强，例如要分类猫和狗的图片的问题，那么 如果图像中既有猫又有狗该怎么分类呢？这时候如果还是坚持用分类则是一个多标签分类 问题，或者就进一步用物体检测告诉我们猫在哪，狗在哪。在物体检测领域以基于Region Proposal的R-CNN及后续的衍生算法，以及基于直接回归的YOLO/SSD 一系的算法为代

表。这两类算法都是基于卷积神经网络，借助的不仅仅是深度网络强大的图像特征提取和 分类能力，也会用到神经网络的逼近能力。

◎Tips:第11章会讲解一个利用MXNet实现物体检测的实例。

人脸识别人脸识别是计算机视觉里非常悠久的一个方向，也是和人相关的研究最多 的一个计算机视觉子领域。和我们生活中最相关的应用一般有两个方面：第一个是检测图 像中是否存在人脸，这个应用和物体检测很像。主要应用有数码相机中对人脸的检测，网 络或手机相册中对人脸的提取等；第二个是人脸匹配，有了第一个方面或是其他手段把人 脸部分找到后，人脸的匹配才是一个更主流的应用。主要的思想是把要比对的两个人脸之 间的相似度计算出来。计算这种度量，传统的方法叫做度量学习(metric learning)。其基 本思想是通过变换，让变换后的空间中定义为相似的样本距离更近，不相似的样本距离更 远。基于深度学习也有相应的方法，比较有代表性的是Siamese网络和Triplet网络，当然 广义上来说都可以算是度量学习。有了这种度量，可以进一步判断是否是一个人。这就是 身份辨识，广泛用于罪犯身份确认、银行卡开卡等场景中。2015年马云在德国的汉诺威信 息技术博览会上“刷脸”的大新闻，背后就是这种技术。此外还可以利用相似度实现一些 好玩的应用，如用自拍照找相似的明星脸等。

人脸领域最流行的测试基准数据是LFW (Labeled Faces in the Wild),顾名思义就是 从实拍照片中标注的人脸。该图片库由美国麻省理工大学开发，约13 000多张图片，其中 有1 680人的脸出现了两次或两次以上。在这个数据上，人类判断两张脸是否是同一人能 达到的准确率为99.2%。而在深度学习大行其道之后，自2014年起这个记录已经被各种基 于深度学习的方法打破。虽然这未必真的代表深度学习胜过了人类，但基于深度学习的人 脸算法让相关应用的可用性大大提高。如今人脸识别相关的商业应用已经遍地开花。

图像搜索狭义来说图像搜索还有个比较学术的名字是基于内容的图片检索(Content Based Image Retrieval, CBIR)。图像搜索是个比较复杂的领域，除了单纯的图像算法， 还带有搜索和海量数据处理的属性。其中图像部分背后的重要思想之一和人脸识别中提到 的度量学习很像，也是要找到和被搜图像的某种度量最近的图片。最常见的应用如Google 的Reverse Image Search和百度的识图功能，京东和淘宝的拍照购物及相似款推荐等。深度 学习在其中的作用主要是把图像转换为一种更适合搜索目的的表达，并且考虑到图像搜索 应用场景和海量数据，这个表达常常会哈希/二值化处理，以达到更高的检索/排序效率。

图像分割图像分割是个比较传统的视觉应用，指的是以像素为单位将图像划分为不 同部分，这些部分代表着不同的感兴趣区域。如图1-11所示的例子，画面中是山东威海的 一只受伤幼年红隼和背景。经过图像分割后，红隼在画面中所占的像素被标了出来，和背 景有了区分。

传统的图像分割算法五花八门，如基于梯度和动态规划路径的Intelligent Scissors (Photoshop中的磁力套索)；利用高一维空间的超曲面解决当前空间轮廓的水平集(Level Set)方法；直接聚类的K-means;后期很流行的基于能量最小化的GraphCut/GrabCut和随

机场的 CRF (Conditional Random Field)等。

后来深度学习出现了。和传统方法相比，深度学习未必能做到很精细的像素级分割。

但是因为深度学习能学到大量样本中的图像语义信息的天然优势，这更贴近人对图像的理 解，所以分割的结果可用性通常也更好一些。常见的基于深度学习的图像分割手段是全卷

积神经网络(Fully Convolutional Networks, FCN)。Facebook 的人工智能实验室 FAIR

(Facebook Artificial Intelligence Research)于 2016 年发布了一套用于分割+物体检测的框 架。其构成是一个大体分割出物体区域的网络DeepMask,加上利用浅层图像信息精细图 像分割的SharpMask,最后是一个MultiPathNet模块进行物体检测。其实在这背后也体现 出学界和业界开始慢慢流行起的另一个很底层的思想：就是图像分割和物体检测背后其实 是-•回事，不应该分开来研究。对照物体检测和图像分类的关系，图像分割传达的是比物 体检测更进一步、更强的信息。

![img](file:///E:/00.Ebook/__Recent__html__/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)/00_深度学习与计算机视觉%20%20算法原理、框架应用与代码实现_14279998(1)_files/00_f1a666600ea1973ac6c9%20%2097d59f060146b694280ee3019eb0_14279998(1)-16.jpg)



图1-11图片分割示意图

视频识别因为和图像的紧密联系，视频当然少不了深度学习的方法。深度学习在图 像分类任务上大行其道之后，视频识别的研究立刻就跟进了上来，比较有代表性的工作从 2014年起相继出现。

2014年的CVPR上，斯坦福大学的Fei-Fei Li组发表了一篇视频识别的论文。其基本 思路是用视频中的多帧作为输入，再通过不同的顺序和方式将多帧信息进行融合。其方法 并没什么特别出彩的地方，但随着论文发布了 Sport-1M数据集，包含了 Youtube上487类 共计113万的体育视频，是目前最大的视频分类数据集。

2014年的NIPS上，牛津大学传统视觉强组VGG (Visual Geometry Group)发表了一 篇更经典的视频识别的文章，将图像的空间信息，也就是画面信息，用一个称为Spatial Stream ConvNet的网络处理，而视频中巾贞之间的时序信息用另一个称为Temporal Stream ConNet的网络处理，最后融合称为Two Streams,直译就是二流法。这个方法后来被改来 改去，发展出了更深网络的双流法，以及更炫融合方式的双流法，甚至是除了双流还加入 音频流的三流法。不过影响最大的改进还是马里兰大学和Google的一篇论文，其对时序信 息进行了处理和改进，加入了本章提到过的LSTM，以及改进版二流合并的方法，成为了 主流框架之一。

因为视频有时间的维度，所以还有一个很自然的想法是用三维卷积去处理视频帧，这 样自然能将时序信息包括进来，这也是一个流行的思路。

更近的一些研究中，最新的深度学习概率框架生成式对抗网络(Generative Adversarial Networks, GAN)也被用到了视频处理当中。2016年，Comma AI的实习生Eder Santana 和被称为天才黑客的George Hotz将GAN用于对视频输入进行降维，然后用低维表达和 LSTM进行处理，从而对视频的未来帧进行预测，可以比较准确地预测沿直线前进时未来

的画面。

视频作为比图像更高一维度的数据，并且还带有时序信息和声音等信息，可探索的空 间更大，相信未来会有更多精彩有趣的深度学习相关应用出现。

纹理/图像合成这是一个2016年左右才开始进入大众视野的领域，是因为一个叫 Prisma的App。纹理合成其实也是计算机视觉的一个传统应用，主要实现的是根据一种图 案，进行相似的复制和排列生成纹理。如图l-12a所示，根据左边照片中间部分的花朵图 案生成右边的图案。在2014年前后，这个领域开始被深度学习大幅攻占。到了 2015年， 纹理合成上的进展自然而然地拓展到了图片风格学习上。其中最有影响力的是德国的Leon Gatys发表的《A Neural Algorithm of Artistic Style》，其中提出的办法可以学习特定图片的 纹理风格并基于其他图片的内容生成风格化的图片。如图l-12b所示就是图片风格学习的 例子，左边的图片是拍摄于密云不老屯的射电望远镜和银河，通过深度网络给这张照片加 上了日本浮世绘名家葛饰北斋的作品《神奈川冲浪里》的风格。

总Tips:第13章会讲解实现一个学习图像风格生成图片的例子。



a)



b)

图1-12纹理合成与照片风格化例子

其他应用除了上面提到的这些应用，传统图像和视觉领域里很多方向现在都有了基 于深度学习的解决方案，包括图像降噪、图像去模糊、图像复原、超分辨率、图像内容描 述、图像深度（立体）信息提取等，在此就不详述了。
