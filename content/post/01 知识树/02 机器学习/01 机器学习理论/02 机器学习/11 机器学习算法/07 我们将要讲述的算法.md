---
title: 07 我们将要讲述的算法
toc: true
date: 2018-09-24
---

# 需要补充的

- 感觉这个的体系还是很好的，更加清晰。

# 将要讲述的算法


![mark](http://pacdb2bfr.bkt.clouddn.com/blog/image/180924/iB5JeJdEBD.png?imageslim)


有监督学习，我们会重点介绍 决策树家族。 线性模型家族，，加上的是 L2的正则项的就是 岭回归，加上 L1 的正则项就是 LASSO 回归算法。

对于分类问题的处理，最简单的就是感知器模型，从感知器算法按照最大化分类间隔思想就是 SVM。另外一个分支是 Logistic 回归，把线性预测器改装了以下，用 logistic 函数影射了以下，得到一个 0~1 之间的概率值。我们可以吧 Logistic 推广到多分类问题的场景，就是著名的 Softmax 回归，这个在深度学习里面是经常用到的，很多时候，我们的深度神经网络最后一层接的就是 Softmax 。

从感知器诞生的另外一类分支就是人工神经网络。在这次我们只重点讲全连接神经网络 MLP，多层感知器模型，实际上从它里面诞生的很多算法都会在深度学习里面进行讲解。

KNN 也是一个大家族，里面要用到距离。引出了距离度量学习算法。

下面的是贝叶斯家族，第一种是朴素贝叶斯，第二是正态贝叶斯。

然后是一种线性投影技术 LDA 是一种有监督学习的投影，他的思想很简单，就是最大化类间差异，最小化类差异，向这个方向做投影，得到一个投影方向。它有非线性版本，加上核函数之后得到一个 KLDA 这个不做重点介绍。

无监督学习

降维 ，最著名的就是 PCA ，主成分分析，改进版本叫做 KPCA 核主成分分析，这种算法在很多地方会大规模使用的，这是一种线性的降维技术。
那么非线性的降维技术呢？就是流行学习，我们会讲述4种有代表性的算法，分别是 LLE，局部线性嵌入，拉普拉斯特征映射、等距映射、局部保持投影。

然后我们说下聚类算法，聚类是无监督学习里面使用最广的一类算法，我们会介绍 层次聚类、k-means 还有三种基于密度的聚类：DBSCAN、OPTICS、Mean shift  然后会介绍谱聚类，它是一种基于图论的算法，最后会介绍EM算法，是一种基于概率的算法。

到这里位置，最常用的算法应该是已经介绍完了，还需要补充的就是 概率图模型，概率图模型的典型代表就是 贝叶斯网络、隐马尔科夫模型、条件线性随机场 等等。我们在这门课里面重点会介绍隐马尔科夫模型 HMM



下面我们看最后一大类算法：强化学习


到这里，经典的机器学习算法基本上是讲完了。
